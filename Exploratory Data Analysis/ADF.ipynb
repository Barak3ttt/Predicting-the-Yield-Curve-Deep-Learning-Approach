{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccfd534-dd9a-4e07-a212-f7f67ce7d113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3,>=1.22.3 in /venv/main/lib/python3.10/site-packages (from statsmodels) (2.1.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /venv/main/lib/python3.10/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /venv/main/lib/python3.10/site-packages (from statsmodels) (2.2.3)\n",
      "Collecting patsy>=0.5.6\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy!=1.9.2,>=1.8 in /venv/main/lib/python3.10/site-packages (from statsmodels) (1.15.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3025b58-35d2-486a-850c-5b31438f478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GPU detected → NVIDIA GeForce RTX 4090\n",
      "\n",
      "[LEVELS] Loading yield level data …\n",
      "[LEVELS] Running ADF tests …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bdadbfd9f14036bd4471c5c12b88ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LEVELS] Saved → adf_results_levels.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87815f808e9d42228f33d2ba2a40a7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Horizons:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ΔY] Horizon 1: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99c8c7f447f478c9a2f63dcf0c02db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 1: saved → adf_results_h1.csv\n",
      "\n",
      "[ΔY] Horizon 5: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd9805905ea42a8952f41370d511f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 5: saved → adf_results_h5.csv\n",
      "\n",
      "[ΔY] Horizon 21: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a9a7b818374ccc8de19ef90ba84d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 21: saved → adf_results_h21.csv\n",
      "\n",
      "[ΔY] Horizon 63: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63338a3d95d40919f12287f99c55457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 63: saved → adf_results_h63.csv\n",
      "\n",
      "[ΔY] Horizon 252: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b864cd98c57649f9a446a5839e6c63bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 252: saved → adf_results_h252.csv\n",
      "\n",
      "✅ Diagnostic complete!\n",
      "Key outputs:\n",
      " • adf_results_levels.csv\n",
      " • adf_results_h1.csv\n",
      " • adf_results_h5.csv\n",
      " • adf_results_h21.csv\n",
      " • adf_results_h63.csv\n",
      " • adf_results_h252.csv\n",
      " • adf_stationarity_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_cols</th>\n",
       "      <th>stationary_cols</th>\n",
       "      <th>share_stationary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levels</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h63</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h252</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  n_cols  stationary_cols  share_stationary\n",
       "0  levels       6                0          0.000000\n",
       "1      h1       6                6          1.000000\n",
       "2      h5       6                6          1.000000\n",
       "3     h21       6                1          0.166667\n",
       "4     h63       6                1          0.166667\n",
       "5    h252       6                1          0.166667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run this notebook  to evaluate the stationarity of\n",
    "1. **Yield levels**  – `Y_df.csv`\n",
    "2. **Yield changes** – `Y_df_change_<h>.csv` for horizons 1, 5, 21, 63, 252\n",
    "\n",
    "Outputs (saved automatically in `DATA_DIR`):\n",
    "- `adf_results_levels.csv`\n",
    "- `adf_results_h<1|5|21|63|252>.csv`\n",
    "- `adf_stationarity_summary.csv`\n",
    "\n",
    "All loops are wrapped with **tqdm** progress bars that render nicely in Jupyter Lab/Notebook.  \n",
    "(The ADF test itself is CPU‑bound; GPU is detected only for information.)\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------- Imports ---------------------- #\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm.notebook import tqdm  # Jupyter‑friendly progress bar\n",
    "import torch                    # just for GPU info\n",
    "\n",
    "# ---------------------- Config ---------------------- #\n",
    "DATA_DIR   = Path(\"./\")   # ← change this to your CSV directory if needed\n",
    "HORIZONS   = [1, 5, 21, 63, 252]\n",
    "LAG        = 1            # fixed lag for ADF (speed‑friendly)\n",
    "\n",
    "# ---------------------- Helper ---------------------- #\n",
    "\n",
    "def run_adf(series: pd.Series, max_lag: int = LAG) -> Dict[str, Any]:\n",
    "    \"\"\"Run (fixed‑lag) Augmented Dickey‑Fuller test on a single Series.\"\"\"\n",
    "    series = series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(series) < max_lag + 2:\n",
    "        return {\"statistic\": np.nan, \"pvalue\": np.nan, \"stationary\": False, \"n_obs\": len(series)}\n",
    "    try:\n",
    "        stat, pval, *_ = adfuller(series, maxlag=max_lag, autolag=None)\n",
    "        return {\n",
    "            \"statistic\": stat,\n",
    "            \"pvalue\"   : pval,\n",
    "            \"stationary\": pval < 0.05,\n",
    "            \"n_obs\"    : len(series),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"statistic\": np.nan, \"pvalue\": np.nan, \"stationary\": False, \"n_obs\": len(series), \"error\": str(e)}\n",
    "\n",
    "\n",
    "def adf_dataframe(df: pd.DataFrame, max_lag: int = LAG) -> pd.DataFrame:\n",
    "    \"\"\"Apply ADF across all columns with a progress bar.\"\"\"\n",
    "    results = {}\n",
    "    for col in tqdm(df.columns, desc=\"Columns\", leave=False):\n",
    "        results[col] = run_adf(df[col].astype(float), max_lag)\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# ---------------------- GPU Info (optional) ---------------------- #\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"[INFO] GPU detected → {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"[INFO] Running on CPU (ADF is CPU‑bound).\")\n",
    "\n",
    "# ---------------------- 1. Levels ---------------------- #\n",
    "levels_path = DATA_DIR / \"Y_df.csv\"\n",
    "assert levels_path.exists(), f\"Missing file: {levels_path}\"\n",
    "\n",
    "print(\"\\n[LEVELS] Loading yield level data …\")\n",
    "levels_df = pd.read_csv(levels_path, index_col=0, parse_dates=True)\n",
    "\n",
    "print(\"[LEVELS] Running ADF tests …\")\n",
    "adf_levels = adf_dataframe(levels_df)\n",
    "levels_out = DATA_DIR / \"adf_results_levels.csv\"\n",
    "adf_levels.to_csv(levels_out)\n",
    "print(f\"[LEVELS] Saved → {levels_out.name}\")\n",
    "\n",
    "# summary placeholder\n",
    "summary_rows = [{\n",
    "    \"dataset\"         : \"levels\",\n",
    "    \"n_cols\"          : len(adf_levels),\n",
    "    \"stationary_cols\" : int(adf_levels[\"stationary\"].sum()),\n",
    "}]\n",
    "\n",
    "# ---------------------- 2. Changes ---------------------- #\n",
    "for h in tqdm(HORIZONS, desc=\"Horizons\"):\n",
    "    change_path = DATA_DIR / f\"Y_df_change_{h}.csv\"\n",
    "    if not change_path.exists():\n",
    "        print(f\"[WARN] {change_path.name} not found – skipped.\")\n",
    "        continue\n",
    "    df = pd.read_csv(change_path, index_col=0, parse_dates=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    print(f\"\\n[ΔY] Horizon {h}: running ADF …\")\n",
    "    adf_df = adf_dataframe(df)\n",
    "\n",
    "    out_name = DATA_DIR / f\"adf_results_h{h}.csv\"\n",
    "    adf_df.to_csv(out_name)\n",
    "    print(f\"[ΔY] Horizon {h}: saved → {out_name.name}\")\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"dataset\"         : f\"h{h}\",\n",
    "        \"n_cols\"          : len(adf_df),\n",
    "        \"stationary_cols\" : int(adf_df[\"stationary\"].sum()),\n",
    "    })\n",
    "\n",
    "# ---------------------- 3. Aggregate Summary ---------------------- #\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df[\"share_stationary\"] = summary_df[\"stationary_cols\"] / summary_df[\"n_cols\"]\n",
    "summary_csv = DATA_DIR / \"adf_stationarity_summary.csv\"\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "print(\"\\n✅ Diagnostic complete!\")\n",
    "print(\"Key outputs:\")\n",
    "for f in [levels_out, *[DATA_DIR / f\"adf_results_h{h}.csv\" for h in HORIZONS], summary_csv]:\n",
    "    if f.exists():\n",
    "        print(\" •\", f.name)\n",
    "\n",
    "# ---------------------- 4. Display Summary ---------------------- #\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474bdeb6-fe78-42c2-a1ab-16c3630e51e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GPU detected → NVIDIA GeForce RTX 4090\n",
      "\n",
      "[LEVELS] Loading yield level data …\n",
      "[LEVELS] Running ADF tests …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b318570062744f28fab6fe5db4faee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LEVELS] Saved → adf_results_levels.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8482e3d9874f33b4ff9d5f44452d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Horizons:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ΔY] Horizon 1: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147cca043a7240b2a65c58e2ef25e2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 1: saved → adf_results_h1.csv\n",
      "\n",
      "[ΔY] Horizon 5: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bad5a0b118a4090a22d1c1b5a081627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 5: saved → adf_results_h5.csv\n",
      "\n",
      "[ΔY] Horizon 21: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad92e2c8d1ff4cee9939b2515afb651b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 21: saved → adf_results_h21.csv\n",
      "\n",
      "[ΔY] Horizon 63: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414cfdea6aac41729e530cfc4f1769e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 63: saved → adf_results_h63.csv\n",
      "\n",
      "[ΔY] Horizon 252: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92a34fbc80c499789013e65f94e1b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 252: saved → adf_results_h252.csv\n",
      "\n",
      "✅ Diagnostic complete!\n",
      "Key outputs:\n",
      " • adf_results_levels.csv\n",
      " • adf_results_h1.csv\n",
      " • adf_results_h5.csv\n",
      " • adf_results_h21.csv\n",
      " • adf_results_h63.csv\n",
      " • adf_results_h252.csv\n",
      " • adf_stationarity_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_cols</th>\n",
       "      <th>stationary_cols</th>\n",
       "      <th>share_stationary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levels</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h63</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h252</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  n_cols  stationary_cols  share_stationary\n",
       "0  levels       6                0          0.000000\n",
       "1      h1       6                6          1.000000\n",
       "2      h5       6                6          1.000000\n",
       "3     h21       6                1          0.166667\n",
       "4     h63       6                1          0.166667\n",
       "5    h252       6                1          0.166667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run this notebook  to evaluate the stationarity of\n",
    "1. **Yield levels**  – `Y_df.csv`\n",
    "2. **Yield changes** – `Y_df_change_<h>.csv` for horizons 1, 5, 21, 63, 252\n",
    "\n",
    "Outputs (saved automatically in `DATA_DIR`):\n",
    "- `adf_results_levels.csv`\n",
    "- `adf_results_h<1|5|21|63|252>.csv`\n",
    "- `adf_stationarity_summary.csv`\n",
    "\n",
    "All loops are wrapped with **tqdm** progress bars that render nicely in Jupyter Lab/Notebook.  \n",
    "(The ADF test itself is CPU‑bound; GPU is detected only for information.)\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------- Imports ---------------------- #\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm.notebook import tqdm  # Jupyter‑friendly progress bar\n",
    "import torch                    # just for GPU info\n",
    "\n",
    "# ---------------------- Config ---------------------- #\n",
    "DATA_DIR   = Path(\"./\")   # ← change this to your CSV directory if needed\n",
    "HORIZONS   = [1, 5, 21, 63, 252]\n",
    "LAG        = 8            # fixed lag for ADF (speed‑friendly)\n",
    "\n",
    "# ---------------------- Helper ---------------------- #\n",
    "\n",
    "def run_adf(series: pd.Series, max_lag: int = LAG) -> Dict[str, Any]:\n",
    "    \"\"\"Run (fixed‑lag) Augmented Dickey‑Fuller test on a single Series.\"\"\"\n",
    "    series = series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(series) < max_lag + 2:\n",
    "        return {\"statistic\": np.nan, \"pvalue\": np.nan, \"stationary\": False, \"n_obs\": len(series)}\n",
    "    try:\n",
    "        stat, pval, *_ = adfuller(series, maxlag=max_lag, autolag=None)\n",
    "        return {\n",
    "            \"statistic\": stat,\n",
    "            \"pvalue\"   : pval,\n",
    "            \"stationary\": pval < 0.05,\n",
    "            \"n_obs\"    : len(series),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"statistic\": np.nan, \"pvalue\": np.nan, \"stationary\": False, \"n_obs\": len(series), \"error\": str(e)}\n",
    "\n",
    "\n",
    "def adf_dataframe(df: pd.DataFrame, max_lag: int = LAG) -> pd.DataFrame:\n",
    "    \"\"\"Apply ADF across all columns with a progress bar.\"\"\"\n",
    "    results = {}\n",
    "    for col in tqdm(df.columns, desc=\"Columns\", leave=False):\n",
    "        results[col] = run_adf(df[col].astype(float), max_lag)\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# ---------------------- GPU Info (optional) ---------------------- #\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"[INFO] GPU detected → {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"[INFO] Running on CPU (ADF is CPU‑bound).\")\n",
    "\n",
    "# ---------------------- 1. Levels ---------------------- #\n",
    "levels_path = DATA_DIR / \"Y_df.csv\"\n",
    "assert levels_path.exists(), f\"Missing file: {levels_path}\"\n",
    "\n",
    "print(\"\\n[LEVELS] Loading yield level data …\")\n",
    "levels_df = pd.read_csv(levels_path, index_col=0, parse_dates=True)\n",
    "\n",
    "print(\"[LEVELS] Running ADF tests …\")\n",
    "adf_levels = adf_dataframe(levels_df)\n",
    "levels_out = DATA_DIR / \"adf_results_levels.csv\"\n",
    "adf_levels.to_csv(levels_out)\n",
    "print(f\"[LEVELS] Saved → {levels_out.name}\")\n",
    "\n",
    "# summary placeholder\n",
    "summary_rows = [{\n",
    "    \"dataset\"         : \"levels\",\n",
    "    \"n_cols\"          : len(adf_levels),\n",
    "    \"stationary_cols\" : int(adf_levels[\"stationary\"].sum()),\n",
    "}]\n",
    "\n",
    "# ---------------------- 2. Changes ---------------------- #\n",
    "for h in tqdm(HORIZONS, desc=\"Horizons\"):\n",
    "    change_path = DATA_DIR / f\"Y_df_change_{h}.csv\"\n",
    "    if not change_path.exists():\n",
    "        print(f\"[WARN] {change_path.name} not found – skipped.\")\n",
    "        continue\n",
    "    df = pd.read_csv(change_path, index_col=0, parse_dates=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    print(f\"\\n[ΔY] Horizon {h}: running ADF …\")\n",
    "    adf_df = adf_dataframe(df)\n",
    "\n",
    "    out_name = DATA_DIR / f\"adf_results_h{h}.csv\"\n",
    "    adf_df.to_csv(out_name)\n",
    "    print(f\"[ΔY] Horizon {h}: saved → {out_name.name}\")\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"dataset\"         : f\"h{h}\",\n",
    "        \"n_cols\"          : len(adf_df),\n",
    "        \"stationary_cols\" : int(adf_df[\"stationary\"].sum()),\n",
    "    })\n",
    "\n",
    "# ---------------------- 3. Aggregate Summary ---------------------- #\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df[\"share_stationary\"] = summary_df[\"stationary_cols\"] / summary_df[\"n_cols\"]\n",
    "summary_csv = DATA_DIR / \"adf_stationarity_summary.csv\"\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "print(\"\\n✅ Diagnostic complete!\")\n",
    "print(\"Key outputs:\")\n",
    "for f in [levels_out, *[DATA_DIR / f\"adf_results_h{h}.csv\" for h in HORIZONS], summary_csv]:\n",
    "    if f.exists():\n",
    "        print(\" •\", f.name)\n",
    "\n",
    "# ---------------------- 4. Display Summary ---------------------- #\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435c8eaa-a918-4b36-9cef-d357683a714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Second difference for long horizons ----------\n",
    "for h in [21, 63, 252]:\n",
    "    path = DATA_DIR / f\"Y_df_change_{h}.csv\"\n",
    "    df_long = pd.read_csv(path, index_col=0, parse_dates=True)\n",
    "    df_dd = df_long.diff().dropna()  # Δ²Y\n",
    "    df_dd.to_csv(DATA_DIR / f\"Y_df_change2_{h}.csv\")\n",
    "\n",
    "# ---------- KPSS check (optional) ----------\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "def kpss_test(series):\n",
    "    stat, pval, *_ = kpss(series.dropna(), regression='c', nlags='auto')\n",
    "    return pval > 0.05  # True ⇒ stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d99622-ff32-48be-8e55-9542002b7eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GPU detected → NVIDIA GeForce RTX 4090 (not used for ADF)\n",
      "\n",
      "[LEVELS] Loading yield level data …\n",
      "[LEVELS] Running ADF tests …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45737bad97c044fbb205d83c1ab82d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LEVELS] Saved → adf_results_levels.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989c17c9bd75412688e87199ab11e2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1st-Difference Horizons:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ΔY] Horizon 1: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1871aaf876b4d5e89808110bc0c16e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 1: saved → adf_results_h1.csv\n",
      "\n",
      "[ΔY] Horizon 5: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e22d1303594def814a9ef3b65e9e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 5: saved → adf_results_h5.csv\n",
      "\n",
      "[ΔY] Horizon 21: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5786d19ec624d3484dfdf21a60d84dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 21: saved → adf_results_h21.csv\n",
      "[Δ²Y] Horizon 21: computing second difference …\n",
      "[Δ²Y] Horizon 21: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e381c20545004d92b3cd0c53c0e27d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Δ²Y] Horizon 21: saved → adf_results_h21_d2.csv\n",
      "\n",
      "[ΔY] Horizon 63: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c71652d1103430faa591d9234c521d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 63: saved → adf_results_h63.csv\n",
      "[Δ²Y] Horizon 63: computing second difference …\n",
      "[Δ²Y] Horizon 63: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a787dc3c21f45d0ae2d5040a6f64a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Δ²Y] Horizon 63: saved → adf_results_h63_d2.csv\n",
      "\n",
      "[ΔY] Horizon 252: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6517e712bbc34e91ac8fe7a99f478d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ΔY] Horizon 252: saved → adf_results_h252.csv\n",
      "[Δ²Y] Horizon 252: computing second difference …\n",
      "[Δ²Y] Horizon 252: running ADF …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685ab7ab84ca493dbdda59993d218794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Columns:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Δ²Y] Horizon 252: saved → adf_results_h252_d2.csv\n",
      "\n",
      "✅ Diagnostic complete!\n",
      "Key outputs:\n",
      " • adf_results_levels.csv\n",
      " • adf_results_h1.csv\n",
      " • adf_results_h5.csv\n",
      " • adf_results_h21.csv\n",
      " • adf_results_h63.csv\n",
      " • adf_results_h252.csv\n",
      " • adf_results_h21_d2.csv\n",
      " • adf_results_h63_d2.csv\n",
      " • adf_results_h252_d2.csv\n",
      " • adf_stationarity_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_cols</th>\n",
       "      <th>stationary_cols</th>\n",
       "      <th>share_stationary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>levels</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h21_d2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>h63</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>h63_d2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h252</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>h252_d2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  n_cols  stationary_cols  share_stationary\n",
       "0   levels       6                0          0.000000\n",
       "1       h1       6                6          1.000000\n",
       "2       h5       6                6          1.000000\n",
       "3      h21       6                1          0.166667\n",
       "4   h21_d2       6                6          1.000000\n",
       "5      h63       6                1          0.166667\n",
       "6   h63_d2       6                6          1.000000\n",
       "7     h252       6                1          0.166667\n",
       "8  h252_d2       6                6          1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================\n",
    "# Stationarity Diagnostic (Notebook Edition)\n",
    "# =============================================\n",
    "# Author: ChatGPT (generated for Barak)\n",
    "# Date: 2025-05-13 (rev. Δ² check)\n",
    "\"\"\"\n",
    "Run this notebook cell-by-cell to evaluate the stationarity of\n",
    "1. **Yield levels**  – `Y_df.csv`\n",
    "2. **Yield 1st-differences** – `Y_df_change_<h>.csv` where h ∈ {1, 5, 21, 63, 252}\n",
    "3. **Yield 2nd-differences** (only for horizons 21, 63, 252) – generated on-the-fly and saved as `Y_df_change2_<h>.csv`\n",
    "\n",
    "Outputs saved in `DATA_DIR`:\n",
    "- `adf_results_levels.csv`\n",
    "- `adf_results_h<1|5|21|63|252>.csv`                (1st-diff)\n",
    "- `adf_results_h<21|63|252>_d2.csv`                 (2nd-diff)\n",
    "- `adf_stationarity_summary.csv`                    (overall summary)\n",
    "\n",
    "Progress bars (`tqdm.notebook`) render nicely in Jupyter. The ADF test itself is CPU-bound; GPU detection is for info only.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------- Imports ---------------------- #\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm.notebook import tqdm\n",
    "import torch  # GPU info only\n",
    "\n",
    "# ---------------------- Config ---------------------- #\n",
    "DATA_DIR    = Path(\"./\")            # ← adjust to your CSV directory\n",
    "HORIZONS    = [1, 5, 21, 63, 252]\n",
    "LONG_HORIZ  = [21, 63, 252]         # horizons to generate Δ²Y\n",
    "LAG         = 1                     # fixed lag for ADF (speed-friendly)\n",
    "\n",
    "# ---------------------- Helper ---------------------- #\n",
    "\n",
    "def run_adf(series: pd.Series, max_lag: int = LAG) -> Dict[str, Any]:\n",
    "    \"\"\"Run fixed-lag Augmented Dickey-Fuller test on a Series.\"\"\"\n",
    "    series = series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(series) < max_lag + 2:\n",
    "        return {\"statistic\": np.nan, \"pvalue\": np.nan, \"stationary\": False, \"n_obs\": len(series)}\n",
    "    try:\n",
    "        stat, pval, *_ = adfuller(series, maxlag=max_lag, autolag=None)\n",
    "        return {\n",
    "            \"statistic\": stat,\n",
    "            \"pvalue\": pval,\n",
    "            \"stationary\": pval < 0.05,\n",
    "            \"n_obs\": len(series),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"statistic\": np.nan, \"pvalue\": np.nan, \"stationary\": False, \"n_obs\": len(series), \"error\": str(e)}\n",
    "\n",
    "\n",
    "def adf_dataframe(df: pd.DataFrame, max_lag: int = LAG) -> pd.DataFrame:\n",
    "    \"\"\"Apply ADF across all columns with a progress bar.\"\"\"\n",
    "    results = {}\n",
    "    for col in tqdm(df.columns, desc=\"Columns\", leave=False):\n",
    "        results[col] = run_adf(df[col].astype(float), max_lag)\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "# ---------------------- GPU Info ---------------------- #\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"[INFO] GPU detected → {torch.cuda.get_device_name(0)} (not used for ADF)\")\n",
    "else:\n",
    "    print(\"[INFO] Running on CPU (ADF is CPU-bound).\")\n",
    "\n",
    "# ---------------------- 1. Levels ---------------------- #\n",
    "levels_path = DATA_DIR / \"Y_df.csv\"\n",
    "assert levels_path.exists(), f\"Missing file: {levels_path}\"\n",
    "\n",
    "print(\"\\n[LEVELS] Loading yield level data …\")\n",
    "levels_df = pd.read_csv(levels_path, index_col=0, parse_dates=True)\n",
    "print(\"[LEVELS] Running ADF tests …\")\n",
    "adf_levels = adf_dataframe(levels_df)\n",
    "levels_out = DATA_DIR / \"adf_results_levels.csv\"\n",
    "adf_levels.to_csv(levels_out)\n",
    "print(f\"[LEVELS] Saved → {levels_out.name}\")\n",
    "\n",
    "# ------------- summary init ------------- #\n",
    "summary_rows = [{\n",
    "    \"dataset\": \"levels\",\n",
    "    \"n_cols\": len(adf_levels),\n",
    "    \"stationary_cols\": int(adf_levels[\"stationary\"].sum()),\n",
    "}]\n",
    "\n",
    "# ---------------------- 2. First Differences ---------------------- #\n",
    "for h in tqdm(HORIZONS, desc=\"1st-Difference Horizons\"):\n",
    "    change_path = DATA_DIR / f\"Y_df_change_{h}.csv\"\n",
    "    if not change_path.exists():\n",
    "        print(f\"[WARN] {change_path.name} not found – skipped 1st-diff.\")\n",
    "        continue\n",
    "\n",
    "    df_1d = pd.read_csv(change_path, index_col=0, parse_dates=True).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    print(f\"\\n[ΔY] Horizon {h}: running ADF …\")\n",
    "    adf_1d = adf_dataframe(df_1d)\n",
    "    out_1d = DATA_DIR / f\"adf_results_h{h}.csv\"\n",
    "    adf_1d.to_csv(out_1d)\n",
    "    print(f\"[ΔY] Horizon {h}: saved → {out_1d.name}\")\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"dataset\": f\"h{h}\",\n",
    "        \"n_cols\": len(adf_1d),\n",
    "        \"stationary_cols\": int(adf_1d[\"stationary\"].sum()),\n",
    "    })\n",
    "\n",
    "    # ---------- 3. Second Differences for long horizons ---------- #\n",
    "    if h in LONG_HORIZ:\n",
    "        print(f\"[Δ²Y] Horizon {h}: computing second difference …\")\n",
    "        df_2d = df_1d.diff().dropna()\n",
    "        df_2d_path = DATA_DIR / f\"Y_df_change2_{h}.csv\"\n",
    "        df_2d.to_csv(df_2d_path)\n",
    "\n",
    "        print(f\"[Δ²Y] Horizon {h}: running ADF …\")\n",
    "        adf_2d = adf_dataframe(df_2d)\n",
    "        out_2d = DATA_DIR / f\"adf_results_h{h}_d2.csv\"\n",
    "        adf_2d.to_csv(out_2d)\n",
    "        print(f\"[Δ²Y] Horizon {h}: saved → {out_2d.name}\")\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"dataset\": f\"h{h}_d2\",\n",
    "            \"n_cols\": len(adf_2d),\n",
    "            \"stationary_cols\": int(adf_2d[\"stationary\"].sum()),\n",
    "        })\n",
    "\n",
    "# ---------------------- 4. Aggregate Summary ---------------------- #\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df[\"share_stationary\"] = summary_df[\"stationary_cols\"] / summary_df[\"n_cols\"]\n",
    "summary_csv = DATA_DIR / \"adf_stationarity_2_summary.csv\"\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "\n",
    "print(\"\\n✅ Diagnostic complete!\")\n",
    "print(\"Key outputs:\")\n",
    "for f in [levels_out,\n",
    "          *[DATA_DIR / f\"adf_results_h{h}.csv\" for h in HORIZONS],\n",
    "          *[DATA_DIR / f\"adf_results_h{h}_d2.csv\" for h in LONG_HORIZ],\n",
    "          summary_csv]:\n",
    "    if f.exists():\n",
    "        print(\" •\", f.name)\n",
    "\n",
    "# ---------------------- 5. Display Summary ---------------------- #\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd529a-6c11-40b6-97b4-0df460ca7759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
