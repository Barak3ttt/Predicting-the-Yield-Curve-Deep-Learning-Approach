{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3d7190-9c03-4654-89a8-6986aeaad9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.7.0+cu128)\n",
      "Requirement already satisfied: scikit-learn in /venv/main/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: optuna in /venv/main/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /venv/main/lib/python3.12/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /venv/main/lib/python3.12/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /venv/main/lib/python3.12/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /venv/main/lib/python3.12/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /venv/main/lib/python3.12/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /venv/main/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /venv/main/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /venv/main/lib/python3.12/site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /venv/main/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /venv/main/lib/python3.12/site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: PyYAML in /venv/main/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /venv/main/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /venv/main/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas tqdm torch scikit-learn optuna"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ca08370-cf0e-4d95-a40d-d0fe372f3306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T17:41:37.223202Z",
     "start_time": "2025-05-15T17:41:36.082368Z"
    }
   },
   "source": [
    "# lstm_dns_kf_error_regression.py\n",
    "\n",
    "\"\"\"\n",
    "LSTM Regression on DNS_KF Forecast Errors\n",
    "=========================================\n",
    "Forecasts one-step-ahead MAE of Kalman DNS model errors over a rolling LSTM.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------- Imports ---------------------- #\n",
    "import os, ast, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import amp\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# ---------------------- Reproducibility ---------------------- #\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED); np.random.seed(RNG_SEED); torch.manual_seed(RNG_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RNG_SEED)\n",
    "\n",
    "# ---------------------- Device & CuDNN ---------------------- #\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    print(f\"  • GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# ---------------------- Constants ---------------------- #\n",
    "BUSINESS_DAYS_YEAR = 252  # trading days ~1y\n",
    "ROLL_YEARS         = 3    # sequence length in years\n",
    "SEQ_LEN            = BUSINESS_DAYS_YEAR * ROLL_YEARS   # 756\n",
    "VAL_WINDOW         = BUSINESS_DAYS_YEAR * 2            # 504\n",
    "HOLDOUT_WINDOW     = BUSINESS_DAYS_YEAR * 3            # 756\n",
    "EARLY_STOP_PATIENCE= 20\n",
    "\n",
    "# Optuna search‑space\n",
    "HSPACE = {\n",
    "    \"hidden_dim\"   : (32, 192),\n",
    "    \"num_layers\"   : [1, 2, 3],\n",
    "    \"dropout\"      : (0.0, 0.6),\n",
    "    \"learning_rate\": (1e-4, 5e-3),\n",
    "    \"batch_size\"   : [32, 64, 128],\n",
    "    \"epochs\"       : (40, 80),\n",
    "}\n",
    "\n",
    "# ---------------------- Model ---------------------- #\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, in_dim: int, hid: int, layers: int, out_dim: int = 1, drop: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_dim,\n",
    "            hidden_size=hid,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=(drop if layers > 1 else 0.0)\n",
    "        )\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.norm = nn.LayerNorm(hid)\n",
    "        self.fc   = nn.Linear(hid, out_dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(self.norm(self.drop(h_n[-1])))\n",
    "\n",
    "# ---------------------- Data Utilities ---------------------- #\n",
    "\n",
    "def _parse_vec(col: str) -> np.ndarray:\n",
    "    return np.asarray(ast.literal_eval(col), dtype=np.float32)\n",
    "\n",
    "def load_target(horizon: int) -> pd.DataFrame:\n",
    "    path = fr\"C:\\\\Users\\\\azorb\\\\PycharmProjects\\\\Predicting the Yield Curve\\\\Model Fit\\\\Output\\\\DNS_Full_Forecast\\\\dns_kf_total_h{horizon}_full_dataset.csv\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    df = pd.read_csv(path, parse_dates=[\"eval_date\"]).sort_values(\"eval_date\")\n",
    "\n",
    "    true = df[\"true_yields\"].apply(_parse_vec)\n",
    "    pred = df[\"forecast_yields\"].apply(_parse_vec)\n",
    "    errors = pred.subtract(true)\n",
    "\n",
    "    return pd.DataFrame(errors.tolist(),\n",
    "                        index=df[\"eval_date\"],\n",
    "                        columns=[f\"err_{i}\" for i in range(6)])\n",
    "\n",
    "def gen_sequences(X_df: pd.DataFrame, y_ser: pd.Series, seq_len: int = SEQ_LEN):\n",
    "    X_arr = X_df.values.astype(np.float32)\n",
    "    y_arr = y_ser.values.astype(np.float32)\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(seq_len, len(X_df)):\n",
    "        X_seq.append(X_arr[i - seq_len:i])\n",
    "        y_seq.append(y_arr[i])\n",
    "    if len(X_seq) == 0:\n",
    "        return np.empty((0, seq_len, X_df.shape[1]), dtype=np.float32), np.empty((0, 1), dtype=np.float32)\n",
    "    return np.stack(X_seq), np.asarray(y_seq)[:, None]\n",
    "\n",
    "def trim_y_to_X(X_df: pd.DataFrame, y_ser: pd.Series, seq_len: int, horizon: int) -> pd.Series:\n",
    "    x_dates = X_df.index\n",
    "    y_dates = y_ser.index\n",
    "    earliest_predictable_idx = seq_len + horizon - 1\n",
    "    if earliest_predictable_idx >= len(x_dates):\n",
    "        raise ValueError(\"Not enough X data to allow for any predictions at this sequence+horizon.\")\n",
    "\n",
    "    min_y_date = x_dates[earliest_predictable_idx]\n",
    "    max_y_date = x_dates[-1]\n",
    "    valid_y_dates = y_dates[(y_dates >= min_y_date) & (y_dates <= max_y_date)]\n",
    "    return y_ser.loc[valid_y_dates]\n",
    "\n",
    "# ---------------------- Splitting ---------------------- #\n",
    "def create_folds(N, seq_len=756, val_window=504, holdout=756):\n",
    "    trainable = N - holdout\n",
    "    if trainable <= seq_len + val_window:\n",
    "        raise ValueError(\"Not enough data for the requested scheme.\")\n",
    "\n",
    "    initial_train = 504\n",
    "    residue = (trainable - initial_train) % val_window\n",
    "    first_train_end = initial_train + residue\n",
    "\n",
    "    folds = []\n",
    "    i = first_train_end\n",
    "    while i + val_window <= trainable:\n",
    "        folds.append((0, i, i, i + val_window))\n",
    "        i += val_window\n",
    "\n",
    "    holdout_slice = slice(trainable, N)\n",
    "    return folds, holdout_slice\n",
    "\n",
    "# ---------------------- Objective Function ---------------------- #\n",
    "def objective(trial, X_df, y_ser, folds):\n",
    "    params = {\n",
    "        \"hidden_dim\"   : trial.suggest_int(\"hidden_dim\", *HSPACE[\"hidden_dim\"]),\n",
    "        \"num_layers\"   : trial.suggest_categorical(\"num_layers\", HSPACE[\"num_layers\"]),\n",
    "        \"dropout\"      : trial.suggest_float(\"dropout\", *HSPACE[\"dropout\"]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", *HSPACE[\"learning_rate\"], log=True),\n",
    "        \"batch_size\"   : trial.suggest_categorical(\"batch_size\", HSPACE[\"batch_size\"]),\n",
    "        \"epochs\"       : trial.suggest_int(\"epochs\", *HSPACE[\"epochs\"])\n",
    "    }\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_df), index=X_df.index, columns=X_df.columns)\n",
    "\n",
    "    all_preds, all_trues = [], []\n",
    "    for train_start, train_end, val_start, val_end in folds:\n",
    "        X_train, y_train = X_scaled.iloc[train_start:train_end], y_ser.iloc[train_start:train_end]\n",
    "        X_val, y_val     = X_scaled.iloc[val_start:val_end], y_ser.iloc[val_start:val_end]\n",
    "\n",
    "        Xt, yt = gen_sequences(X_train, y_train)\n",
    "        Xv, yv = gen_sequences(X_val, y_val)\n",
    "\n",
    "        if len(Xt) == 0 or len(Xv) == 0:\n",
    "            continue\n",
    "\n",
    "        model = LSTMRegressor(Xt.shape[-1], params[\"hidden_dim\"], params[\"num_layers\"], drop=params[\"dropout\"]).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(Xt), torch.tensor(yt)),\n",
    "                                  batch_size=params[\"batch_size\"], shuffle=True)\n",
    "        best_loss = float(\"inf\")\n",
    "        patience = EARLY_STOP_PATIENCE\n",
    "\n",
    "        for epoch in range(params[\"epochs\"]):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = model(torch.tensor(Xv).to(device)).cpu().numpy()\n",
    "                val_loss = mean_squared_error(yv, val_pred)\n",
    "\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                patience = EARLY_STOP_PATIENCE\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "\n",
    "        all_preds.append(val_pred.flatten())\n",
    "        all_trues.append(yv.flatten())\n",
    "\n",
    "    if not all_preds:\n",
    "        raise ValueError(\"No valid training/validation split produced any predictions.\")\n",
    "\n",
    "    return mean_squared_error(np.concatenate(all_trues), np.concatenate(all_preds))\n",
    "\n",
    "# ---------------------- Main (Notebook-compatible) ---------------------- #\n",
    "def main_notebook(horizon, trials=30, n_jobs=1):\n",
    "    X_df  = pd.read_csv(\"X_df_filtered_shap.csv\", index_col=0, parse_dates=True)\n",
    "    y_df  = load_target(horizon)\n",
    "    y_ser = y_df.mean(axis=1).rename(\"err\")  # Use raw directional error, not absolute\n",
    "    y_ser = trim_y_to_X(X_df, y_ser, seq_len=SEQ_LEN, horizon=horizon)\n",
    "\n",
    "    folds, hold_out = create_folds(len(y_ser))\n",
    "    print(f\"Expanding CV folds: {len(folds)}, hold‑out length: {hold_out.stop - hold_out.start}\")\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=TPESampler(seed=RNG_SEED),\n",
    "                                pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=15))\n",
    "    t0 = time.time()\n",
    "    study.optimize(lambda tr: objective(tr, X_df, y_ser, folds),\n",
    "                   n_trials=trials, n_jobs=n_jobs, show_progress_bar=True)\n",
    "    minutes = (time.time() - t0) / 60\n",
    "\n",
    "    print(\"=== Best trial (CV) ===\")\n",
    "    print(f\"MSE : {study.best_value:.6f}\")\n",
    "    print(\"Params:\")\n",
    "    for k, v in study.best_trial.params.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"Optimisation time: {minutes:.1f} min\")\n",
    "\n",
    "    # Optionally add: train_on_full()\n",
    "\n",
    "main_notebook(1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 19:41:36,383] A new study created in memory with name: no-name-9f5e2578-e1e3-42dc-853d-a86672d13fc5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding CV folds: 6, hold‑out length: 756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-15 19:41:36,881] Trial 0 failed with parameters: {'hidden_dim': 92, 'num_layers': 1, 'dropout': 0.0936111842654619, 'learning_rate': 0.00018408992080552527, 'batch_size': 64, 'epochs': 69} because of the following error: ValueError('No valid training/validation split produced any predictions.').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azorb\\AppData\\Local\\Temp\\ipykernel_253940\\1142337683.py\", line 216, in <lambda>\n",
      "    study.optimize(lambda tr: objective(tr, X_df, y_ser, folds),\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azorb\\AppData\\Local\\Temp\\ipykernel_253940\\1142337683.py\", line 198, in objective\n",
      "    raise ValueError(\"No valid training/validation split produced any predictions.\")\n",
      "ValueError: No valid training/validation split produced any predictions.\n",
      "[W 2025-05-15 19:41:36,887] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No valid training/validation split produced any predictions.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 229\u001B[39m\n\u001B[32m    225\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mOptimisation time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mminutes\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m min\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# Optionally add: train_on_full()\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m229\u001B[39m \u001B[43mmain_notebook\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 216\u001B[39m, in \u001B[36mmain_notebook\u001B[39m\u001B[34m(horizon, trials, n_jobs)\u001B[39m\n\u001B[32m    212\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mminimize\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    213\u001B[39m                             sampler=TPESampler(seed=RNG_SEED),\n\u001B[32m    214\u001B[39m                             pruner=MedianPruner(n_startup_trials=\u001B[32m8\u001B[39m, n_warmup_steps=\u001B[32m15\u001B[39m))\n\u001B[32m    215\u001B[39m t0 = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtr\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_ser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[43m               \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m minutes = (time.time() - t0) / \u001B[32m60\u001B[39m\n\u001B[32m    220\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== Best trial (CV) ===\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    374\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    375\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    382\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    383\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    385\u001B[39m \n\u001B[32m    386\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    473\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    474\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m475\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     frozen_trial = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    241\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    243\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    244\u001B[39m     frozen_trial.state == TrialState.FAIL\n\u001B[32m    245\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    246\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    247\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m248\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    196\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    198\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    199\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    200\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 216\u001B[39m, in \u001B[36mmain_notebook.<locals>.<lambda>\u001B[39m\u001B[34m(tr)\u001B[39m\n\u001B[32m    212\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mminimize\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    213\u001B[39m                             sampler=TPESampler(seed=RNG_SEED),\n\u001B[32m    214\u001B[39m                             pruner=MedianPruner(n_startup_trials=\u001B[32m8\u001B[39m, n_warmup_steps=\u001B[32m15\u001B[39m))\n\u001B[32m    215\u001B[39m t0 = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m study.optimize(\u001B[38;5;28;01mlambda\u001B[39;00m tr: \u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_ser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    217\u001B[39m                n_trials=trials, n_jobs=n_jobs, show_progress_bar=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    218\u001B[39m minutes = (time.time() - t0) / \u001B[32m60\u001B[39m\n\u001B[32m    220\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== Best trial (CV) ===\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 198\u001B[39m, in \u001B[36mobjective\u001B[39m\u001B[34m(trial, X_df, y_ser, folds)\u001B[39m\n\u001B[32m    195\u001B[39m     all_trues.append(yv.flatten())\n\u001B[32m    197\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m all_preds:\n\u001B[32m--> \u001B[39m\u001B[32m198\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo valid training/validation split produced any predictions.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    200\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m mean_squared_error(np.concatenate(all_trues), np.concatenate(all_preds))\n",
      "\u001B[31mValueError\u001B[39m: No valid training/validation split produced any predictions."
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "6c6602ba26d7984b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:51:26.183799Z",
     "start_time": "2025-05-15T16:51:25.580805Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 18:51:25,841] A new study created in memory with name: no-name-799123d5-d0de-4e7f-93f3-1443279853f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding CV folds: 6, hold‑out length: 756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-15 18:51:25,854] Trial 0 failed with parameters: {'hidden_dim': 92, 'num_layers': 1, 'dropout': 0.0936111842654619, 'learning_rate': 0.00018408992080552527, 'batch_size': 64, 'epochs': 69} because of the following error: ValueError('need at least one array to stack').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azorb\\AppData\\Local\\Temp\\ipykernel_253940\\2407196840.py\", line 149, in <lambda>\n",
      "    study.optimize(lambda tr: objective(tr, X_df, y_ser, folds),\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azorb\\AppData\\Local\\Temp\\ipykernel_253940\\4097518514.py\", line 229, in objective\n",
      "    Xv, yv = gen_sequences(X_va_s, y_va)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azorb\\AppData\\Local\\Temp\\ipykernel_253940\\2407196840.py\", line 102, in gen_sequences\n",
      "    return np.stack(X_seq), np.asarray(y_seq)[:, None]\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\numpy\\_core\\shape_base.py\", line 456, in stack\n",
      "    raise ValueError('need at least one array to stack')\n",
      "ValueError: need at least one array to stack\n",
      "[W 2025-05-15 18:51:25,859] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmain_notebook\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 149\u001B[39m, in \u001B[36mmain_notebook\u001B[39m\u001B[34m(horizon, trials, n_jobs)\u001B[39m\n\u001B[32m    145\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mminimize\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    146\u001B[39m                             sampler=TPESampler(seed=RNG_SEED),\n\u001B[32m    147\u001B[39m                             pruner=MedianPruner(n_startup_trials=\u001B[32m8\u001B[39m, n_warmup_steps=\u001B[32m15\u001B[39m))\n\u001B[32m    148\u001B[39m t0 = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m149\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtr\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_ser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    150\u001B[39m \u001B[43m               \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m minutes = (time.time() - t0) / \u001B[32m60\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== Best trial (CV) ===\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    374\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    375\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    382\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    383\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    385\u001B[39m \n\u001B[32m    386\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    473\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    474\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m475\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     frozen_trial = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    241\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    243\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    244\u001B[39m     frozen_trial.state == TrialState.FAIL\n\u001B[32m    245\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    246\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    247\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m248\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    196\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    198\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    199\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    200\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 149\u001B[39m, in \u001B[36mmain_notebook.<locals>.<lambda>\u001B[39m\u001B[34m(tr)\u001B[39m\n\u001B[32m    145\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mminimize\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    146\u001B[39m                             sampler=TPESampler(seed=RNG_SEED),\n\u001B[32m    147\u001B[39m                             pruner=MedianPruner(n_startup_trials=\u001B[32m8\u001B[39m, n_warmup_steps=\u001B[32m15\u001B[39m))\n\u001B[32m    148\u001B[39m t0 = time.time()\n\u001B[32m--> \u001B[39m\u001B[32m149\u001B[39m study.optimize(\u001B[38;5;28;01mlambda\u001B[39;00m tr: \u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_ser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    150\u001B[39m                n_trials=trials, n_jobs=n_jobs, show_progress_bar=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    151\u001B[39m minutes = (time.time() - t0) / \u001B[32m60\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=== Best trial (CV) ===\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 229\u001B[39m, in \u001B[36mobjective\u001B[39m\u001B[34m(trial, X_df, y_ser, folds)\u001B[39m\n\u001B[32m    226\u001B[39m X_va_s = pd.DataFrame(sc.transform(X_va),   index=X_va.index, columns=X_va.columns)\n\u001B[32m    228\u001B[39m Xt, yt = gen_sequences(X_tr_s, y_tr)\n\u001B[32m--> \u001B[39m\u001B[32m229\u001B[39m Xv, yv = \u001B[43mgen_sequences\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_va_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_va\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    230\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m Xt.size == \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m Xv.size == \u001B[32m0\u001B[39m:\n\u001B[32m    231\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 102\u001B[39m, in \u001B[36mgen_sequences\u001B[39m\u001B[34m(X_df, y_ser, seq_len)\u001B[39m\n\u001B[32m    100\u001B[39m     X_seq.append(X_arr[i - seq_len:i])\n\u001B[32m    101\u001B[39m     y_seq.append(y_arr[i])\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_seq\u001B[49m\u001B[43m)\u001B[49m, np.asarray(y_seq)[:, \u001B[38;5;28;01mNone\u001B[39;00m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\numpy\\_core\\shape_base.py:456\u001B[39m, in \u001B[36mstack\u001B[39m\u001B[34m(arrays, axis, out, dtype, casting)\u001B[39m\n\u001B[32m    454\u001B[39m arrays = [asanyarray(arr) \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[32m    455\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m arrays:\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mneed at least one array to stack\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    458\u001B[39m shapes = {arr.shape \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays}\n\u001B[32m    459\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shapes) != \u001B[32m1\u001B[39m:\n",
      "\u001B[31mValueError\u001B[39m: need at least one array to stack"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "d60910e4-840e-456f-a3fc-13c8588ac2e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:00.769207Z",
     "start_time": "2025-05-15T16:24:00.591023Z"
    }
   },
   "source": [
    "X_df  = pd.read_csv(r\"C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\Data Processing\\Output\\Independent\\X_df_filtered_shap.csv\", index_col=0, parse_dates=True)\n",
    "y_ser = load_target(horizon)\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "c1387094-1607-47e1-b428-ad7a888f9d11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:02.159336Z",
     "start_time": "2025-05-15T16:24:02.141030Z"
    }
   },
   "source": [
    "X_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            RX1  Index  .EURGBP02 U Index  HSI  Index  GJTB3MO  Index  \\\n",
       "2004-09-13       430.0           -1.99750    13139.57          0.0090   \n",
       "2004-09-14       445.0           -2.00100    13148.06          0.0080   \n",
       "2004-09-15       451.0           -2.00150    13084.40          0.0080   \n",
       "2004-09-16       451.0           -2.07000    13209.84          0.0080   \n",
       "2004-09-17       451.0           -2.07650    13224.93          0.0080   \n",
       "...                ...                ...         ...             ...   \n",
       "2025-02-27       579.0           -2.02400    23718.29          0.3000   \n",
       "2025-02-28       579.0           -2.03600    22941.32          0.3300   \n",
       "2025-03-03       579.0           -2.03700    23006.27          0.3353   \n",
       "2025-03-04       579.0           -2.02800    22941.77          0.3403   \n",
       "2025-03-05       579.0           -1.94245    23594.21          0.3451   \n",
       "\n",
       "            SX7E  Index  Y_df_change_dir_63_US_6m  EUR009M  Index    CS  \\\n",
       "2004-09-13       260.92                         1           2.302  1.34   \n",
       "2004-09-14       261.07                         1           2.298  1.34   \n",
       "2004-09-15       261.01                         1           2.289  1.33   \n",
       "2004-09-16       261.88                         1           2.304  1.35   \n",
       "2004-09-17       263.87                         1           2.288  1.33   \n",
       "...                 ...                       ...             ...   ...   \n",
       "2025-02-27       184.49                         0          -0.194  0.92   \n",
       "2025-02-28       184.23                         0          -0.194  0.97   \n",
       "2025-03-03       187.20                         0          -0.194  1.00   \n",
       "2025-03-04       179.59                         0          -0.194  1.00   \n",
       "2025-03-05       188.87                         0          -0.194  0.95   \n",
       "\n",
       "            NG1  Index  Y_df_change_dir_252_US_5y  ...  EUDR1T  Index  \\\n",
       "2004-09-13       4.850                          1  ...         2.0375   \n",
       "2004-09-14       4.928                          1  ...         2.0375   \n",
       "2004-09-15       4.824                          1  ...         2.0375   \n",
       "2004-09-16       4.719                          1  ...         2.0475   \n",
       "2004-09-17       5.108                          1  ...         2.0375   \n",
       "...                ...                        ...  ...            ...   \n",
       "2025-02-27       3.934                          0  ...         2.6500   \n",
       "2025-02-28       3.834                          0  ...         2.7202   \n",
       "2025-03-03       4.122                          0  ...         2.7200   \n",
       "2025-03-04       4.350                          0  ...         2.6974   \n",
       "2025-03-05       4.450                          0  ...         2.6800   \n",
       "\n",
       "            LEI CHNG  Index  .EUR1030Y U Index  Y_df_change_dir_21_US_5y  \\\n",
       "2004-09-13              0.6            -0.8056                         0   \n",
       "2004-09-14              0.6            -0.8091                         0   \n",
       "2004-09-15              0.6            -0.7951                         0   \n",
       "2004-09-16              0.6            -0.8012                         0   \n",
       "2004-09-17              0.6            -0.8031                         0   \n",
       "...                     ...                ...                       ...   \n",
       "2025-02-27             -0.2            -0.2711                         0   \n",
       "2025-02-28             -0.2            -0.2812                         0   \n",
       "2025-03-03             -0.2            -0.2942                         0   \n",
       "2025-03-04             -0.2            -0.2934                         0   \n",
       "2025-03-05             -0.2            -0.2934                         0   \n",
       "\n",
       "            Y_df_change_dir_252_US_3y  ER3  Index  USURTOT  Index  \\\n",
       "2004-09-13                          1         185             5.4   \n",
       "2004-09-14                          1         185             5.4   \n",
       "2004-09-15                          1         185             5.4   \n",
       "2004-09-16                          1         185             5.4   \n",
       "2004-09-17                          1         185             5.4   \n",
       "...                               ...         ...             ...   \n",
       "2025-02-27                          0         564             4.0   \n",
       "2025-02-28                          0         564             4.1   \n",
       "2025-03-03                          0         564             4.1   \n",
       "2025-03-04                          0         564             4.1   \n",
       "2025-03-05                          0         564             4.1   \n",
       "\n",
       "            Y_df_change_dir_21_US_3m  INF   BULL  \n",
       "2004-09-13                         1  2.7  50.50  \n",
       "2004-09-14                         1  2.7  50.50  \n",
       "2004-09-15                         1  2.7  50.50  \n",
       "2004-09-16                         1  2.7  45.50  \n",
       "2004-09-17                         1  2.7  45.50  \n",
       "...                              ...  ...    ...  \n",
       "2025-02-27                         1  3.0  19.38  \n",
       "2025-02-28                         1  3.0  19.38  \n",
       "2025-03-03                         1  3.0  19.38  \n",
       "2025-03-04                         0  3.0  19.38  \n",
       "2025-03-05                         1  3.0  19.38  \n",
       "\n",
       "[5336 rows x 50 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RX1  Index</th>\n",
       "      <th>.EURGBP02 U Index</th>\n",
       "      <th>HSI  Index</th>\n",
       "      <th>GJTB3MO  Index</th>\n",
       "      <th>SX7E  Index</th>\n",
       "      <th>Y_df_change_dir_63_US_6m</th>\n",
       "      <th>EUR009M  Index</th>\n",
       "      <th>CS</th>\n",
       "      <th>NG1  Index</th>\n",
       "      <th>Y_df_change_dir_252_US_5y</th>\n",
       "      <th>...</th>\n",
       "      <th>EUDR1T  Index</th>\n",
       "      <th>LEI CHNG  Index</th>\n",
       "      <th>.EUR1030Y U Index</th>\n",
       "      <th>Y_df_change_dir_21_US_5y</th>\n",
       "      <th>Y_df_change_dir_252_US_3y</th>\n",
       "      <th>ER3  Index</th>\n",
       "      <th>USURTOT  Index</th>\n",
       "      <th>Y_df_change_dir_21_US_3m</th>\n",
       "      <th>INF</th>\n",
       "      <th>BULL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-13</th>\n",
       "      <td>430.0</td>\n",
       "      <td>-1.99750</td>\n",
       "      <td>13139.57</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>260.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2.302</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.850</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0375</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.8056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>50.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-14</th>\n",
       "      <td>445.0</td>\n",
       "      <td>-2.00100</td>\n",
       "      <td>13148.06</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>261.07</td>\n",
       "      <td>1</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.34</td>\n",
       "      <td>4.928</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0375</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.8091</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>50.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-15</th>\n",
       "      <td>451.0</td>\n",
       "      <td>-2.00150</td>\n",
       "      <td>13084.40</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>261.01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.289</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.824</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0375</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.7951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>50.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-16</th>\n",
       "      <td>451.0</td>\n",
       "      <td>-2.07000</td>\n",
       "      <td>13209.84</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>261.88</td>\n",
       "      <td>1</td>\n",
       "      <td>2.304</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.719</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0475</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.8012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>45.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-17</th>\n",
       "      <td>451.0</td>\n",
       "      <td>-2.07650</td>\n",
       "      <td>13224.93</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>263.87</td>\n",
       "      <td>1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>1.33</td>\n",
       "      <td>5.108</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0375</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.8031</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>45.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-27</th>\n",
       "      <td>579.0</td>\n",
       "      <td>-2.02400</td>\n",
       "      <td>23718.29</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>184.49</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.934</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6500</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-28</th>\n",
       "      <td>579.0</td>\n",
       "      <td>-2.03600</td>\n",
       "      <td>22941.32</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>184.23</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.97</td>\n",
       "      <td>3.834</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7202</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03</th>\n",
       "      <td>579.0</td>\n",
       "      <td>-2.03700</td>\n",
       "      <td>23006.27</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>187.20</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.122</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7200</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2942</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-04</th>\n",
       "      <td>579.0</td>\n",
       "      <td>-2.02800</td>\n",
       "      <td>22941.77</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>179.59</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.350</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6974</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05</th>\n",
       "      <td>579.0</td>\n",
       "      <td>-1.94245</td>\n",
       "      <td>23594.21</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>188.87</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.450</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6800</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>564</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5336 rows × 50 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "c6d2d046-9a10-422e-bfe7-8c4913d55a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:04.376478Z",
     "start_time": "2025-05-15T16:24:04.365401Z"
    }
   },
   "source": [
    "y_ser"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               err_0     err_1     err_2     err_3     err_4     err_5\n",
       "eval_date                                                             \n",
       "2006-08-21  0.037889 -0.074640 -0.033638  0.106929  0.090232  0.046057\n",
       "2006-08-22  0.055971 -0.060338 -0.035661  0.090449  0.068072  0.020281\n",
       "2006-08-23  0.068861 -0.060926 -0.041979  0.051814  0.045365 -0.003775\n",
       "2006-08-24  0.069610 -0.061383 -0.044437  0.054951  0.026934 -0.002941\n",
       "2006-08-25  0.051137 -0.049746 -0.032708  0.066100  0.047075  0.015302\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "2025-02-27 -0.055035 -0.059044  0.027544  0.048352  0.070113  0.046477\n",
       "2025-02-28 -0.047761 -0.028886  0.065750  0.068886  0.079419  0.038070\n",
       "2025-03-03 -0.053037 -0.067601  0.101380  0.132421  0.139024  0.116499\n",
       "2025-03-04 -0.063268 -0.062399  0.089305  0.076784  0.051101  0.012029\n",
       "2025-03-05 -0.056958 -0.074657  0.062837 -0.031056 -0.067977 -0.102444\n",
       "\n",
       "[4838 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_0</th>\n",
       "      <th>err_1</th>\n",
       "      <th>err_2</th>\n",
       "      <th>err_3</th>\n",
       "      <th>err_4</th>\n",
       "      <th>err_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-08-21</th>\n",
       "      <td>0.037889</td>\n",
       "      <td>-0.074640</td>\n",
       "      <td>-0.033638</td>\n",
       "      <td>0.106929</td>\n",
       "      <td>0.090232</td>\n",
       "      <td>0.046057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-22</th>\n",
       "      <td>0.055971</td>\n",
       "      <td>-0.060338</td>\n",
       "      <td>-0.035661</td>\n",
       "      <td>0.090449</td>\n",
       "      <td>0.068072</td>\n",
       "      <td>0.020281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-23</th>\n",
       "      <td>0.068861</td>\n",
       "      <td>-0.060926</td>\n",
       "      <td>-0.041979</td>\n",
       "      <td>0.051814</td>\n",
       "      <td>0.045365</td>\n",
       "      <td>-0.003775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-24</th>\n",
       "      <td>0.069610</td>\n",
       "      <td>-0.061383</td>\n",
       "      <td>-0.044437</td>\n",
       "      <td>0.054951</td>\n",
       "      <td>0.026934</td>\n",
       "      <td>-0.002941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-25</th>\n",
       "      <td>0.051137</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>-0.032708</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.047075</td>\n",
       "      <td>0.015302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-27</th>\n",
       "      <td>-0.055035</td>\n",
       "      <td>-0.059044</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>0.048352</td>\n",
       "      <td>0.070113</td>\n",
       "      <td>0.046477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-28</th>\n",
       "      <td>-0.047761</td>\n",
       "      <td>-0.028886</td>\n",
       "      <td>0.065750</td>\n",
       "      <td>0.068886</td>\n",
       "      <td>0.079419</td>\n",
       "      <td>0.038070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03</th>\n",
       "      <td>-0.053037</td>\n",
       "      <td>-0.067601</td>\n",
       "      <td>0.101380</td>\n",
       "      <td>0.132421</td>\n",
       "      <td>0.139024</td>\n",
       "      <td>0.116499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-04</th>\n",
       "      <td>-0.063268</td>\n",
       "      <td>-0.062399</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.076784</td>\n",
       "      <td>0.051101</td>\n",
       "      <td>0.012029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05</th>\n",
       "      <td>-0.056958</td>\n",
       "      <td>-0.074657</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>-0.067977</td>\n",
       "      <td>-0.102444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4838 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:06.469164Z",
     "start_time": "2025-05-15T16:24:06.463350Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "55ed0d5853447b6f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:24:10.257834Z",
     "start_time": "2025-05-15T16:24:10.247400Z"
    }
   },
   "cell_type": "code",
   "source": "y_ser",
   "id": "8f6a078ad13b1f49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               err_0     err_1     err_2     err_3     err_4     err_5\n",
       "eval_date                                                             \n",
       "2007-08-07 -0.037180 -0.147252 -0.115564  0.001923 -0.041472 -0.087331\n",
       "2007-08-08 -0.033905 -0.167879 -0.162297 -0.095216 -0.139183 -0.159733\n",
       "2007-08-09  0.178331  0.053061  0.056316  0.096766  0.028895 -0.056236\n",
       "2007-08-10  0.462340  0.160074  0.158193  0.158394  0.083001 -0.012737\n",
       "2007-08-13  0.156232 -0.071388 -0.024745  0.081188  0.022104 -0.043261\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "2025-02-27 -0.055035 -0.059044  0.027544  0.048352  0.070113  0.046477\n",
       "2025-02-28 -0.047761 -0.028886  0.065750  0.068886  0.079419  0.038070\n",
       "2025-03-03 -0.053037 -0.067601  0.101380  0.132421  0.139024  0.116499\n",
       "2025-03-04 -0.063268 -0.062399  0.089305  0.076784  0.051101  0.012029\n",
       "2025-03-05 -0.056958 -0.074657  0.062837 -0.031056 -0.067977 -0.102444\n",
       "\n",
       "[4587 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_0</th>\n",
       "      <th>err_1</th>\n",
       "      <th>err_2</th>\n",
       "      <th>err_3</th>\n",
       "      <th>err_4</th>\n",
       "      <th>err_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-08-07</th>\n",
       "      <td>-0.037180</td>\n",
       "      <td>-0.147252</td>\n",
       "      <td>-0.115564</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>-0.041472</td>\n",
       "      <td>-0.087331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-08</th>\n",
       "      <td>-0.033905</td>\n",
       "      <td>-0.167879</td>\n",
       "      <td>-0.162297</td>\n",
       "      <td>-0.095216</td>\n",
       "      <td>-0.139183</td>\n",
       "      <td>-0.159733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-09</th>\n",
       "      <td>0.178331</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.056316</td>\n",
       "      <td>0.096766</td>\n",
       "      <td>0.028895</td>\n",
       "      <td>-0.056236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-10</th>\n",
       "      <td>0.462340</td>\n",
       "      <td>0.160074</td>\n",
       "      <td>0.158193</td>\n",
       "      <td>0.158394</td>\n",
       "      <td>0.083001</td>\n",
       "      <td>-0.012737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-13</th>\n",
       "      <td>0.156232</td>\n",
       "      <td>-0.071388</td>\n",
       "      <td>-0.024745</td>\n",
       "      <td>0.081188</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>-0.043261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-27</th>\n",
       "      <td>-0.055035</td>\n",
       "      <td>-0.059044</td>\n",
       "      <td>0.027544</td>\n",
       "      <td>0.048352</td>\n",
       "      <td>0.070113</td>\n",
       "      <td>0.046477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-28</th>\n",
       "      <td>-0.047761</td>\n",
       "      <td>-0.028886</td>\n",
       "      <td>0.065750</td>\n",
       "      <td>0.068886</td>\n",
       "      <td>0.079419</td>\n",
       "      <td>0.038070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03</th>\n",
       "      <td>-0.053037</td>\n",
       "      <td>-0.067601</td>\n",
       "      <td>0.101380</td>\n",
       "      <td>0.132421</td>\n",
       "      <td>0.139024</td>\n",
       "      <td>0.116499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-04</th>\n",
       "      <td>-0.063268</td>\n",
       "      <td>-0.062399</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.076784</td>\n",
       "      <td>0.051101</td>\n",
       "      <td>0.012029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05</th>\n",
       "      <td>-0.056958</td>\n",
       "      <td>-0.074657</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>-0.067977</td>\n",
       "      <td>-0.102444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4587 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "58b79c22586fced4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T17:39:00.295783Z",
     "start_time": "2025-05-15T17:39:00.048167Z"
    }
   },
   "source": [
    "# ---------------------------------------------------------\n",
    "# DEBUG: inspect expanding-CV fold boundaries for any horizon\n",
    "# ---------------------------------------------------------\n",
    "# --- adjust this line to the horizon you want to inspect ---\n",
    "horizon = 5     # choose from 1, 5, 21, 63, 252\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# load features & target (MAE from DNS_KF forecast errors)\n",
    "X_df  = pd.read_csv(r\"C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\Data Processing\\Output\\Independent\\X_df_filtered_shap.csv\", index_col=0, parse_dates=True)\n",
    "y_ser = load_target(horizon)\n",
    "\n",
    "# Trim y_ser so that LSTM can always construct a sequence ending at y_t - horizon\n",
    "y_ser = trim_y_to_X(X_df, y_ser, seq_len=SEQ_LEN, horizon=horizon)\n",
    "\n",
    "# build folds + hold-out\n",
    "folds, hold_slice = create_folds(len(y_ser))\n",
    "\n",
    "date_index = y_ser.index  # convenience alias\n",
    "\n",
    "print(f\"\\n=== Horizon h={horizon}  |  Total aligned obs.: {len(y_ser):,} ===\")\n",
    "for i, (tr_s, tr_e, va_s, va_e) in enumerate(folds, 1):\n",
    "    print(f\"\\nFold {i}\")\n",
    "    print(f\"  Train : {date_index[tr_s]}  →  {date_index[tr_e-1]}   \"\n",
    "          f\"(n={tr_e-tr_s})\")\n",
    "    print(f\"  Val   : {date_index[va_s]}  →  {date_index[va_e-1]}   \"\n",
    "          f\"(n={va_e-va_s})\")\n",
    "\n",
    "print(\"\\nHold-out\")\n",
    "print(f\"  Test  : {date_index[hold_slice.start]}  →  \"\n",
    "      f\"{date_index[hold_slice.stop-1]}   \"\n",
    "      f\"(n={hold_slice.stop - hold_slice.start})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Horizon h=5  |  Total aligned obs.: 4,583 ===\n",
      "\n",
      "Fold 1\n",
      "  Train : 2007-08-13 00:00:00  →  2010-09-08 00:00:00   (n=803)\n",
      "  Val   : 2010-09-09 00:00:00  →  2012-08-14 00:00:00   (n=504)\n",
      "\n",
      "Fold 2\n",
      "  Train : 2007-08-13 00:00:00  →  2012-08-14 00:00:00   (n=1307)\n",
      "  Val   : 2012-08-15 00:00:00  →  2014-07-21 00:00:00   (n=504)\n",
      "\n",
      "Fold 3\n",
      "  Train : 2007-08-13 00:00:00  →  2014-07-21 00:00:00   (n=1811)\n",
      "  Val   : 2014-07-22 00:00:00  →  2016-06-24 00:00:00   (n=504)\n",
      "\n",
      "Fold 4\n",
      "  Train : 2007-08-13 00:00:00  →  2016-06-24 00:00:00   (n=2315)\n",
      "  Val   : 2016-06-27 00:00:00  →  2018-05-31 00:00:00   (n=504)\n",
      "\n",
      "Fold 5\n",
      "  Train : 2007-08-13 00:00:00  →  2018-05-31 00:00:00   (n=2819)\n",
      "  Val   : 2018-06-01 00:00:00  →  2020-05-06 00:00:00   (n=504)\n",
      "\n",
      "Fold 6\n",
      "  Train : 2007-08-13 00:00:00  →  2020-05-06 00:00:00   (n=3323)\n",
      "  Val   : 2020-05-07 00:00:00  →  2022-04-12 00:00:00   (n=504)\n",
      "\n",
      "Hold-out\n",
      "  Test  : 2022-04-13 00:00:00  →  2025-03-05 00:00:00   (n=756)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117aefa0-6fe3-404a-a5d4-c8f067249a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.018671\n",
      "Params: {'hidden_dim': 156, 'num_layers': 3, 'dropout': 0.4241144063085703, 'learning_rate': 0.001732053535845956, 'batch_size': 32, 'epochs': 44}\n",
      "Total run time: 6340.3 s\n"
     ]
    }
   ],
   "source": [
    "    print(f\"MSE   : {study.best_value:.6f}\")\n",
    "    print(f\"Params: {study.best_trial.params}\")\n",
    "    print(f\"Total run time: {dur:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a511d1-e5c8-4b4a-a9d4-5c23dd3af05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
