{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3d7190-9c03-4654-89a8-6986aeaad9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (2.1.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.9/89.9 kB\u001B[0m \u001B[31m2.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.7.0+cu128)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /venv/main/lib/python3.12/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /venv/main/lib/python3.12/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /venv/main/lib/python3.12/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /venv/main/lib/python3.12/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /venv/main/lib/python3.12/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /venv/main/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /venv/main/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.0/62.0 kB\u001B[0m \u001B[31m10.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: PyYAML in /venv/main/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.7/12.7 MB\u001B[0m \u001B[31m17.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m35.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m386.6/386.6 kB\u001B[0m \u001B[31m56.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m231.9/231.9 kB\u001B[0m \u001B[31m42.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m307.7/307.7 kB\u001B[0m \u001B[31m49.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m509.2/509.2 kB\u001B[0m \u001B[31m64.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m37.3/37.3 MB\u001B[0m \u001B[31m91.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hDownloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m115.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m347.8/347.8 kB\u001B[0m \u001B[31m60.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m603.9/603.9 kB\u001B[0m \u001B[31m68.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m17.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: pytz, tzdata, threadpoolctl, scipy, Mako, joblib, greenlet, colorlog, sqlalchemy, scikit-learn, pandas, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 greenlet-3.2.2 joblib-1.5.0 optuna-4.3.0 pandas-2.2.3 pytz-2025.2 scikit-learn-1.6.1 scipy-1.15.3 sqlalchemy-2.0.40 threadpoolctl-3.6.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas tqdm torch scikit-learn optuna"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ca08370-cf0e-4d95-a40d-d0fe372f3306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T08:58:29.457521Z",
     "start_time": "2025-05-16T08:58:27.714738Z"
    }
   },
   "source": [
    "# ==============================================================\n",
    "#  LSTM Regression on DNS_KF Forecast Errors\n",
    "#  --------------------------------------------------------------\n",
    "#  • Expanding‑window CV (train → val blocks)\n",
    "#  • Rolling look‑back  = 756 b‑days  (3 yrs)\n",
    "#  • Validation block   = 252 b‑days  (≈1 yr)\n",
    "#  • Forecast horizon h = configurable (here default = 1)\n",
    "#  --------------------------------------------------------------\n",
    "#  This file merges the working CV logic from the “second model”\n",
    "#  into the original DNS_KF error‑prediction script.\n",
    "# ==============================================================\n",
    "\n",
    "import os, time, random, ast, gc\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# -------------------------- Repro ----------------------------- #\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED); np.random.seed(RNG_SEED); torch.manual_seed(RNG_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RNG_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"  • GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# --------------------------- Config --------------------------- #\n",
    "BUSINESS_DAYS_YEAR = 252\n",
    "ROLL_YEARS         = 3\n",
    "SEQ_LEN_DEFAULT    = BUSINESS_DAYS_YEAR * ROLL_YEARS   # 756\n",
    "VAL_WINDOW         = BUSINESS_DAYS_YEAR                # 252\n",
    "HOLDOUT_WINDOW     = BUSINESS_DAYS_YEAR * 3            # 756  (≈ 3 yrs)\n",
    "\n",
    "# Forecast‑horizon‑dependent sequence length (map if needed)\n",
    "SEQ_LEN_MAP = {\n",
    "    1: 756,   # 3 yrs\n",
    "    5: 756,\n",
    "    21: 756,\n",
    "    63: 756,\n",
    "    252: 756,\n",
    "}\n",
    "\n",
    "EARLY_STOP_PATIENCE = 20\n",
    "\n",
    "HSPACE = {\n",
    "    \"hidden_dim\":   (32, 192),\n",
    "    \"num_layers\":   [1, 2, 3],\n",
    "    \"dropout\":      (0.0, 0.6),\n",
    "    \"learning_rate\":(1e-4, 5e-3),\n",
    "    \"batch_size\":   [32, 64, 128],\n",
    "    \"epochs\":       (40, 80),\n",
    "}\n",
    "\n",
    "# --------------------------- Model --------------------------- #\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, in_dim:int, hid:int, layers:int, out_dim:int=1, drop:float=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(in_dim, hid, layers, batch_first=True,\n",
    "                            dropout=(drop if layers>1 else 0.0))\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.norm = nn.LayerNorm(hid)\n",
    "        self.fc   = nn.Linear(hid, out_dim, bias=False)\n",
    "    def forward(self, x:torch.Tensor)->torch.Tensor:\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(self.norm(self.drop(h_n[-1])))\n",
    "\n",
    "# --------------------------- Utility Functions --------------------------- #\n",
    "\n",
    "def load_target(horizon: int) -> pd.DataFrame:\n",
    "    path = fr\"dns_kf_total_h{horizon}_full_dataset.csv\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    df = pd.read_csv(path, parse_dates=[\"eval_date\"]).sort_values(\"eval_date\")\n",
    "\n",
    "    true = df[\"true_yields\"].apply(_parse_vec)\n",
    "    pred = df[\"forecast_yields\"].apply(_parse_vec)\n",
    "    errors = pred.subtract(true)\n",
    "\n",
    "    return pd.DataFrame(errors.tolist(),\n",
    "                        index=df[\"eval_date\"],\n",
    "                        columns=[f\"err_{i}\" for i in range(6)])\n",
    "\n",
    "def _parse_vec(col: str) -> np.ndarray:\n",
    "    import ast\n",
    "    return np.asarray(ast.literal_eval(col), dtype=np.float32)\n",
    "\n",
    "# -------------------- Debug Fold Info ------------------------ #\n",
    "\n",
    "def debug_cv_folds(folds):\n",
    "    print(\"\\n[DEBUG] Fold summary:\\n\")\n",
    "    for i, f in enumerate(folds, 1):\n",
    "        print(f\"--- Fold {i} ---\")\n",
    "        print(f\"Train X: {f['X_tr'].index[0].date()} → {f['X_tr'].index[-1].date()} ({len(f['X_tr'])} rows)\")\n",
    "        print(f\"Val   X: {f['X_va'].index[0].date()} → {f['X_va'].index[-1].date()} ({len(f['X_va'])} rows)\")\n",
    "        print(f\"Train Y: {f['Y_tr'].index[0].date()} → {f['Y_tr'].index[-1].date()} ({len(f['Y_tr'])} rows)\")\n",
    "        print(f\"Val   Y: {f['Y_va'].index[0].date()} → {f['Y_va'].index[-1].date()} ({len(f['Y_va'])} rows)\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# --------------------- Sequence Generator ------------------------ #\n",
    "\n",
    "def gen_seq(X_df: pd.DataFrame, Y_fold: pd.Series, seq_len: int, h: int):\n",
    "    \"\"\"Return X_seq, y_seq aligned so that\n",
    "       X[t-seq_len+1 : t]  → y[t+horizon]\n",
    "    \"\"\"\n",
    "    X_arr = X_df.values.astype(np.float32)\n",
    "    idx   = {ts: i for i, ts in enumerate(X_df.index)}\n",
    "\n",
    "    X_seq, Y_seq = [], []\n",
    "    for target_ts in Y_fold.index:\n",
    "        t = idx.get(target_ts)\n",
    "        if t is None:\n",
    "            continue\n",
    "        y_idx = t + h\n",
    "        end   = t + 1\n",
    "        start = end - seq_len\n",
    "        if start < 0 or y_idx >= len(X_arr):\n",
    "            continue\n",
    "        window = X_arr[start:end]\n",
    "        if np.isnan(window).any():\n",
    "            continue\n",
    "        X_seq.append(window)\n",
    "        Y_seq.append(np.float32(Y_fold.iloc[y_idx]))\n",
    "\n",
    "    if not X_seq:\n",
    "        return np.empty((0, seq_len, X_arr.shape[1]), dtype=np.float32), np.empty((0, 1), dtype=np.float32)\n",
    "    return np.stack(X_seq), np.asarray(Y_seq)[:, None]\n",
    "\n",
    "\n",
    "# ----------------------- CV Generator ------------------------ #\n",
    "\n",
    "def make_folds(X: pd.DataFrame, Y: pd.Series, horizon: int):\n",
    "    \"\"\"Expanding‑window folds with correct alignment.\n",
    "       Each fold dict contains X_tr, Y_tr, X_va, Y_va, seq_len.\n",
    "    \"\"\"\n",
    "    seq_len = SEQ_LEN_MAP.get(horizon, SEQ_LEN_DEFAULT)\n",
    "    total   = len(X)\n",
    "\n",
    "    train_y_len   = 252\n",
    "    val_y_len     = 252\n",
    "    holdout_len   = 756\n",
    "\n",
    "    folds = []\n",
    "    min_required = seq_len + horizon + train_y_len\n",
    "    val_start = min_required\n",
    "\n",
    "    while val_start + val_y_len + holdout_len <= total:\n",
    "        # Training set (expanding up to val_start - val_y_len)\n",
    "        y_tr_end   = val_start - val_y_len\n",
    "        y_tr_start = y_tr_end - train_y_len\n",
    "        x_tr_end   = y_tr_end - horizon\n",
    "        x_tr_start = max(0, x_tr_end - seq_len - train_y_len + 1)\n",
    "\n",
    "        # Validation set\n",
    "        y_va_start = y_tr_end\n",
    "        y_va_end   = y_va_start + val_y_len\n",
    "        x_va_end   = y_va_end - horizon\n",
    "        x_va_start = max(0, y_va_start - seq_len - horizon + 1)\n",
    "\n",
    "        if y_tr_start < 0 or x_tr_start < 0:\n",
    "            break\n",
    "\n",
    "        folds.append({\n",
    "            \"X_tr\": X.iloc[x_tr_start:x_tr_end].copy(),\n",
    "            \"Y_tr\": Y.iloc[y_tr_start:y_tr_end].copy(),\n",
    "            \"X_va\": X.iloc[x_va_start:x_va_end].copy(),\n",
    "            \"Y_va\": Y.iloc[y_va_start:y_va_end].copy(),\n",
    "            \"seq_len\": seq_len,\n",
    "        })\n",
    "\n",
    "        val_start += val_y_len\n",
    "        train_y_len += val_y_len\n",
    "\n",
    "    return folds\n",
    "\n",
    "# ---------------------- Debug Printer ------------------------ #\n",
    "\n",
    "def debug_folds(folds:List[dict]):\n",
    "    print(f\"[DEBUG] Created {len(folds)} folds\\n\")\n",
    "    for i,f in enumerate(folds,1):\n",
    "        tr_x, tr_y = len(f[\"X_tr\"]), len(f[\"Y_tr\"])\n",
    "        va_x, va_y = len(f[\"X_va\"]), len(f[\"Y_va\"])\n",
    "        print(f\"--- Fold {i} ---\")\n",
    "        print(f\"Train‑Y rows : {tr_y:4d}   ({f['Y_tr'].index[0].date()} → {f['Y_tr'].index[-1].date()})\")\n",
    "        print(f\"Train‑X rows : {tr_x:4d}   ({f['X_tr'].index[0].date()} → {f['X_tr'].index[-1].date()})\")\n",
    "        print(f\"Val‑Y rows   : {va_y:4d}   ({f['Y_va'].index[0].date()} → {f['Y_va'].index[-1].date()})\")\n",
    "        print(f\"Val‑X rows   : {va_x:4d}   ({f['X_va'].index[0].date()} → {f['X_va'].index[-1].date()})\")\n",
    "        print(\"-\")\n",
    "\n",
    "# -------------------- Optuna Objective ----------------------- #\n",
    "\n",
    "def optuna_objective(trial, folds, horizon):\n",
    "    p = {\n",
    "        \"hid\": trial.suggest_int(\"hidden_dim\", *HSPACE[\"hidden_dim\"]),\n",
    "        \"lay\": trial.suggest_categorical(\"num_layers\", HSPACE[\"num_layers\"]),\n",
    "        \"drp\": trial.suggest_float(\"dropout\", *HSPACE[\"dropout\"]),\n",
    "        \"lr\" : trial.suggest_float(\"learning_rate\", *HSPACE[\"learning_rate\"], log=True),\n",
    "        \"bs\" : trial.suggest_categorical(\"batch_size\", HSPACE[\"batch_size\"]),\n",
    "        \"ep\" : trial.suggest_int(\"epochs\", *HSPACE[\"epochs\"]),\n",
    "    }\n",
    "\n",
    "    fold_mse = []\n",
    "    scaler   = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for fold_idx, f in enumerate(folds, 1):\n",
    "        # Standardise\n",
    "        sc = StandardScaler()\n",
    "        X_tr_s = pd.DataFrame(sc.fit_transform(f[\"X_tr\"]), index=f[\"X_tr\"].index, columns=f[\"X_tr\"].columns)\n",
    "        X_va_s = pd.DataFrame(sc.transform(f[\"X_va\"]),     index=f[\"X_va\"].index, columns=f[\"X_va\"].columns)\n",
    "\n",
    "        # Generate sequences\n",
    "        Xtr, Ytr = gen_seq(X_tr_s, f[\"Y_tr\"], f[\"seq_len\"], horizon)\n",
    "        Xva, Yva = gen_seq(X_va_s, f[\"Y_va\"], f[\"seq_len\"], horizon)\n",
    "        if len(Xtr) == 0 or len(Xva) == 0:\n",
    "            continue\n",
    "\n",
    "        model = LSTMRegressor(Xtr.shape[2], p[\"hid\"], p[\"lay\"], Ytr.shape[1], p[\"drp\"]).to(device)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=p[\"lr\"])\n",
    "        best  = np.inf\n",
    "        patience = 0\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(Xtr), torch.tensor(Ytr)), batch_size=p[\"bs\"], shuffle=True)\n",
    "        va_loader    = DataLoader(TensorDataset(torch.tensor(Xva), torch.tensor(Yva)), batch_size=p[\"bs\"])\n",
    "\n",
    "        for epoch in range(p[\"ep\"]):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                opt.zero_grad()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    pred = model(xb)\n",
    "                    loss = nn.functional.mse_loss(pred, yb)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "\n",
    "            # Evaluation\n",
    "            model.eval()\n",
    "            preds, gts = [], []\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "                for xb, yb in va_loader:\n",
    "                    preds.append(model(xb.to(device)).cpu())\n",
    "                    gts.append(yb)\n",
    "\n",
    "            mse = mean_squared_error(torch.cat(gts).numpy(), torch.cat(preds).numpy())\n",
    "\n",
    "            trial.report(mse, step=epoch)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            if mse < best:\n",
    "                best = mse\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= EARLY_STOP_PATIENCE:\n",
    "                    break\n",
    "\n",
    "        fold_mse.append(best)\n",
    "\n",
    "    return np.mean(fold_mse) if fold_mse else float(\"inf\")\n",
    "\n",
    "# -------------------- Run Experiment ------------------------ #\n",
    "\n",
    "def main_notebook(horizon: int, trials: int = 30, n_jobs: int = 1):\n",
    "    # 1. Load features + target\n",
    "    X_df = pd.read_csv(\"X_df_filtered_shap.csv\", index_col=0, parse_dates=True)\n",
    "    y_df = load_target(horizon)\n",
    "    y_ser = y_df.mean(axis=1).rename(\"err\")  # raw directional error\n",
    "\n",
    "    # 2. Join and clean\n",
    "    X_df = X_df.join(y_df)\n",
    "    X_df.dropna(inplace=True)\n",
    "\n",
    "    # 3. Generate CV folds\n",
    "    folds = make_folds(X_df, y_ser, horizon)\n",
    "    print(f\"Generated {len(folds)} folds\\n\")\n",
    "    debug_cv_folds(folds)\n",
    "\n",
    "    # 4. Run Optuna\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=TPESampler(seed=RNG_SEED),\n",
    "        pruner=MedianPruner(n_startup_trials=8, n_warmup_steps=15)\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    study.optimize(lambda tr: optuna_objective(tr, folds, horizon),\n",
    "                   n_trials=trials, n_jobs=n_jobs, show_progress_bar=True)\n",
    "    duration = time.time() - t0\n",
    "\n",
    "    # 5. Print results\n",
    "    print(\"=== Best Trial ===\")\n",
    "    print(f\"MSE   : {study.best_value:.6f}\")\n",
    "    print(f\"Params: {study.best_trial.params}\")\n",
    "    print(f\"Duration: {duration/60:.1f} min\")"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'fx' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnn\u001B[39;00m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdata\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DataLoader, TensorDataset\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\torch\\__init__.py:2600\u001B[39m\n\u001B[32m   2596\u001B[39m     torch_module_name = \u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m.join([\u001B[34m__name__\u001B[39m, device_type])\n\u001B[32m   2597\u001B[39m     sys.modules[torch_module_name] = module\n\u001B[32m-> \u001B[39m\u001B[32m2600\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m   2601\u001B[39m     export \u001B[38;5;28;01mas\u001B[39;00m export,\n\u001B[32m   2602\u001B[39m     func \u001B[38;5;28;01mas\u001B[39;00m func,\n\u001B[32m   2603\u001B[39m     library \u001B[38;5;28;01mas\u001B[39;00m library,\n\u001B[32m   2604\u001B[39m     return_types \u001B[38;5;28;01mas\u001B[39;00m return_types,\n\u001B[32m   2605\u001B[39m )\n\u001B[32m   2606\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_higher_order_ops\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m cond \u001B[38;5;28;01mas\u001B[39;00m cond, while_loop \u001B[38;5;28;01mas\u001B[39;00m while_loop\n\u001B[32m   2607\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\torch\\func\\__init__.py:3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_functorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapis\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m grad, grad_and_value, vmap\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_functorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbatch_norm_replacement\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m replace_all_batch_norm_modules_\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_functorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01meager_transforms\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      4\u001B[39m     debug_unwrap,\n\u001B[32m      5\u001B[39m     functionalize,\n\u001B[32m      6\u001B[39m     hessian,\n\u001B[32m      7\u001B[39m     jacfwd,\n\u001B[32m      8\u001B[39m     jacrev,\n\u001B[32m      9\u001B[39m     jvp,\n\u001B[32m     10\u001B[39m     linearize,\n\u001B[32m     11\u001B[39m     vjp,\n\u001B[32m     12\u001B[39m )\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_functorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctional_call\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m functional_call, stack_module_state\n\u001B[32m     16\u001B[39m __all__ = [\n\u001B[32m     17\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mgrad\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     18\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mgrad_and_value\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     30\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdebug_unwrap\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     31\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\torch\\_functorch\\eager_transforms.py:35\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_functorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m argnums_t, exposed_in\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_subclasses\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctional_tensor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m FunctionalTensor\n\u001B[32m---> \u001B[39m\u001B[32m35\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexperimental\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m const_fold\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexperimental\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mproxy_tensor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m make_fx\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _pytree \u001B[38;5;28;01mas\u001B[39;00m pytree\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Predicting the Yield Curve\\.venv\\Lib\\site-packages\\torch\\fx\\experimental\\const_fold.py:17\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpasses\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msplit_module\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m split_module\n\u001B[32m     10\u001B[39m __all__ = [\n\u001B[32m     11\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mFoldedGraphModule\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mget_unique_attr_name_in_module\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33msplit_const_subgraphs\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     14\u001B[39m ]\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mFoldedGraphModule\u001B[39;00m(\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfx\u001B[49m.GraphModule):\n\u001B[32m     18\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[33;03m    FoldedGraphModule is a GraphModule which also contains another\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[33;03m    `const_subgraph_module` representing a subgraph which has all const attr\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     24\u001B[39m \u001B[33;03m    on which attrs.\u001B[39;00m\n\u001B[32m     25\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m     27\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m     28\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     29\u001B[39m         root: torch.nn.Module,\n\u001B[32m   (...)\u001B[39m\u001B[32m     33\u001B[39m         device_for_folded_attrs: \u001B[38;5;28mstr\u001B[39m = \u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     34\u001B[39m     ):\n",
      "\u001B[31mAttributeError\u001B[39m: partially initialized module 'torch' has no attribute 'fx' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------- Execution ------------------------ #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_notebook(horizon=1, trials=30, n_jobs=1)"
   ],
   "id": "f8aed198ecfba14c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T18:13:54.866924Z",
     "start_time": "2025-05-15T18:13:54.820854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------- Debug Folds ---------------------- #\n",
    "def debug_folds(folds, forecast_horizon=1):\n",
    "    print(f\"[DEBUG] Total folds generated: {len(folds)}\\n\")\n",
    "\n",
    "    for i, f in enumerate(folds):\n",
    "        print(f\"\\n--- Fold {i+1} ---\")\n",
    "\n",
    "        # Print shapes\n",
    "        print(f\"Train X: {f['X_tr'].shape}, Y: {f['Y_tr'].shape}\")\n",
    "        print(f\"Valid X: {f['X_va'].shape}, Y: {f['Y_va'].shape}\")\n",
    "\n",
    "        # Show date ranges\n",
    "        print(f\"Train X range: {f['X_tr'].index[0].date()} → {f['X_tr'].index[-1].date()}\")\n",
    "        print(f\"Train Y range: {f['Y_tr'].index[0].date()} → {f['Y_tr'].index[-1].date()}\")\n",
    "        print(f\"Valid X range: {f['X_va'].index[0].date()} → {f['X_va'].index[-1].date()}\")\n",
    "        print(f\"Valid Y range: {f['Y_va'].index[0].date()} → {f['Y_va'].index[-1].date()}\")\n",
    "\n",
    "        # Check alignment\n",
    "        expected_end_x = f['Y_va'].index[0] - pd.Timedelta(days=forecast_horizon)\n",
    "        actual_end_x   = f['X_va'].index[-1]\n",
    "        print(f\"Expected X_va end before Y_va start: {expected_end_x.date()}\")\n",
    "        print(f\"Actual X_va end: {actual_end_x.date()}\")\n",
    "\n",
    "        # Check overlap\n",
    "        overlap = set(f['X_va'].index).intersection(f['Y_va'].index)\n",
    "        print(f\"Overlap between X_va and Y_va: {len(overlap)} dates\")\n",
    "\n",
    "        if len(overlap) > 0:\n",
    "            print(\"⚠️ Overlap detected between X_va and Y_va – check alignment logic.\")\n",
    "        if actual_end_x >= f['Y_va'].index[0]:\n",
    "            print(\"❗ X_va may leak into Y_va – check sequence slicing.\")\n",
    "\n",
    "# Call it\n",
    "debug_folds(folds, forecast_horizon=FORECAST_HORIZON)\n"
   ],
   "id": "23a6fa01a4dd4652",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Total folds generated: 6\n",
      "\n",
      "\n",
      "--- Fold 1 ---\n",
      "Train X: (757, 56), Y: (757, 6)\n",
      "Valid X: (1259, 56), Y: (504, 6)\n",
      "Train X range: 2006-08-25 → 2009-07-21\n",
      "Train Y range: 2009-07-21 → 2012-06-13\n",
      "Valid X range: 2006-08-28 → 2011-06-24\n",
      "Valid Y range: 2012-06-14 → 2014-05-20\n",
      "Expected X_va end before Y_va start: 2012-06-13\n",
      "Actual X_va end: 2011-06-24\n",
      "Overlap between X_va and Y_va: 0 dates\n",
      "\n",
      "--- Fold 2 ---\n",
      "Train X: (1261, 56), Y: (1261, 6)\n",
      "Valid X: (1259, 56), Y: (504, 6)\n",
      "Train X range: 2006-08-25 → 2011-06-27\n",
      "Train Y range: 2009-07-21 → 2014-05-20\n",
      "Valid X range: 2008-08-01 → 2013-05-31\n",
      "Valid Y range: 2014-05-21 → 2016-04-25\n",
      "Expected X_va end before Y_va start: 2014-05-20\n",
      "Actual X_va end: 2013-05-31\n",
      "Overlap between X_va and Y_va: 0 dates\n",
      "\n",
      "--- Fold 3 ---\n",
      "Train X: (1765, 56), Y: (1765, 6)\n",
      "Valid X: (1259, 56), Y: (504, 6)\n",
      "Train X range: 2006-08-25 → 2013-06-03\n",
      "Train Y range: 2009-07-21 → 2016-04-25\n",
      "Valid X range: 2010-07-09 → 2015-05-07\n",
      "Valid Y range: 2016-04-26 → 2018-03-30\n",
      "Expected X_va end before Y_va start: 2016-04-25\n",
      "Actual X_va end: 2015-05-07\n",
      "Overlap between X_va and Y_va: 0 dates\n",
      "\n",
      "--- Fold 4 ---\n",
      "Train X: (2269, 56), Y: (2269, 6)\n",
      "Valid X: (1259, 56), Y: (504, 6)\n",
      "Train X range: 2006-08-25 → 2015-05-08\n",
      "Train Y range: 2009-07-21 → 2018-03-30\n",
      "Valid X range: 2012-06-15 → 2017-04-18\n",
      "Valid Y range: 2018-04-02 → 2020-03-05\n",
      "Expected X_va end before Y_va start: 2018-04-01\n",
      "Actual X_va end: 2017-04-18\n",
      "Overlap between X_va and Y_va: 0 dates\n",
      "\n",
      "--- Fold 5 ---\n",
      "Train X: (2773, 56), Y: (2773, 6)\n",
      "Valid X: (1259, 56), Y: (504, 6)\n",
      "Train X range: 2006-08-25 → 2017-04-19\n",
      "Train Y range: 2009-07-21 → 2020-03-05\n",
      "Valid X range: 2014-05-22 → 2019-03-25\n",
      "Valid Y range: 2020-03-06 → 2022-02-09\n",
      "Expected X_va end before Y_va start: 2020-03-05\n",
      "Actual X_va end: 2019-03-25\n",
      "Overlap between X_va and Y_va: 0 dates\n",
      "\n",
      "--- Fold 6 ---\n",
      "Train X: (3277, 56), Y: (3277, 6)\n",
      "Valid X: (1259, 56), Y: (504, 6)\n",
      "Train X range: 2006-08-25 → 2019-03-26\n",
      "Train Y range: 2009-07-21 → 2022-02-09\n",
      "Valid X range: 2016-05-03 → 2021-03-01\n",
      "Valid Y range: 2022-02-10 → 2024-01-16\n",
      "Expected X_va end before Y_va start: 2022-02-09\n",
      "Actual X_va end: 2021-03-01\n",
      "Overlap between X_va and Y_va: 0 dates\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T18:00:50.203440Z",
     "start_time": "2025-05-15T18:00:49.496435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Example usage:\n",
    "df_with_errors = get_forecast_errors_only(r\"C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\Model Fit\\Output\\DNS_Full_Forecast\\dns_kf_total_h5_full_dataset.csv\")"
   ],
   "id": "c157ab938ea309a2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T18:01:47.689984Z",
     "start_time": "2025-05-15T18:01:47.677701Z"
    }
   },
   "cell_type": "code",
   "source": "df_with_errors",
   "id": "5eb875625f1807b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            error_3m  error_6m  error_1y  error_3y  error_5y  error_10y\n",
       "eval_date                                                              \n",
       "2006-08-25  0.049399 -0.041120 -0.007011  0.128507  0.121623   0.093890\n",
       "2006-08-28  0.067899 -0.056128 -0.027910  0.103968  0.091551   0.060019\n",
       "2006-08-29  0.100689 -0.036597 -0.013761  0.096428  0.070023   0.046928\n",
       "2006-08-30  0.121152 -0.016889  0.014671  0.121862  0.114195   0.070162\n",
       "2006-08-31  0.122509  0.014783  0.036736  0.173692  0.134809   0.088192\n",
       "...              ...       ...       ...       ...       ...        ...\n",
       "2025-02-27  0.018743  0.026411  0.132412  0.196475  0.234137   0.218851\n",
       "2025-02-28  0.001930  0.039014  0.164062  0.236158  0.273256   0.247947\n",
       "2025-03-03 -0.062340 -0.058485  0.141231  0.241750  0.274899   0.268048\n",
       "2025-03-04 -0.053563 -0.032764  0.151810  0.210346  0.208558   0.178195\n",
       "2025-03-05 -0.086683 -0.081883  0.092619  0.077878  0.066686   0.039925\n",
       "\n",
       "[4834 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_3m</th>\n",
       "      <th>error_6m</th>\n",
       "      <th>error_1y</th>\n",
       "      <th>error_3y</th>\n",
       "      <th>error_5y</th>\n",
       "      <th>error_10y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-08-25</th>\n",
       "      <td>0.049399</td>\n",
       "      <td>-0.041120</td>\n",
       "      <td>-0.007011</td>\n",
       "      <td>0.128507</td>\n",
       "      <td>0.121623</td>\n",
       "      <td>0.093890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-28</th>\n",
       "      <td>0.067899</td>\n",
       "      <td>-0.056128</td>\n",
       "      <td>-0.027910</td>\n",
       "      <td>0.103968</td>\n",
       "      <td>0.091551</td>\n",
       "      <td>0.060019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-29</th>\n",
       "      <td>0.100689</td>\n",
       "      <td>-0.036597</td>\n",
       "      <td>-0.013761</td>\n",
       "      <td>0.096428</td>\n",
       "      <td>0.070023</td>\n",
       "      <td>0.046928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-30</th>\n",
       "      <td>0.121152</td>\n",
       "      <td>-0.016889</td>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.121862</td>\n",
       "      <td>0.114195</td>\n",
       "      <td>0.070162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-31</th>\n",
       "      <td>0.122509</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>0.173692</td>\n",
       "      <td>0.134809</td>\n",
       "      <td>0.088192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-27</th>\n",
       "      <td>0.018743</td>\n",
       "      <td>0.026411</td>\n",
       "      <td>0.132412</td>\n",
       "      <td>0.196475</td>\n",
       "      <td>0.234137</td>\n",
       "      <td>0.218851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-28</th>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.236158</td>\n",
       "      <td>0.273256</td>\n",
       "      <td>0.247947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-03</th>\n",
       "      <td>-0.062340</td>\n",
       "      <td>-0.058485</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.241750</td>\n",
       "      <td>0.274899</td>\n",
       "      <td>0.268048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-04</th>\n",
       "      <td>-0.053563</td>\n",
       "      <td>-0.032764</td>\n",
       "      <td>0.151810</td>\n",
       "      <td>0.210346</td>\n",
       "      <td>0.208558</td>\n",
       "      <td>0.178195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05</th>\n",
       "      <td>-0.086683</td>\n",
       "      <td>-0.081883</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.077878</td>\n",
       "      <td>0.066686</td>\n",
       "      <td>0.039925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4834 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117aefa0-6fe3-404a-a5d4-c8f067249a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.018671\n",
      "Params: {'hidden_dim': 156, 'num_layers': 3, 'dropout': 0.4241144063085703, 'learning_rate': 0.001732053535845956, 'batch_size': 32, 'epochs': 44}\n",
      "Total run time: 6340.3 s\n"
     ]
    }
   ],
   "source": [
    "    print(f\"MSE   : {study.best_value:.6f}\")\n",
    "    print(f\"Params: {study.best_trial.params}\")\n",
    "    print(f\"Total run time: {dur:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf582293-9367-4a97-9c9a-a7d36095eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running final model evaluation on test set\n",
      "[DEBUG] It's working\n",
      "\n",
      "[RESULT] Final Test Set MSE: 0.000339\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    FORECAST_HORIZON = 1\n",
    "    BEST_PARAMS = {\n",
    "        'hidden_dim': 156,\n",
    "        'num_layers': 3,\n",
    "        'dropout': 0.4241144063085703,\n",
    "        'learning_rate': 0.001732053535845956,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 44\n",
    "    }\n",
    "    SEQUENCE_LENGTH = 1512\n",
    "    \n",
    "    print(\"[INFO] Running final model evaluation on test set\")\n",
    "\n",
    "    X = pd.read_csv(\"X_df_filtered_shap.csv\", index_col=0, parse_dates=True)\n",
    "    Y = pd.read_csv(\"Y_df_change_1.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "    TEST_SIZE = 756             # 3-year hold-out\n",
    "    seq_buffer = SEQUENCE_LENGTH + FORECAST_HORIZON - 1\n",
    "    \n",
    "    X_train = X.iloc[:-TEST_SIZE]\n",
    "    Y_train = Y.iloc[:-TEST_SIZE]\n",
    "    \n",
    "    X_test_start = -TEST_SIZE - seq_buffer   # keep enough context for sequences\n",
    "    X_test = X.iloc[X_test_start:]\n",
    "    Y_test = Y.iloc[-TEST_SIZE:]\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train_std = pd.DataFrame(sc.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_test_std  = pd.DataFrame(sc.transform(X_test),     index=X_test.index,  columns=X_test.columns)\n",
    "\n",
    "    X_tr_seq, Y_tr_seq = gen_seq(X_train_std, Y_train, SEQUENCE_LENGTH, FORECAST_HORIZON)\n",
    "    X_te_seq, Y_te_seq = gen_seq(X_test_std,  Y_test,  SEQUENCE_LENGTH, FORECAST_HORIZON)\n",
    "\n",
    "    if len(X_te_seq) == 0 or len(Y_te_seq) == 0:\n",
    "        print(\"[ERROR] No valid test sequences generated. Check alignment or sequence length.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"[DEBUG] It's working\")\n",
    "\n",
    "    model = LSTMRegressor(\n",
    "        in_dim=X_tr_seq.shape[2],\n",
    "        hid=BEST_PARAMS['hidden_dim'],\n",
    "        layers=BEST_PARAMS['num_layers'],\n",
    "        out_dim=Y_tr_seq.shape[1],\n",
    "        drop=BEST_PARAMS['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=BEST_PARAMS['learning_rate'])\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(torch.tensor(X_tr_seq), torch.tensor(Y_tr_seq)),\n",
    "                              batch_size=BEST_PARAMS['batch_size'], shuffle=True, pin_memory=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(BEST_PARAMS['epochs']):\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with amp.autocast(device_type=\"cuda\"):\n",
    "                loss = nn.functional.mse_loss(model(xb), yb)\n",
    "            scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "\n",
    "    model.eval(); preds, gts = [], []\n",
    "    test_loader = DataLoader(TensorDataset(torch.tensor(X_te_seq), torch.tensor(Y_te_seq)),\n",
    "                             batch_size=BEST_PARAMS['batch_size'], pin_memory=True)\n",
    "\n",
    "    with torch.no_grad(), amp.autocast(device_type='cuda'):\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            preds.append(model(xb).cpu())\n",
    "            gts.append(yb)\n",
    "\n",
    "    if len(preds) == 0 or len(gts) == 0:\n",
    "        print(\"[ERROR] No predictions generated. Check test data preprocessing.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    y_true = torch.cat(gts).numpy()\n",
    "    y_pred = torch.cat(preds).numpy()\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"\\n[RESULT] Final Test Set MSE: {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16dcdd34-c742-4fed-a396-4b15ff5b5549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Multi-output predictions saved to 'final_test_predictions_multioutput.csv'\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Save Multi-Output Results ---------------------- #\n",
    "maturity_labels = [f\"m{i+1}\" for i in range(y_true.shape[1])]  # e.g., m1, m2, ..., m6\n",
    "\n",
    "# Create column-wise dict\n",
    "results_dict = {\n",
    "    \"date\": Y_test.index[-len(y_true):]  # ensure alignment\n",
    "}\n",
    "\n",
    "# Add true and predicted values for each maturity\n",
    "for i, label in enumerate(maturity_labels):\n",
    "    results_dict[f\"{label}_true\"] = y_true[:, i]\n",
    "    results_dict[f\"{label}_pred\"] = y_pred[:, i]\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results_dict).set_index(\"date\")\n",
    "\n",
    "# Save\n",
    "results_df.to_csv(\"final_test_predictions_multioutput.csv\")\n",
    "print(\"[INFO] Multi-output predictions saved to 'final_test_predictions_multioutput.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3022755c-87d7-4f88-aa45-14a10af63937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-04-13', '2022-04-14', '2022-04-15', '2022-04-18',\n",
       "               '2022-04-19', '2022-04-20', '2022-04-21', '2022-04-22',\n",
       "               '2022-04-25', '2022-04-26',\n",
       "               ...\n",
       "               '2025-02-20', '2025-02-21', '2025-02-24', '2025-02-25',\n",
       "               '2025-02-26', '2025-02-27', '2025-02-28', '2025-03-03',\n",
       "               '2025-03-04', '2025-03-05'],\n",
       "              dtype='datetime64[ns]', length=756, freq=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------- Save Results ---------------------- #\n",
    "import os\n",
    "\n",
    "Y_test.index[-len(y_true):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a511d1-e5c8-4b4a-a9d4-5c23dd3af05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "756"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
