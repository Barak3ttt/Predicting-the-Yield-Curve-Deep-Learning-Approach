{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "914819af9bb112c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:38:55.705593Z",
     "start_time": "2025-05-11T16:36:11.252784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /venv/main/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in /venv/main/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.7.0+cu128)\n",
      "Requirement already satisfied: geneticalgorithm in /venv/main/lib/python3.12/site-packages (1.0.2)\n",
      "Requirement already satisfied: matplotlib in /venv/main/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: optuna in /venv/main/lib/python3.12/site-packages (4.3.0)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /venv/main/lib/python3.12/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /venv/main/lib/python3.12/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /venv/main/lib/python3.12/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /venv/main/lib/python3.12/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /venv/main/lib/python3.12/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /venv/main/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /venv/main/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: func-timeout in /venv/main/lib/python3.12/site-packages (from geneticalgorithm) (4.3.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /venv/main/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /venv/main/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /venv/main/lib/python3.12/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /venv/main/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /venv/main/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /venv/main/lib/python3.12/site-packages (from optuna) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /venv/main/lib/python3.12/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /venv/main/lib/python3.12/site-packages (from optuna) (2.0.40)\n",
      "Requirement already satisfied: PyYAML in /venv/main/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Mako in /venv/main/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /venv/main/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn tqdm torch geneticalgorithm matplotlib optuna openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51eb54fc85eec128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T19:07:26.931413Z",
     "start_time": "2025-05-11T19:07:26.887436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "  - GPU: NVIDIA H200\n",
      "  - Memory Allocated: 0.11 GB\n",
      "  - Memory Cached   : 0.36 GB\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Importing Packages ---------------------- #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "# ---------------------- Reproducibility ---------------------- #\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# ---------------------- Device ---------------------- #\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"  - GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  - Memory Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"  - Memory Cached   : {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "# ---------------------- Configuration ---------------------- #\n",
    "val_window_num_sequences = 504\n",
    "holdout_base = 756\n",
    "forecast_horizons = [5, 21, 63, 252]\n",
    "num_epochs = 120\n",
    "patience = 20\n",
    "\n",
    "sequence_length_map = {\n",
    "    1: 1512,\n",
    "    5: 1323,\n",
    "    21: 1512,\n",
    "    63: 1512,\n",
    "    252: 1512\n",
    "}\n",
    "\n",
    "batch_size_options = [32, 64]\n",
    "hidden_dim_range = (64, 128)\n",
    "num_layers_options = [1, 2]\n",
    "dropout_range = (0.0, 0.6)\n",
    "learning_rate_range = (1e-4, 5e-2)\n",
    "\n",
    "# ---------------------- Model ---------------------- #\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=(dropout if num_layers > 1 else 0.0))\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.norm(hn[-1])\n",
    "        out = self.relu(self.fc1(out))\n",
    "        return self.fc2(out)\n",
    "\n",
    "# ---------------------- Data Utilities ---------------------- #\n",
    "def generate_X_sequences_from_Y(X_df, Y_df_fold, sequence_length, forecast_horizon):\n",
    "    X_arr = X_df.values.astype(np.float32)\n",
    "    Y_arr = Y_df_fold.reindex(X_df.index).values.astype(np.float32)\n",
    "\n",
    "    X_seq, Y_seq, valid_timestamps = [], [], []\n",
    "    idx_map = {ts: i for i, ts in enumerate(X_df.index)}\n",
    "\n",
    "    for t in Y_df_fold.index:\n",
    "        target_idx = idx_map.get(t, None)\n",
    "        if target_idx is None:\n",
    "            continue\n",
    "        x_end = target_idx - forecast_horizon + 1\n",
    "        x_start = x_end - sequence_length\n",
    "        if x_start < 0 or x_end > len(X_arr):\n",
    "            continue\n",
    "        x_window = X_arr[x_start:x_end]\n",
    "        if x_window.shape[0] != sequence_length or np.isnan(x_window).any():\n",
    "            continue\n",
    "        try:\n",
    "            Y_seq.append(Y_arr[target_idx])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        X_seq.append(x_window)\n",
    "        valid_timestamps.append(t)\n",
    "\n",
    "    return np.array(X_seq), np.array(Y_seq), valid_timestamps\n",
    "\n",
    "def standardize_fold(X_train, X_val):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "    X_val_scaled = pd.DataFrame(scaler.transform(X_val), index=X_val.index, columns=X_val.columns)\n",
    "    return X_train_scaled, X_val_scaled\n",
    "\n",
    "# ---------------------- CV ---------------------- #\n",
    "def get_expanding_folds(X_df, Y_df, forecast_horizon, sequence_length_map, val_window_num_sequences, holdout_base):\n",
    "    assert X_df.index.equals(Y_df.index)\n",
    "    sequence_length = sequence_length_map[forecast_horizon]\n",
    "    total_days = len(X_df)\n",
    "    val_window = val_window_num_sequences\n",
    "    min_train_window = sequence_length + forecast_horizon\n",
    "    folds = []\n",
    "    i = min_train_window\n",
    "    while i + val_window + holdout_base <= total_days:\n",
    "        train_end = i\n",
    "        val_start = i\n",
    "        val_end = i + val_window\n",
    "\n",
    "        X_train = X_df.iloc[:train_end].copy()\n",
    "        Y_train = Y_df.iloc[:train_end].copy()\n",
    "        X_val = X_df.iloc[val_start - sequence_length - forecast_horizon + 1:val_end - forecast_horizon].copy()\n",
    "        Y_val = Y_df.iloc[val_start:val_end].copy()\n",
    "\n",
    "        folds.append({\n",
    "            \"X_train\": X_train,\n",
    "            \"Y_train\": Y_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"Y_val\": Y_val,\n",
    "            \"sequence_length\": sequence_length\n",
    "        })\n",
    "        i += val_window\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    return folds\n",
    "\n",
    "# ---------------------- Optuna Objective ---------------------- #\n",
    "def objective(trial, folds, forecast_horizon):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", *hidden_dim_range)\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", num_layers_options)\n",
    "    dropout = trial.suggest_float(\"dropout\", *dropout_range)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", *learning_rate_range, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", batch_size_options)\n",
    "\n",
    "    total_f1 = []\n",
    "\n",
    "    for fold in tqdm(folds, desc=f\"Horizon {forecast_horizon} folds\", leave=False):\n",
    "        X_train_std, X_val_std = standardize_fold(fold[\"X_train\"], fold[\"X_val\"])\n",
    "        X_train_seq, Y_train_seq, _ = generate_X_sequences_from_Y(X_train_std, fold[\"Y_train\"], fold[\"sequence_length\"], forecast_horizon)\n",
    "        X_val_seq, Y_val_seq, _ = generate_X_sequences_from_Y(X_val_std, fold[\"Y_val\"], fold[\"sequence_length\"], forecast_horizon)\n",
    "\n",
    "        if len(X_train_seq) == 0 or len(X_val_seq) == 0:\n",
    "            continue\n",
    "\n",
    "        model = LSTMClassifier(X_train_seq.shape[2], hidden_dim, num_layers, Y_train_seq.shape[1], dropout).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "        y_train_tensor = torch.tensor(Y_train_seq).float().to(device)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(X_train_seq), y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(torch.tensor(X_val_seq), torch.tensor(Y_val_seq)), batch_size=batch_size)\n",
    "\n",
    "        best_f1, patience_counter = 0, 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xb.to(device)), yb.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_loss, preds = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    output = model(xb.to(device))\n",
    "                    val_loss.append(criterion(output, yb.to(device)).item())\n",
    "                    preds.append(torch.sigmoid(output))\n",
    "            scheduler.step(np.mean(val_loss))\n",
    "            pred_tensor = torch.cat(preds, dim=0).squeeze()\n",
    "            preds_binary = (pred_tensor > 0.5).int().cpu().numpy()\n",
    "            y_true = torch.tensor(Y_val_seq).int().cpu().numpy()\n",
    "\n",
    "            f1 = f1_score(y_true, preds_binary, average=\"macro\")\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    break\n",
    "\n",
    "        total_f1.append(best_f1)\n",
    "\n",
    "    return -np.mean(total_f1)\n",
    "\n",
    "# ---------------------- Optuna Wrapper ---------------------- #\n",
    "def run_optuna_optimization(folds, forecast_horizon, n_trials=4):\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, folds, forecast_horizon), n_trials=n_trials)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# ---------------------- Run All ---------------------- #\n",
    "def run_for_all_horizons(X_df, Y_df_dict):\n",
    "    all_results = {}\n",
    "    for h in trange(len(forecast_horizons), desc=\"Forecast Horizons\"):\n",
    "        horizon = forecast_horizons[h]\n",
    "        print(f\"\\n=== Forecast Horizon: {horizon} ===\")\n",
    "        Y_df = Y_df_dict[horizon]\n",
    "        folds = get_expanding_folds(X_df, Y_df, horizon, sequence_length_map, val_window_num_sequences, holdout_base)\n",
    "        best_params, best_score = run_optuna_optimization(folds, horizon)\n",
    "        print(f\"[RESULT] Horizon {horizon}: Best Params = {best_params}, Best F1 = {-best_score:.4f}\")\n",
    "        all_results[horizon] = {\"best_params\": best_params, \"best_score\": best_score}\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ec020dc1ecc876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast Horizons:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Forecast Horizon: 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 12:26:21,074] A new study created in memory with name: no-name-74c1cc61-b1d1-4360-819d-587991cd1383\n",
      "\n",
      "Horizon 5 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 5 folds:  17%|‚ñà‚ñã        | 1/6 [00:57<04:45, 57.14s/it]\u001b[A\n",
      "Horizon 5 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [05:48<12:58, 194.70s/it]\u001b[A\n",
      "Horizon 5 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [09:53<10:54, 218.03s/it]\u001b[A\n",
      "Horizon 5 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [31:38<21:33, 646.80s/it]\u001b[A\n",
      "Horizon 5 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [42:36<10:51, 651.13s/it]\u001b[A\n",
      "Horizon 5 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [52:59<00:00, 641.36s/it]\u001b[A\n",
      "                                                               \u001b[A[I 2025-05-12 13:19:20,440] Trial 0 finished with value: -0.364841357917739 and parameters: {'hidden_dim': 74, 'num_layers': 1, 'dropout': 0.011049363497449116, 'learning_rate': 0.0006052030903899146, 'batch_size': 32}. Best is trial 0 with value: -0.364841357917739.\n",
      "\n",
      "Horizon 5 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 5 folds:  17%|‚ñà‚ñã        | 1/6 [00:26<02:11, 26.37s/it]\u001b[A\n",
      "Horizon 5 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [03:52<08:47, 131.85s/it]\u001b[A\n",
      "Horizon 5 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [08:22<09:45, 195.12s/it]\u001b[A\n",
      "Horizon 5 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [27:50<19:18, 579.04s/it]\u001b[A\n",
      "Horizon 5 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [33:34<08:14, 494.32s/it]\u001b[A\n",
      "Horizon 5 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [42:40<00:00, 512.10s/it]\u001b[A\n",
      "                                                               \u001b[A[I 2025-05-12 14:02:01,429] Trial 1 finished with value: -0.18924007335970802 and parameters: {'hidden_dim': 72, 'num_layers': 1, 'dropout': 0.4196421469971567, 'learning_rate': 0.02650426611639811, 'batch_size': 32}. Best is trial 0 with value: -0.364841357917739.\n",
      "\n",
      "Horizon 5 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 5 folds:  17%|‚ñà‚ñã        | 1/6 [01:06<05:32, 66.57s/it]\u001b[A\n",
      "Horizon 5 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [04:05<08:51, 132.89s/it]\u001b[A\n",
      "Horizon 5 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [09:59<11:41, 233.85s/it]\u001b[A\n",
      "Horizon 5 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [21:06<13:29, 404.78s/it]\u001b[A\n",
      "Horizon 5 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [36:32<09:52, 592.66s/it]\u001b[A\n",
      "Horizon 5 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [54:59<00:00, 767.53s/it]\u001b[A\n",
      "                                                               \u001b[A[I 2025-05-12 14:57:01,043] Trial 2 finished with value: -0.35792097982522647 and parameters: {'hidden_dim': 91, 'num_layers': 2, 'dropout': 0.2821153503102117, 'learning_rate': 0.007063841997015125, 'batch_size': 64}. Best is trial 0 with value: -0.364841357917739.\n",
      "\n",
      "Horizon 5 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 5 folds:  17%|‚ñà‚ñã        | 1/6 [01:04<05:24, 64.86s/it]\u001b[A\n",
      "Horizon 5 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [04:00<08:39, 129.83s/it]\u001b[A\n",
      "Horizon 5 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [12:51<15:39, 313.14s/it]\u001b[A\n",
      "Horizon 5 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [22:22<13:50, 415.07s/it]\u001b[A\n",
      "Horizon 5 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [27:59<06:26, 386.88s/it]\u001b[A\n",
      "Horizon 5 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [45:42<00:00, 616.76s/it]\u001b[A\n",
      "                                                               \u001b[A[I 2025-05-12 15:42:43,844] Trial 3 finished with value: -0.18783646633735607 and parameters: {'hidden_dim': 122, 'num_layers': 2, 'dropout': 0.2505095763543279, 'learning_rate': 0.012163265737617772, 'batch_size': 32}. Best is trial 0 with value: -0.364841357917739.\n",
      "Forecast Horizons:  25%|‚ñà‚ñà‚ñå       | 1/4 [3:16:23<9:49:11, 11783.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 5: Best Params = {'hidden_dim': 74, 'num_layers': 1, 'dropout': 0.011049363497449116, 'learning_rate': 0.0006052030903899146, 'batch_size': 32}, Best F1 = 0.3648\n",
      "\n",
      "=== Forecast Horizon: 21 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 15:42:44,841] A new study created in memory with name: no-name-033af407-8b0c-4683-8076-938b612683d9\n",
      "\n",
      "Horizon 21 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 21 folds:  17%|‚ñà‚ñã        | 1/6 [01:27<07:19, 87.87s/it]\u001b[A\n",
      "Horizon 21 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [03:33<07:19, 109.95s/it]\u001b[A\n",
      "Horizon 21 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [10:50<12:58, 259.51s/it]\u001b[A\n",
      "Horizon 21 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [16:03<09:21, 280.59s/it]\u001b[A\n",
      "Horizon 21 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [20:40<04:39, 279.12s/it]\u001b[A\n",
      "Horizon 21 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [26:40<00:00, 306.82s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 16:09:25,765] Trial 0 finished with value: -0.517721837244002 and parameters: {'hidden_dim': 124, 'num_layers': 1, 'dropout': 0.31344902537665004, 'learning_rate': 0.0004530440937038322, 'batch_size': 32}. Best is trial 0 with value: -0.517721837244002.\n",
      "\n",
      "Horizon 21 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 21 folds:  17%|‚ñà‚ñã        | 1/6 [00:32<02:42, 32.55s/it]\u001b[A\n",
      "Horizon 21 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [04:19<09:48, 147.11s/it]\u001b[A\n",
      "Horizon 21 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [07:22<08:09, 163.23s/it]\u001b[A\n",
      "Horizon 21 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [12:27<07:18, 219.39s/it]\u001b[A\n",
      "Horizon 21 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [18:34<04:32, 272.65s/it]\u001b[A\n",
      "Horizon 21 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [25:26<00:00, 319.80s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 16:34:52,063] Trial 1 finished with value: -0.4838950240537352 and parameters: {'hidden_dim': 71, 'num_layers': 1, 'dropout': 0.42447762223691493, 'learning_rate': 0.005483074553287732, 'batch_size': 64}. Best is trial 0 with value: -0.517721837244002.\n",
      "\n",
      "Horizon 21 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 21 folds:  17%|‚ñà‚ñã        | 1/6 [00:59<04:58, 59.65s/it]\u001b[A\n",
      "Horizon 21 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [04:21<09:34, 143.50s/it]\u001b[A\n",
      "Horizon 21 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [07:51<08:40, 173.59s/it]\u001b[A\n",
      "Horizon 21 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [11:55<06:43, 201.62s/it]\u001b[A\n",
      "Horizon 21 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [16:55<03:57, 237.03s/it]\u001b[A\n",
      "Horizon 21 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [26:09<00:00, 344.66s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 17:01:01,479] Trial 2 finished with value: -0.5297231928417055 and parameters: {'hidden_dim': 65, 'num_layers': 1, 'dropout': 0.03241020068521034, 'learning_rate': 0.0022195404702176876, 'batch_size': 64}. Best is trial 2 with value: -0.5297231928417055.\n",
      "\n",
      "Horizon 21 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 21 folds:  17%|‚ñà‚ñã        | 1/6 [00:33<02:47, 33.43s/it]\u001b[A\n",
      "Horizon 21 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [03:25<07:40, 115.00s/it]\u001b[A\n",
      "Horizon 21 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [05:51<06:27, 129.29s/it]\u001b[A\n",
      "Horizon 21 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [09:41<05:38, 169.01s/it]\u001b[A\n",
      "Horizon 21 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [14:39<03:35, 215.45s/it]\u001b[A\n",
      "Horizon 21 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [26:36<00:00, 385.84s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 17:27:37,757] Trial 3 finished with value: -0.5322773483887173 and parameters: {'hidden_dim': 81, 'num_layers': 2, 'dropout': 0.4665467248745586, 'learning_rate': 0.004230006709092564, 'batch_size': 32}. Best is trial 3 with value: -0.5322773483887173.\n",
      "Forecast Horizons:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [5:01:17<4:45:09, 8554.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 21: Best Params = {'hidden_dim': 81, 'num_layers': 2, 'dropout': 0.4665467248745586, 'learning_rate': 0.004230006709092564, 'batch_size': 32}, Best F1 = 0.5323\n",
      "\n",
      "=== Forecast Horizon: 63 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 17:27:38,701] A new study created in memory with name: no-name-2ff5b007-396b-42b9-8974-eaa750bc78d2\n",
      "\n",
      "Horizon 63 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 63 folds:  17%|‚ñà‚ñã        | 1/6 [00:29<02:26, 29.21s/it]\u001b[A\n",
      "Horizon 63 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [02:08<04:41, 70.38s/it]\u001b[A\n",
      "Horizon 63 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [05:15<06:11, 123.86s/it]\u001b[A\n",
      "Horizon 63 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [12:21<08:06, 243.02s/it]\u001b[A\n",
      "Horizon 63 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [19:30<05:09, 309.98s/it]\u001b[A\n",
      "Horizon 63 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [23:27<00:00, 285.17s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 17:51:06,163] Trial 0 finished with value: -0.383442925431797 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.4101717525835676, 'learning_rate': 0.001536255900922402, 'batch_size': 32}. Best is trial 0 with value: -0.383442925431797.\n",
      "\n",
      "Horizon 63 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 63 folds:  17%|‚ñà‚ñã        | 1/6 [00:26<02:12, 26.45s/it]\u001b[A\n",
      "Horizon 63 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [01:29<03:11, 47.89s/it]\u001b[A\n",
      "Horizon 63 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [03:23<03:53, 77.94s/it]\u001b[A\n",
      "Horizon 63 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [09:36<06:29, 194.58s/it]\u001b[A\n",
      "Horizon 63 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [14:30<03:50, 230.58s/it]\u001b[A\n",
      "Horizon 63 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [18:49<00:00, 239.97s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 18:09:55,384] Trial 1 finished with value: -0.4266854723488167 and parameters: {'hidden_dim': 66, 'num_layers': 2, 'dropout': 0.4587297474587346, 'learning_rate': 0.00028773331072369377, 'batch_size': 64}. Best is trial 1 with value: -0.4266854723488167.\n",
      "\n",
      "Horizon 63 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 63 folds:  17%|‚ñà‚ñã        | 1/6 [00:23<01:56, 23.32s/it]\u001b[A\n",
      "Horizon 63 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [01:23<03:00, 45.07s/it]\u001b[A\n",
      "Horizon 63 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [06:51<08:43, 174.36s/it]\u001b[A\n",
      "Horizon 63 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [09:35<05:40, 170.07s/it]\u001b[A\n",
      "Horizon 63 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [12:35<02:53, 173.69s/it]\u001b[A\n",
      "Horizon 63 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [16:34<00:00, 196.03s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 18:26:30,441] Trial 2 finished with value: -0.3582815005550026 and parameters: {'hidden_dim': 116, 'num_layers': 1, 'dropout': 0.13126620640538408, 'learning_rate': 0.029357600409440625, 'batch_size': 32}. Best is trial 1 with value: -0.4266854723488167.\n",
      "\n",
      "Horizon 63 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 63 folds:  17%|‚ñà‚ñã        | 1/6 [00:19<01:38, 19.77s/it]\u001b[A\n",
      "Horizon 63 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [01:29<03:17, 49.44s/it]\u001b[A\n",
      "Horizon 63 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [03:53<04:37, 92.47s/it]\u001b[A\n",
      "Horizon 63 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [08:18<05:20, 160.39s/it]\u001b[A\n",
      "Horizon 63 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [12:11<03:06, 186.79s/it]\u001b[A\n",
      "Horizon 63 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [15:49<00:00, 197.43s/it]\u001b[A\n",
      "                                                                \u001b[A[I 2025-05-12 18:42:20,450] Trial 3 finished with value: -0.42806396763017185 and parameters: {'hidden_dim': 78, 'num_layers': 2, 'dropout': 0.2675391803066028, 'learning_rate': 0.016946190664661555, 'batch_size': 32}. Best is trial 3 with value: -0.42806396763017185.\n",
      "Forecast Horizons:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [6:16:00<1:51:35, 6695.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 63: Best Params = {'hidden_dim': 78, 'num_layers': 2, 'dropout': 0.2675391803066028, 'learning_rate': 0.016946190664661555, 'batch_size': 32}, Best F1 = 0.4281\n",
      "\n",
      "=== Forecast Horizon: 252 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 18:42:21,404] A new study created in memory with name: no-name-5e9cec6d-869b-4770-a3cc-ef4426377dce\n",
      "\n",
      "Horizon 252 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 252 folds:  17%|‚ñà‚ñã        | 1/6 [00:14<01:13, 14.61s/it]\u001b[A\n",
      "Horizon 252 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:58<02:07, 31.83s/it]\u001b[A\n",
      "Horizon 252 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [02:24<02:49, 56.57s/it]\u001b[A\n",
      "Horizon 252 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [04:43<02:57, 88.92s/it]\u001b[A\n",
      "Horizon 252 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [09:02<02:30, 150.54s/it]\u001b[A\n",
      "Horizon 252 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [12:27<00:00, 168.85s/it]\u001b[A\n",
      "                                                                 \u001b[A[I 2025-05-12 18:54:48,752] Trial 0 finished with value: -0.37207892803529097 and parameters: {'hidden_dim': 90, 'num_layers': 2, 'dropout': 0.17700763247582565, 'learning_rate': 0.0005408147588880358, 'batch_size': 64}. Best is trial 0 with value: -0.37207892803529097.\n",
      "\n",
      "Horizon 252 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 252 folds:  17%|‚ñà‚ñã        | 1/6 [00:12<01:04, 12.96s/it]\u001b[A\n",
      "Horizon 252 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [01:09<02:34, 38.63s/it]\u001b[A\n",
      "Horizon 252 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [02:22<02:42, 54.09s/it]\u001b[A\n",
      "Horizon 252 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [05:34<03:37, 108.50s/it]\u001b[A\n",
      "Horizon 252 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [08:11<02:06, 126.02s/it]\u001b[A\n",
      "Horizon 252 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [11:31<00:00, 151.17s/it]\u001b[A\n",
      "                                                                 \u001b[A[I 2025-05-12 19:06:19,938] Trial 1 finished with value: -0.39282001256831695 and parameters: {'hidden_dim': 71, 'num_layers': 1, 'dropout': 0.5070530814948203, 'learning_rate': 0.0012195949032976384, 'batch_size': 32}. Best is trial 1 with value: -0.39282001256831695.\n",
      "\n",
      "Horizon 252 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 252 folds:  17%|‚ñà‚ñã        | 1/6 [00:11<00:59, 11.88s/it]\u001b[A\n",
      "Horizon 252 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [01:36<03:37, 54.48s/it]\u001b[A\n",
      "Horizon 252 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [02:58<03:21, 67.27s/it]\u001b[A\n",
      "Horizon 252 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [04:55<02:53, 86.83s/it]\u001b[A\n",
      "Horizon 252 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [07:39<01:54, 114.84s/it]\u001b[A\n",
      "Horizon 252 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [11:07<00:00, 146.41s/it]\u001b[A\n",
      "                                                                 \u001b[A[I 2025-05-12 19:17:27,741] Trial 2 finished with value: -0.41571272320092784 and parameters: {'hidden_dim': 79, 'num_layers': 1, 'dropout': 0.40510817941460214, 'learning_rate': 0.0020222837671099274, 'batch_size': 32}. Best is trial 2 with value: -0.41571272320092784.\n",
      "\n",
      "Horizon 252 folds:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Horizon 252 folds:  17%|‚ñà‚ñã        | 1/6 [00:15<01:15, 15.07s/it]\u001b[A\n",
      "Horizon 252 folds:  33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [01:00<02:10, 32.73s/it]\u001b[A\n",
      "Horizon 252 folds:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [02:23<02:48, 56.01s/it]\u001b[A\n",
      "Horizon 252 folds:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [09:15<06:32, 196.24s/it]\u001b[A\n",
      "Horizon 252 folds:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [12:22<03:13, 193.15s/it]\u001b[A/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\n",
      "Horizon 252 folds: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [16:03<00:00, 202.42s/it]\u001b[A\n",
      "                                                                 \u001b[A[I 2025-05-12 19:33:31,055] Trial 3 finished with value: -0.4179803013359234 and parameters: {'hidden_dim': 66, 'num_layers': 2, 'dropout': 0.4760925570543213, 'learning_rate': 0.0015169995512927972, 'batch_size': 64}. Best is trial 3 with value: -0.4179803013359234.\n",
      "Forecast Horizons: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [7:07:11<00:00, 6407.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 252: Best Params = {'hidden_dim': 66, 'num_layers': 2, 'dropout': 0.4760925570543213, 'learning_rate': 0.0015169995512927972, 'batch_size': 64}, Best F1 = 0.4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load your prepared feature and target data\n",
    "X_df = pd.read_csv(\"X_df_filtered.csv\", index_col=0, parse_dates=True)\n",
    "\n",
    "# Define forecast horizons\n",
    "horizons = [1, 5, 21, 63, 252]\n",
    "\n",
    "# Dynamically load target data into dictionary\n",
    "Y_df_dict = {\n",
    "    h: pd.read_csv(f\"Y_df_change_dir_{h}.csv\", index_col=0, parse_dates=True)\n",
    "    for h in horizons\n",
    "}\n",
    "\n",
    "# Run the full optimization pipeline\n",
    "results = run_for_all_horizons(X_df, Y_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e01ddcc-5d1d-435a-b8fa-824001e724a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'best_params': {'hidden_dim': 74,\n",
       "   'num_layers': 1,\n",
       "   'dropout': 0.011049363497449116,\n",
       "   'learning_rate': 0.0006052030903899146,\n",
       "   'batch_size': 32},\n",
       "  'best_score': -0.364841357917739},\n",
       " 21: {'best_params': {'hidden_dim': 81,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.4665467248745586,\n",
       "   'learning_rate': 0.004230006709092564,\n",
       "   'batch_size': 32},\n",
       "  'best_score': -0.5322773483887173},\n",
       " 63: {'best_params': {'hidden_dim': 78,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.2675391803066028,\n",
       "   'learning_rate': 0.016946190664661555,\n",
       "   'batch_size': 32},\n",
       "  'best_score': -0.42806396763017185},\n",
       " 252: {'best_params': {'hidden_dim': 66,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.4760925570543213,\n",
       "   'learning_rate': 0.0015169995512927972,\n",
       "   'batch_size': 64},\n",
       "  'best_score': -0.4179803013359234}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94beaadfd0bb4bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T17:33:28.624145Z",
     "start_time": "2025-05-11T17:33:27.619672Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_on_holdout(\n",
    "    X_df, Y_df_dict, params_file, forecast_horizons, sequence_length_map, validation_end_dates\n",
    "):\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "    results = []\n",
    "    params_df = pd.read_excel(params_file)\n",
    "\n",
    "    for h in forecast_horizons:\n",
    "        print(f\"\\n[INFO] Evaluating Forecast Horizon {h} on Holdout Set\")\n",
    "\n",
    "        # Load best parameters\n",
    "        row = params_df[params_df['Horizon'] == h].iloc[0]\n",
    "        best_params = {\n",
    "            \"hidden_dim\": int(row[\"hidden_dim\"]),\n",
    "            \"num_layers\": int(row[\"num_layers\"]),\n",
    "            \"dropout\": float(row[\"dropout\"]),\n",
    "            \"learning_rate\": float(row[\"learning_rate\"]),\n",
    "            \"batch_size\": int(row[\"batch_size\"])\n",
    "        }\n",
    "\n",
    "        # Setup\n",
    "        Y_df = Y_df_dict[h]\n",
    "        assert X_df.index.equals(Y_df.index)\n",
    "\n",
    "        # Standardize full X\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X_df), index=X_df.index, columns=X_df.columns)\n",
    "\n",
    "        # Get holdout start for Y\n",
    "        holdout_start = pd.to_datetime(validation_end_dates[h]) + pd.Timedelta(days=1)\n",
    "        Y_holdout = Y_df[Y_df.index >= holdout_start]\n",
    "\n",
    "        # Generate sequences: from full X, targeting only Y_holdout\n",
    "        sequence_length = sequence_length_map[h]\n",
    "        X_seq, Y_seq, valid_ts = generate_X_sequences_from_Y(X_scaled, Y_holdout, sequence_length, h)\n",
    "        if len(X_seq) == 0:\n",
    "            print(f\"[WARNING] No valid sequences for horizon {h}\")\n",
    "            continue\n",
    "\n",
    "        # Train model on all available data before holdout_start\n",
    "        X_train_all = X_scaled[X_scaled.index < holdout_start]\n",
    "        Y_train_all = Y_df[Y_df.index < holdout_start]\n",
    "        X_train_seq, Y_train_seq, _ = generate_X_sequences_from_Y(X_train_all, Y_train_all, sequence_length, h)\n",
    "\n",
    "        model = LSTMClassifier(X_seq.shape[2], best_params[\"hidden_dim\"], best_params[\"num_layers\"],\n",
    "                               Y_seq.shape[1], best_params[\"dropout\"]).to(device)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=best_params[\"learning_rate\"])\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(torch.tensor(X_train_seq), torch.tensor(Y_train_seq).float().to(device)),\n",
    "                                  batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(50):\n",
    "            for xb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xb.to(device)), yb.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluate on holdout\n",
    "        model.eval()\n",
    "        test_loader = DataLoader(TensorDataset(torch.tensor(X_seq), torch.tensor(Y_seq)), batch_size=best_params[\"batch_size\"])\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in test_loader:\n",
    "                output = model(xb.to(device))\n",
    "                preds.append(torch.sigmoid(output))\n",
    "\n",
    "        pred_tensor = torch.cat(preds, dim=0).squeeze()\n",
    "        preds_binary = (pred_tensor > 0.5).int().cpu().numpy()\n",
    "        y_true = torch.tensor(Y_seq).int().cpu().numpy()\n",
    "\n",
    "        results.append({\n",
    "            \"Horizon\": h,\n",
    "            \"F1\": f1_score(y_true, preds_binary, average=\"macro\"),\n",
    "            \"Precision\": precision_score(y_true, preds_binary, average=\"macro\", zero_division=0),\n",
    "            \"Recall\": recall_score(y_true, preds_binary, average=\"macro\", zero_division=0),\n",
    "            \"Accuracy\": accuracy_score(y_true, preds_binary)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5db5e7-3195-4255-a504-bb3a81371acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Evaluating Forecast Horizon 1 on Holdout Set\n",
      "\n",
      "[INFO] Evaluating Forecast Horizon 5 on Holdout Set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openpyxl\n",
    "\n",
    "validation_end_dates = {\n",
    "    1: \"2022-02-02\",\n",
    "    5: \"2021-11-17\",\n",
    "    21: \"2021-07-08\",\n",
    "    63: \"2021-08-06\",\n",
    "    252: \"2021-05-11\"\n",
    "}\n",
    "\n",
    "results_df = evaluate_on_holdout(\n",
    "    X_df=X_df,\n",
    "    Y_df_dict=Y_df_dict,\n",
    "    params_file=\"Best_LSTM_Parameters_per_Horizon_without_Autoregressive.xlsx\",\n",
    "    forecast_horizons=[1, 5, 21, 63, 252],\n",
    "    sequence_length_map={\n",
    "        1: 1512,\n",
    "        5: 1197,\n",
    "        21: 1323,\n",
    "        63: 1260,\n",
    "        252: 1323\n",
    "    },\n",
    "    validation_end_dates=validation_end_dates\n",
    ")\n",
    "\n",
    "results_df.to_csv(\"final_holdout_eval.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "becf7186409cbab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T19:08:12.982047Z",
     "start_time": "2025-05-11T19:07:28.153216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Forecast Horizon: 1 ===\n",
      "[DEBUG] Fold window i=1513, val_start=1513, val_end=1765, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1765, val_start=1765, val_end=2017, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2017, val_start=2017, val_end=2269, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2269, val_start=2269, val_end=2521, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2521, val_start=2521, val_end=2773, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2773, val_start=2773, val_end=3025, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3025, val_start=3025, val_end=3277, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3277, val_start=3277, val_end=3529, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3529, val_start=3529, val_end=3781, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3781, val_start=3781, val_end=4033, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4033, val_start=4033, val_end=4285, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4285, val_start=4285, val_end=4537, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4537, val_start=4537, val_end=4789, X_val.shape=(1764, 74), Y_val.shape=(252, 6)\n",
      "[INFO] Generated 13 non-overlapping folds for forecast horizon 1\n",
      "[FOLD 1]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2009-07-14 00:00:00\n",
      "    ‚û§ Val:   2009-07-15 00:00:00 ‚Üí 2010-07-01 00:00:00\n",
      "    üß† X_train_seq.shape = (1, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (1, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2009-07-14 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2009-07-15 00:00:00 ‚Üí 2010-07-01 00:00:00\n",
      "[FOLD 2]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2010-07-01 00:00:00\n",
      "    ‚û§ Val:   2010-07-02 00:00:00 ‚Üí 2011-06-20 00:00:00\n",
      "    üß† X_train_seq.shape = (253, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (253, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2010-07-01 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2010-07-02 00:00:00 ‚Üí 2011-06-20 00:00:00\n",
      "[FOLD 3]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2011-06-20 00:00:00\n",
      "    ‚û§ Val:   2011-06-21 00:00:00 ‚Üí 2012-06-06 00:00:00\n",
      "    üß† X_train_seq.shape = (505, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (505, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2011-06-20 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2011-06-21 00:00:00 ‚Üí 2012-06-06 00:00:00\n",
      "[FOLD 4]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2012-06-06 00:00:00\n",
      "    ‚û§ Val:   2012-06-07 00:00:00 ‚Üí 2013-05-24 00:00:00\n",
      "    üß† X_train_seq.shape = (757, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (757, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2012-06-06 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2012-06-07 00:00:00 ‚Üí 2013-05-24 00:00:00\n",
      "[FOLD 5]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2013-05-24 00:00:00\n",
      "    ‚û§ Val:   2013-05-27 00:00:00 ‚Üí 2014-05-13 00:00:00\n",
      "    üß† X_train_seq.shape = (1009, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (1009, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2013-05-24 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2013-05-27 00:00:00 ‚Üí 2014-05-13 00:00:00\n",
      "[FOLD 6]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2014-05-13 00:00:00\n",
      "    ‚û§ Val:   2014-05-14 00:00:00 ‚Üí 2015-04-30 00:00:00\n",
      "    üß† X_train_seq.shape = (1261, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (1261, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2014-05-13 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2014-05-14 00:00:00 ‚Üí 2015-04-30 00:00:00\n",
      "[FOLD 7]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2015-04-30 00:00:00\n",
      "    ‚û§ Val:   2015-05-01 00:00:00 ‚Üí 2016-04-18 00:00:00\n",
      "    üß† X_train_seq.shape = (1513, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (1513, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2015-04-30 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2015-05-01 00:00:00 ‚Üí 2016-04-18 00:00:00\n",
      "[FOLD 8]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2016-04-18 00:00:00\n",
      "    ‚û§ Val:   2016-04-19 00:00:00 ‚Üí 2017-04-05 00:00:00\n",
      "    üß† X_train_seq.shape = (1765, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (1765, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2016-04-18 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2016-04-19 00:00:00 ‚Üí 2017-04-05 00:00:00\n",
      "[FOLD 9]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2017-04-05 00:00:00\n",
      "    ‚û§ Val:   2017-04-06 00:00:00 ‚Üí 2018-03-23 00:00:00\n",
      "    üß† X_train_seq.shape = (2017, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (2017, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2017-04-05 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2017-04-06 00:00:00 ‚Üí 2018-03-23 00:00:00\n",
      "[FOLD 10]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2018-03-23 00:00:00\n",
      "    ‚û§ Val:   2018-03-26 00:00:00 ‚Üí 2019-03-12 00:00:00\n",
      "    üß† X_train_seq.shape = (2269, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (2269, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2018-03-23 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2018-03-26 00:00:00 ‚Üí 2019-03-12 00:00:00\n",
      "[FOLD 11]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2019-03-12 00:00:00\n",
      "    ‚û§ Val:   2019-03-13 00:00:00 ‚Üí 2020-02-27 00:00:00\n",
      "    üß† X_train_seq.shape = (2521, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (2521, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2019-03-12 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2019-03-13 00:00:00 ‚Üí 2020-02-27 00:00:00\n",
      "[FOLD 12]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2020-02-27 00:00:00\n",
      "    ‚û§ Val:   2020-02-28 00:00:00 ‚Üí 2021-02-15 00:00:00\n",
      "    üß† X_train_seq.shape = (2773, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (2773, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2020-02-27 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2020-02-28 00:00:00 ‚Üí 2021-02-15 00:00:00\n",
      "[FOLD 13]\n",
      "    ‚û§ Train: 2003-09-26 00:00:00 ‚Üí 2021-02-15 00:00:00\n",
      "    ‚û§ Val:   2021-02-16 00:00:00 ‚Üí 2022-02-02 00:00:00\n",
      "    üß† X_train_seq.shape = (3025, 1512, 74)\n",
      "    üß† Y_train_seq.shape = (3025, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1512, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-07-14 00:00:00 ‚Üí 2021-02-15 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2021-02-16 00:00:00 ‚Üí 2022-02-02 00:00:00\n",
      "\n",
      "=== Forecast Horizon: 5 ===\n",
      "[DEBUG] Fold window i=1202, val_start=1202, val_end=1454, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1454, val_start=1454, val_end=1706, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1706, val_start=1706, val_end=1958, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1958, val_start=1958, val_end=2210, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2210, val_start=2210, val_end=2462, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2462, val_start=2462, val_end=2714, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2714, val_start=2714, val_end=2966, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2966, val_start=2966, val_end=3218, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3218, val_start=3218, val_end=3470, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3470, val_start=3470, val_end=3722, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3722, val_start=3722, val_end=3974, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3974, val_start=3974, val_end=4226, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4226, val_start=4226, val_end=4478, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4478, val_start=4478, val_end=4730, X_val.shape=(1453, 74), Y_val.shape=(252, 6)\n",
      "[INFO] Generated 14 non-overlapping folds for forecast horizon 5\n",
      "[FOLD 1]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2008-05-09 00:00:00\n",
      "    ‚û§ Val:   2008-05-12 00:00:00 ‚Üí 2009-04-28 00:00:00\n",
      "    üß† X_train_seq.shape = (1, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (1, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2008-05-09 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2008-05-12 00:00:00 ‚Üí 2009-04-28 00:00:00\n",
      "[FOLD 2]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2009-04-28 00:00:00\n",
      "    ‚û§ Val:   2009-04-29 00:00:00 ‚Üí 2010-04-15 00:00:00\n",
      "    üß† X_train_seq.shape = (253, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (253, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2009-04-28 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2009-04-29 00:00:00 ‚Üí 2010-04-15 00:00:00\n",
      "[FOLD 3]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2010-04-15 00:00:00\n",
      "    ‚û§ Val:   2010-04-16 00:00:00 ‚Üí 2011-04-04 00:00:00\n",
      "    üß† X_train_seq.shape = (505, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (505, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2010-04-15 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2010-04-16 00:00:00 ‚Üí 2011-04-04 00:00:00\n",
      "[FOLD 4]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2011-04-04 00:00:00\n",
      "    ‚û§ Val:   2011-04-05 00:00:00 ‚Üí 2012-03-21 00:00:00\n",
      "    üß† X_train_seq.shape = (757, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (757, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2011-04-04 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2011-04-05 00:00:00 ‚Üí 2012-03-21 00:00:00\n",
      "[FOLD 5]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2012-03-21 00:00:00\n",
      "    ‚û§ Val:   2012-03-22 00:00:00 ‚Üí 2013-03-08 00:00:00\n",
      "    üß† X_train_seq.shape = (1009, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (1009, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2012-03-21 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2012-03-22 00:00:00 ‚Üí 2013-03-08 00:00:00\n",
      "[FOLD 6]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2013-03-08 00:00:00\n",
      "    ‚û§ Val:   2013-03-11 00:00:00 ‚Üí 2014-02-25 00:00:00\n",
      "    üß† X_train_seq.shape = (1261, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (1261, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2013-03-08 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2013-03-11 00:00:00 ‚Üí 2014-02-25 00:00:00\n",
      "[FOLD 7]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2014-02-25 00:00:00\n",
      "    ‚û§ Val:   2014-02-26 00:00:00 ‚Üí 2015-02-12 00:00:00\n",
      "    üß† X_train_seq.shape = (1513, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (1513, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2014-02-25 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2014-02-26 00:00:00 ‚Üí 2015-02-12 00:00:00\n",
      "[FOLD 8]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2015-02-12 00:00:00\n",
      "    ‚û§ Val:   2015-02-13 00:00:00 ‚Üí 2016-02-01 00:00:00\n",
      "    üß† X_train_seq.shape = (1765, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (1765, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2015-02-12 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2015-02-13 00:00:00 ‚Üí 2016-02-01 00:00:00\n",
      "[FOLD 9]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2016-02-01 00:00:00\n",
      "    ‚û§ Val:   2016-02-02 00:00:00 ‚Üí 2017-01-18 00:00:00\n",
      "    üß† X_train_seq.shape = (2017, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (2017, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2016-02-01 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2016-02-02 00:00:00 ‚Üí 2017-01-18 00:00:00\n",
      "[FOLD 10]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2017-01-18 00:00:00\n",
      "    ‚û§ Val:   2017-01-19 00:00:00 ‚Üí 2018-01-05 00:00:00\n",
      "    üß† X_train_seq.shape = (2269, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (2269, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2017-01-18 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2017-01-19 00:00:00 ‚Üí 2018-01-05 00:00:00\n",
      "[FOLD 11]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2018-01-05 00:00:00\n",
      "    ‚û§ Val:   2018-01-08 00:00:00 ‚Üí 2018-12-25 00:00:00\n",
      "    üß† X_train_seq.shape = (2521, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (2521, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2018-01-05 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2018-01-08 00:00:00 ‚Üí 2018-12-25 00:00:00\n",
      "[FOLD 12]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2018-12-25 00:00:00\n",
      "    ‚û§ Val:   2018-12-26 00:00:00 ‚Üí 2019-12-12 00:00:00\n",
      "    üß† X_train_seq.shape = (2773, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (2773, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2018-12-25 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2018-12-26 00:00:00 ‚Üí 2019-12-12 00:00:00\n",
      "[FOLD 13]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2019-12-12 00:00:00\n",
      "    ‚û§ Val:   2019-12-13 00:00:00 ‚Üí 2020-11-30 00:00:00\n",
      "    üß† X_train_seq.shape = (3025, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (3025, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2019-12-12 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2019-12-13 00:00:00 ‚Üí 2020-11-30 00:00:00\n",
      "[FOLD 14]\n",
      "    ‚û§ Train: 2003-10-02 00:00:00 ‚Üí 2020-11-30 00:00:00\n",
      "    ‚û§ Val:   2020-12-01 00:00:00 ‚Üí 2021-11-17 00:00:00\n",
      "    üß† X_train_seq.shape = (3277, 1197, 74)\n",
      "    üß† Y_train_seq.shape = (3277, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1197, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-05-09 00:00:00 ‚Üí 2020-11-30 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2020-12-01 00:00:00 ‚Üí 2021-11-17 00:00:00\n",
      "\n",
      "=== Forecast Horizon: 21 ===\n",
      "[DEBUG] Fold window i=1344, val_start=1344, val_end=1596, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1596, val_start=1596, val_end=1848, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1848, val_start=1848, val_end=2100, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2100, val_start=2100, val_end=2352, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2352, val_start=2352, val_end=2604, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2604, val_start=2604, val_end=2856, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2856, val_start=2856, val_end=3108, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3108, val_start=3108, val_end=3360, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3360, val_start=3360, val_end=3612, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3612, val_start=3612, val_end=3864, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3864, val_start=3864, val_end=4116, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4116, val_start=4116, val_end=4368, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4368, val_start=4368, val_end=4620, X_val.shape=(1595, 74), Y_val.shape=(252, 6)\n",
      "[INFO] Generated 13 non-overlapping folds for forecast horizon 21\n",
      "[FOLD 1]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2008-12-17 00:00:00\n",
      "    ‚û§ Val:   2008-12-18 00:00:00 ‚Üí 2009-12-04 00:00:00\n",
      "    üß† X_train_seq.shape = (1, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2008-12-17 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2008-12-18 00:00:00 ‚Üí 2009-12-04 00:00:00\n",
      "[FOLD 2]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2009-12-04 00:00:00\n",
      "    ‚û§ Val:   2009-12-07 00:00:00 ‚Üí 2010-11-23 00:00:00\n",
      "    üß† X_train_seq.shape = (253, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (253, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2009-12-04 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2009-12-07 00:00:00 ‚Üí 2010-11-23 00:00:00\n",
      "[FOLD 3]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2010-11-23 00:00:00\n",
      "    ‚û§ Val:   2010-11-24 00:00:00 ‚Üí 2011-11-10 00:00:00\n",
      "    üß† X_train_seq.shape = (505, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (505, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2010-11-23 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2010-11-24 00:00:00 ‚Üí 2011-11-10 00:00:00\n",
      "[FOLD 4]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2011-11-10 00:00:00\n",
      "    ‚û§ Val:   2011-11-11 00:00:00 ‚Üí 2012-10-29 00:00:00\n",
      "    üß† X_train_seq.shape = (757, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (757, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2011-11-10 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2011-11-11 00:00:00 ‚Üí 2012-10-29 00:00:00\n",
      "[FOLD 5]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2012-10-29 00:00:00\n",
      "    ‚û§ Val:   2012-10-30 00:00:00 ‚Üí 2013-10-16 00:00:00\n",
      "    üß† X_train_seq.shape = (1009, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1009, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2012-10-29 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2012-10-30 00:00:00 ‚Üí 2013-10-16 00:00:00\n",
      "[FOLD 6]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2013-10-16 00:00:00\n",
      "    ‚û§ Val:   2013-10-17 00:00:00 ‚Üí 2014-10-03 00:00:00\n",
      "    üß† X_train_seq.shape = (1261, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1261, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2013-10-16 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2013-10-17 00:00:00 ‚Üí 2014-10-03 00:00:00\n",
      "[FOLD 7]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2014-10-03 00:00:00\n",
      "    ‚û§ Val:   2014-10-06 00:00:00 ‚Üí 2015-09-22 00:00:00\n",
      "    üß† X_train_seq.shape = (1513, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1513, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2014-10-03 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2014-10-06 00:00:00 ‚Üí 2015-09-22 00:00:00\n",
      "[FOLD 8]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2015-09-22 00:00:00\n",
      "    ‚û§ Val:   2015-09-23 00:00:00 ‚Üí 2016-09-08 00:00:00\n",
      "    üß† X_train_seq.shape = (1765, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1765, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2015-09-22 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2015-09-23 00:00:00 ‚Üí 2016-09-08 00:00:00\n",
      "[FOLD 9]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2016-09-08 00:00:00\n",
      "    ‚û§ Val:   2016-09-09 00:00:00 ‚Üí 2017-08-28 00:00:00\n",
      "    üß† X_train_seq.shape = (2017, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2017, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2016-09-08 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2016-09-09 00:00:00 ‚Üí 2017-08-28 00:00:00\n",
      "[FOLD 10]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2017-08-28 00:00:00\n",
      "    ‚û§ Val:   2017-08-29 00:00:00 ‚Üí 2018-08-15 00:00:00\n",
      "    üß† X_train_seq.shape = (2269, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2269, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2017-08-28 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2017-08-29 00:00:00 ‚Üí 2018-08-15 00:00:00\n",
      "[FOLD 11]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2018-08-15 00:00:00\n",
      "    ‚û§ Val:   2018-08-16 00:00:00 ‚Üí 2019-08-02 00:00:00\n",
      "    üß† X_train_seq.shape = (2521, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2521, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2018-08-15 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2018-08-16 00:00:00 ‚Üí 2019-08-02 00:00:00\n",
      "[FOLD 12]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2019-08-02 00:00:00\n",
      "    ‚û§ Val:   2019-08-05 00:00:00 ‚Üí 2020-07-21 00:00:00\n",
      "    üß† X_train_seq.shape = (2773, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2773, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2019-08-02 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2019-08-05 00:00:00 ‚Üí 2020-07-21 00:00:00\n",
      "[FOLD 13]\n",
      "    ‚û§ Train: 2003-10-24 00:00:00 ‚Üí 2020-07-21 00:00:00\n",
      "    ‚û§ Val:   2020-07-22 00:00:00 ‚Üí 2021-07-08 00:00:00\n",
      "    üß† X_train_seq.shape = (3025, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (3025, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2008-12-17 00:00:00 ‚Üí 2020-07-21 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2020-07-22 00:00:00 ‚Üí 2021-07-08 00:00:00\n",
      "\n",
      "=== Forecast Horizon: 63 ===\n",
      "[DEBUG] Fold window i=1323, val_start=1323, val_end=1575, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1575, val_start=1575, val_end=1827, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1827, val_start=1827, val_end=2079, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2079, val_start=2079, val_end=2331, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2331, val_start=2331, val_end=2583, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2583, val_start=2583, val_end=2835, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2835, val_start=2835, val_end=3087, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3087, val_start=3087, val_end=3339, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3339, val_start=3339, val_end=3591, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3591, val_start=3591, val_end=3843, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3843, val_start=3843, val_end=4095, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4095, val_start=4095, val_end=4347, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4347, val_start=4347, val_end=4599, X_val.shape=(1574, 74), Y_val.shape=(252, 6)\n",
      "[INFO] Generated 13 non-overlapping folds for forecast horizon 63\n",
      "[FOLD 1]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2009-01-15 00:00:00\n",
      "    ‚û§ Val:   2009-01-16 00:00:00 ‚Üí 2010-01-04 00:00:00\n",
      "    üß† X_train_seq.shape = (1, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (1, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2009-01-15 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2009-01-16 00:00:00 ‚Üí 2010-01-04 00:00:00\n",
      "[FOLD 2]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2010-01-04 00:00:00\n",
      "    ‚û§ Val:   2010-01-05 00:00:00 ‚Üí 2010-12-22 00:00:00\n",
      "    üß† X_train_seq.shape = (253, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (253, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2010-01-04 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2010-01-05 00:00:00 ‚Üí 2010-12-22 00:00:00\n",
      "[FOLD 3]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2010-12-22 00:00:00\n",
      "    ‚û§ Val:   2010-12-23 00:00:00 ‚Üí 2011-12-09 00:00:00\n",
      "    üß† X_train_seq.shape = (505, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (505, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2010-12-22 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2010-12-23 00:00:00 ‚Üí 2011-12-09 00:00:00\n",
      "[FOLD 4]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2011-12-09 00:00:00\n",
      "    ‚û§ Val:   2011-12-12 00:00:00 ‚Üí 2012-11-27 00:00:00\n",
      "    üß† X_train_seq.shape = (757, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (757, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2011-12-09 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2011-12-12 00:00:00 ‚Üí 2012-11-27 00:00:00\n",
      "[FOLD 5]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2012-11-27 00:00:00\n",
      "    ‚û§ Val:   2012-11-28 00:00:00 ‚Üí 2013-11-14 00:00:00\n",
      "    üß† X_train_seq.shape = (1009, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (1009, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2012-11-27 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2012-11-28 00:00:00 ‚Üí 2013-11-14 00:00:00\n",
      "[FOLD 6]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2013-11-14 00:00:00\n",
      "    ‚û§ Val:   2013-11-15 00:00:00 ‚Üí 2014-11-03 00:00:00\n",
      "    üß† X_train_seq.shape = (1261, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (1261, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2013-11-14 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2013-11-15 00:00:00 ‚Üí 2014-11-03 00:00:00\n",
      "[FOLD 7]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2014-11-03 00:00:00\n",
      "    ‚û§ Val:   2014-11-04 00:00:00 ‚Üí 2015-10-21 00:00:00\n",
      "    üß† X_train_seq.shape = (1513, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (1513, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2014-11-03 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2014-11-04 00:00:00 ‚Üí 2015-10-21 00:00:00\n",
      "[FOLD 8]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2015-10-21 00:00:00\n",
      "    ‚û§ Val:   2015-10-22 00:00:00 ‚Üí 2016-10-07 00:00:00\n",
      "    üß† X_train_seq.shape = (1765, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (1765, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2015-10-21 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2015-10-22 00:00:00 ‚Üí 2016-10-07 00:00:00\n",
      "[FOLD 9]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2016-10-07 00:00:00\n",
      "    ‚û§ Val:   2016-10-10 00:00:00 ‚Üí 2017-09-26 00:00:00\n",
      "    üß† X_train_seq.shape = (2017, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (2017, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2016-10-07 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2016-10-10 00:00:00 ‚Üí 2017-09-26 00:00:00\n",
      "[FOLD 10]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2017-09-26 00:00:00\n",
      "    ‚û§ Val:   2017-09-27 00:00:00 ‚Üí 2018-09-13 00:00:00\n",
      "    üß† X_train_seq.shape = (2269, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (2269, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2017-09-26 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2017-09-27 00:00:00 ‚Üí 2018-09-13 00:00:00\n",
      "[FOLD 11]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2018-09-13 00:00:00\n",
      "    ‚û§ Val:   2018-09-14 00:00:00 ‚Üí 2019-09-02 00:00:00\n",
      "    üß† X_train_seq.shape = (2521, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (2521, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2018-09-13 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2018-09-14 00:00:00 ‚Üí 2019-09-02 00:00:00\n",
      "[FOLD 12]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2019-09-02 00:00:00\n",
      "    ‚û§ Val:   2019-09-03 00:00:00 ‚Üí 2020-08-19 00:00:00\n",
      "    üß† X_train_seq.shape = (2773, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (2773, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2019-09-02 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2019-09-03 00:00:00 ‚Üí 2020-08-19 00:00:00\n",
      "[FOLD 13]\n",
      "    ‚û§ Train: 2003-12-23 00:00:00 ‚Üí 2020-08-19 00:00:00\n",
      "    ‚û§ Val:   2020-08-20 00:00:00 ‚Üí 2021-08-06 00:00:00\n",
      "    üß† X_train_seq.shape = (3025, 1260, 74)\n",
      "    üß† Y_train_seq.shape = (3025, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1260, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2009-01-15 00:00:00 ‚Üí 2020-08-19 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2020-08-20 00:00:00 ‚Üí 2021-08-06 00:00:00\n",
      "\n",
      "=== Forecast Horizon: 252 ===\n",
      "[DEBUG] Fold window i=1575, val_start=1575, val_end=1827, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=1827, val_start=1827, val_end=2079, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2079, val_start=2079, val_end=2331, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2331, val_start=2331, val_end=2583, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2583, val_start=2583, val_end=2835, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=2835, val_start=2835, val_end=3087, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3087, val_start=3087, val_end=3339, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3339, val_start=3339, val_end=3591, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3591, val_start=3591, val_end=3843, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=3843, val_start=3843, val_end=4095, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[DEBUG] Fold window i=4095, val_start=4095, val_end=4347, X_val.shape=(1826, 74), Y_val.shape=(252, 6)\n",
      "[INFO] Generated 11 non-overlapping folds for forecast horizon 252\n",
      "[FOLD 1]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2010-09-24 00:00:00\n",
      "    ‚û§ Val:   2010-09-27 00:00:00 ‚Üí 2011-09-13 00:00:00\n",
      "    üß† X_train_seq.shape = (1, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2010-09-24 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2010-09-27 00:00:00 ‚Üí 2011-09-13 00:00:00\n",
      "[FOLD 2]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2011-09-13 00:00:00\n",
      "    ‚û§ Val:   2011-09-14 00:00:00 ‚Üí 2012-08-30 00:00:00\n",
      "    üß† X_train_seq.shape = (253, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (253, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2011-09-13 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2011-09-14 00:00:00 ‚Üí 2012-08-30 00:00:00\n",
      "[FOLD 3]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2012-08-30 00:00:00\n",
      "    ‚û§ Val:   2012-08-31 00:00:00 ‚Üí 2013-08-19 00:00:00\n",
      "    üß† X_train_seq.shape = (505, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (505, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2012-08-30 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2012-08-31 00:00:00 ‚Üí 2013-08-19 00:00:00\n",
      "[FOLD 4]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2013-08-19 00:00:00\n",
      "    ‚û§ Val:   2013-08-20 00:00:00 ‚Üí 2014-08-06 00:00:00\n",
      "    üß† X_train_seq.shape = (757, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (757, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2013-08-19 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2013-08-20 00:00:00 ‚Üí 2014-08-06 00:00:00\n",
      "[FOLD 5]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2014-08-06 00:00:00\n",
      "    ‚û§ Val:   2014-08-07 00:00:00 ‚Üí 2015-07-24 00:00:00\n",
      "    üß† X_train_seq.shape = (1009, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1009, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2014-08-06 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2014-08-07 00:00:00 ‚Üí 2015-07-24 00:00:00\n",
      "[FOLD 6]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2015-07-24 00:00:00\n",
      "    ‚û§ Val:   2015-07-27 00:00:00 ‚Üí 2016-07-12 00:00:00\n",
      "    üß† X_train_seq.shape = (1261, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1261, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2015-07-24 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2015-07-27 00:00:00 ‚Üí 2016-07-12 00:00:00\n",
      "[FOLD 7]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2016-07-12 00:00:00\n",
      "    ‚û§ Val:   2016-07-13 00:00:00 ‚Üí 2017-06-29 00:00:00\n",
      "    üß† X_train_seq.shape = (1513, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1513, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2016-07-12 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2016-07-13 00:00:00 ‚Üí 2017-06-29 00:00:00\n",
      "[FOLD 8]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2017-06-29 00:00:00\n",
      "    ‚û§ Val:   2017-06-30 00:00:00 ‚Üí 2018-06-18 00:00:00\n",
      "    üß† X_train_seq.shape = (1765, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (1765, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2017-06-29 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2017-06-30 00:00:00 ‚Üí 2018-06-18 00:00:00\n",
      "[FOLD 9]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2018-06-18 00:00:00\n",
      "    ‚û§ Val:   2018-06-19 00:00:00 ‚Üí 2019-06-05 00:00:00\n",
      "    üß† X_train_seq.shape = (2017, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2017, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2018-06-18 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2018-06-19 00:00:00 ‚Üí 2019-06-05 00:00:00\n",
      "[FOLD 10]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2019-06-05 00:00:00\n",
      "    ‚û§ Val:   2019-06-06 00:00:00 ‚Üí 2020-05-22 00:00:00\n",
      "    üß† X_train_seq.shape = (2269, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2269, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2019-06-05 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2019-06-06 00:00:00 ‚Üí 2020-05-22 00:00:00\n",
      "[FOLD 11]\n",
      "    ‚û§ Train: 2004-09-13 00:00:00 ‚Üí 2020-05-22 00:00:00\n",
      "    ‚û§ Val:   2020-05-25 00:00:00 ‚Üí 2021-05-11 00:00:00\n",
      "    üß† X_train_seq.shape = (2521, 1323, 74)\n",
      "    üß† Y_train_seq.shape = (2521, 6)\n",
      "    üß† X_val_seq.shape   = (252, 1323, 74)\n",
      "    üß† Y_val_seq.shape   = (252, 6)\n",
      "    ‚úîÔ∏è Train target window: 2010-09-24 00:00:00 ‚Üí 2020-05-22 00:00:00\n",
      "    ‚úîÔ∏è Val target window:   2020-05-25 00:00:00 ‚Üí 2021-05-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Run Diagnostics ---------------------- #\n",
    "for h in forecast_horizons:\n",
    "    print(f\"\\n=== Forecast Horizon: {h} ===\")\n",
    "    sequence_length = sequence_length_map[h]\n",
    "\n",
    "    # Load X and Y\n",
    "    X_df = pd.read_csv(r'C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\Data Processing\\Output\\Independent\\X_df_filtered.csv', index_col=0, parse_dates=True)\n",
    "    Y_df = pd.read_csv(fr'C:\\Users\\azorb\\PycharmProjects\\Predicting the Yield Curve\\Data Processing\\Output\\Dependent\\Classification\\Y_df_change_dir_{h}.csv', index_col=0, parse_dates=True)\n",
    "    X_df.index = pd.to_datetime(X_df.index)\n",
    "    Y_df.index = pd.to_datetime(Y_df.index)\n",
    "\n",
    "    X_shifted = shift_X_by_horizon(X_df, h)\n",
    "    common_idx = X_shifted.index.intersection(Y_df.index)\n",
    "    X_aligned = X_shifted.loc[common_idx]\n",
    "    Y_aligned = Y_df.loc[common_idx]\n",
    "\n",
    "    folds = get_expanding_folds(X_aligned, Y_aligned, h, sequence_length_map, val_window_num_sequences, holdout_base)\n",
    "\n",
    "    for i, fold in enumerate(folds):\n",
    "        print(f\"[FOLD {i+1}]\")\n",
    "        print(f\"    ‚û§ Train: {fold['train_start_date']} ‚Üí {fold['train_end_date']}\")\n",
    "        print(f\"    ‚û§ Val:   {fold['val_start_date']} ‚Üí {fold['val_end_date']}\")\n",
    "\n",
    "        X_train_std, X_val_std = standardize_fold(fold[\"X_train\"], fold[\"X_val\"])\n",
    "        X_train_seq, Y_train_seq, ts_train = generate_X_sequences_from_Y(X_train_std, fold[\"Y_train\"], sequence_length, h)\n",
    "        X_val_seq, Y_val_seq, ts_val = generate_X_sequences_from_Y(X_val_std, fold[\"Y_val\"], sequence_length, h)\n",
    "\n",
    "        print(f\"    üß† X_train_seq.shape = {X_train_seq.shape}\")\n",
    "        print(f\"    üß† Y_train_seq.shape = {Y_train_seq.shape}\")\n",
    "        print(f\"    üß† X_val_seq.shape   = {X_val_seq.shape}\")\n",
    "        print(f\"    üß† Y_val_seq.shape   = {Y_val_seq.shape}\")\n",
    "        if len(ts_train):\n",
    "            print(f\"    ‚úîÔ∏è Train target window: {ts_train[0]} ‚Üí {ts_train[-1]}\")\n",
    "        if len(ts_val):\n",
    "            print(f\"    ‚úîÔ∏è Val target window:   {ts_val[0]} ‚Üí {ts_val[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebc013986906094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 11:28:07,326] A new study created in memory with name: no-name-af171a09-e814-4e7e-be0d-3b412b82f251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Forecast Horizon: 1 ===\n",
      "[INFO] Generated 8 folds for forecast horizon 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 11:28:36,273] Trial 0 finished with value: -0.4247086622213306 and parameters: {'hidden_dim': 98, 'num_layers': 1, 'dropout': 0.2276490796352143, 'learning_rate': 0.0004122960660443855, 'batch_size': 128}. Best is trial 0 with value: -0.4247086622213306.\n",
      "[I 2025-05-11 11:29:32,680] Trial 1 finished with value: -0.4863466531338707 and parameters: {'hidden_dim': 126, 'num_layers': 2, 'dropout': 0.2895212610734162, 'learning_rate': 0.0035656209620512943, 'batch_size': 16}. Best is trial 1 with value: -0.4863466531338707.\n",
      "[I 2025-05-11 11:29:59,235] Trial 2 finished with value: -0.47561975036998483 and parameters: {'hidden_dim': 69, 'num_layers': 2, 'dropout': 0.32774522966985487, 'learning_rate': 0.0002023610070712248, 'batch_size': 128}. Best is trial 1 with value: -0.4863466531338707.\n",
      "[I 2025-05-11 11:30:30,935] Trial 3 finished with value: -0.45252246447470207 and parameters: {'hidden_dim': 70, 'num_layers': 2, 'dropout': 0.172800444770923, 'learning_rate': 0.0006842077861165199, 'batch_size': 64}. Best is trial 1 with value: -0.4863466531338707.\n",
      "[I 2025-05-11 11:30:57,069] Trial 4 finished with value: -0.4073950520735591 and parameters: {'hidden_dim': 102, 'num_layers': 1, 'dropout': 0.465670823934781, 'learning_rate': 0.0011471735921989446, 'batch_size': 128}. Best is trial 1 with value: -0.4863466531338707.\n",
      "[I 2025-05-11 11:31:33,199] Trial 5 finished with value: -0.542395619668946 and parameters: {'hidden_dim': 44, 'num_layers': 2, 'dropout': 0.37182586652106697, 'learning_rate': 0.003683427723693766, 'batch_size': 32}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:32:26,882] Trial 6 finished with value: -0.36366266508011286 and parameters: {'hidden_dim': 57, 'num_layers': 1, 'dropout': 0.4013286100829695, 'learning_rate': 0.00010706897930051511, 'batch_size': 16}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:33:13,656] Trial 7 finished with value: -0.3794413815537883 and parameters: {'hidden_dim': 53, 'num_layers': 1, 'dropout': 0.4653613370530977, 'learning_rate': 0.00024252042305606493, 'batch_size': 16}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:33:55,679] Trial 8 finished with value: -0.4409998220926702 and parameters: {'hidden_dim': 37, 'num_layers': 1, 'dropout': 0.3455474223685915, 'learning_rate': 0.0014640970710719453, 'batch_size': 32}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:34:39,604] Trial 9 finished with value: -0.3508068610037843 and parameters: {'hidden_dim': 123, 'num_layers': 1, 'dropout': 0.13985357153313097, 'learning_rate': 0.0018351221615148835, 'batch_size': 32}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:35:15,802] Trial 10 finished with value: -0.48115246471893985 and parameters: {'hidden_dim': 38, 'num_layers': 2, 'dropout': 0.39895158317300594, 'learning_rate': 0.0098036460637825, 'batch_size': 32}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:36:13,994] Trial 11 finished with value: -0.5337341337120267 and parameters: {'hidden_dim': 124, 'num_layers': 2, 'dropout': 0.26154056600253356, 'learning_rate': 0.0053647679271085985, 'batch_size': 16}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:36:44,469] Trial 12 finished with value: -0.4573456020913468 and parameters: {'hidden_dim': 92, 'num_layers': 2, 'dropout': 0.24588587224945457, 'learning_rate': 0.006190263427460322, 'batch_size': 64}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:37:24,948] Trial 13 finished with value: -0.48850680106227223 and parameters: {'hidden_dim': 85, 'num_layers': 2, 'dropout': 0.2547223946102023, 'learning_rate': 0.004090581101446843, 'batch_size': 32}. Best is trial 5 with value: -0.542395619668946.\n",
      "[I 2025-05-11 11:38:23,584] Trial 14 finished with value: -0.5508163671502837 and parameters: {'hidden_dim': 111, 'num_layers': 2, 'dropout': 0.382515337195703, 'learning_rate': 0.0026744242996887867, 'batch_size': 16}. Best is trial 14 with value: -0.5508163671502837.\n",
      "[I 2025-05-11 11:39:27,594] Trial 15 finished with value: -0.48514580760519055 and parameters: {'hidden_dim': 108, 'num_layers': 2, 'dropout': 0.3860522776695834, 'learning_rate': 0.002382539431542395, 'batch_size': 16}. Best is trial 14 with value: -0.5508163671502837.\n",
      "[I 2025-05-11 11:40:09,815] Trial 16 finished with value: -0.5395415996242655 and parameters: {'hidden_dim': 75, 'num_layers': 2, 'dropout': 0.3586449566995066, 'learning_rate': 0.0029813888908597607, 'batch_size': 32}. Best is trial 14 with value: -0.5508163671502837.\n",
      "[I 2025-05-11 11:40:47,834] Trial 17 finished with value: -0.3710838262200759 and parameters: {'hidden_dim': 112, 'num_layers': 2, 'dropout': 0.436281632529667, 'learning_rate': 0.0008587600960319674, 'batch_size': 64}. Best is trial 14 with value: -0.5508163671502837.\n",
      "[I 2025-05-11 11:41:24,708] Trial 18 finished with value: -0.5413143791825815 and parameters: {'hidden_dim': 53, 'num_layers': 2, 'dropout': 0.3039807426145141, 'learning_rate': 0.007801929526883494, 'batch_size': 32}. Best is trial 14 with value: -0.5508163671502837.\n",
      "[I 2025-05-11 11:42:17,242] Trial 19 finished with value: -0.5516305400778261 and parameters: {'hidden_dim': 84, 'num_layers': 2, 'dropout': 0.424931900458637, 'learning_rate': 0.0022486783930516746, 'batch_size': 16}. Best is trial 19 with value: -0.5516305400778261.\n",
      "[I 2025-05-11 11:43:16,430] Trial 20 finished with value: -0.5537320976479521 and parameters: {'hidden_dim': 87, 'num_layers': 2, 'dropout': 0.49644774829525107, 'learning_rate': 0.002040176001804273, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:44:05,609] Trial 21 finished with value: -0.5518282541547677 and parameters: {'hidden_dim': 83, 'num_layers': 2, 'dropout': 0.4905458725447064, 'learning_rate': 0.0021083396844553317, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:44:54,966] Trial 22 finished with value: -0.5204160183688047 and parameters: {'hidden_dim': 84, 'num_layers': 2, 'dropout': 0.47811602909709716, 'learning_rate': 0.001773379421354805, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:45:51,437] Trial 23 finished with value: -0.47593540989737015 and parameters: {'hidden_dim': 90, 'num_layers': 2, 'dropout': 0.4860185676405147, 'learning_rate': 0.0006310939907100848, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:46:42,159] Trial 24 finished with value: -0.4647574149891582 and parameters: {'hidden_dim': 78, 'num_layers': 2, 'dropout': 0.4364092319461347, 'learning_rate': 0.0014461630787260583, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:47:34,629] Trial 25 finished with value: -0.5513988136272476 and parameters: {'hidden_dim': 65, 'num_layers': 2, 'dropout': 0.49502472459534735, 'learning_rate': 0.0023185625112591667, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:48:32,564] Trial 26 finished with value: -0.46513979864153276 and parameters: {'hidden_dim': 94, 'num_layers': 2, 'dropout': 0.43213228842490103, 'learning_rate': 0.0009622749728567902, 'batch_size': 16}. Best is trial 20 with value: -0.5537320976479521.\n",
      "[I 2025-05-11 11:49:24,746] Trial 27 finished with value: -0.5548958508540118 and parameters: {'hidden_dim': 84, 'num_layers': 2, 'dropout': 0.45710576033956674, 'learning_rate': 0.004688535399076738, 'batch_size': 16}. Best is trial 27 with value: -0.5548958508540118.\n",
      "[I 2025-05-11 11:50:32,538] Trial 28 finished with value: -0.49436891392523913 and parameters: {'hidden_dim': 103, 'num_layers': 2, 'dropout': 0.49886180239933764, 'learning_rate': 0.0049724410768192005, 'batch_size': 16}. Best is trial 27 with value: -0.5548958508540118.\n",
      "[I 2025-05-11 11:50:59,573] Trial 29 finished with value: -0.47653983208182404 and parameters: {'hidden_dim': 77, 'num_layers': 1, 'dropout': 0.45742694033233117, 'learning_rate': 0.007153752567255967, 'batch_size': 128}. Best is trial 27 with value: -0.5548958508540118.\n",
      "[I 2025-05-11 11:50:59,612] A new study created in memory with name: no-name-43720cb5-7b7c-438a-a166-9bcf4f3f6ad0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 1: Best Params = {'hidden_dim': 84, 'num_layers': 2, 'dropout': 0.45710576033956674, 'learning_rate': 0.004688535399076738, 'batch_size': 16}, Best F1 = 0.5549\n",
      "\n",
      "=== Forecast Horizon: 5 ===\n",
      "[INFO] Generated 8 folds for forecast horizon 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 11:51:53,612] Trial 0 finished with value: -0.32030847099713206 and parameters: {'hidden_dim': 69, 'num_layers': 2, 'dropout': 0.3148187575916974, 'learning_rate': 0.0004258480821630382, 'batch_size': 16}. Best is trial 0 with value: -0.32030847099713206.\n",
      "[I 2025-05-11 11:53:18,725] Trial 1 finished with value: -0.5108031206681662 and parameters: {'hidden_dim': 110, 'num_layers': 2, 'dropout': 0.4595409993291274, 'learning_rate': 0.0013881241700925003, 'batch_size': 16}. Best is trial 1 with value: -0.5108031206681662.\n",
      "[I 2025-05-11 11:54:06,179] Trial 2 finished with value: -0.4090906835667759 and parameters: {'hidden_dim': 54, 'num_layers': 1, 'dropout': 0.19127230712937734, 'learning_rate': 0.0027655499093746216, 'batch_size': 16}. Best is trial 1 with value: -0.5108031206681662.\n",
      "[I 2025-05-11 11:54:52,791] Trial 3 finished with value: -0.40551460319060095 and parameters: {'hidden_dim': 32, 'num_layers': 2, 'dropout': 0.4940906514754819, 'learning_rate': 0.0014083285381945923, 'batch_size': 16}. Best is trial 1 with value: -0.5108031206681662.\n",
      "[I 2025-05-11 11:55:44,728] Trial 4 finished with value: -0.5482964955974565 and parameters: {'hidden_dim': 92, 'num_layers': 1, 'dropout': 0.21557525139220088, 'learning_rate': 0.0004883533160474792, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 11:56:37,750] Trial 5 finished with value: -0.38907904594421694 and parameters: {'hidden_dim': 62, 'num_layers': 2, 'dropout': 0.14504453970453846, 'learning_rate': 0.0028191052323359935, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 11:57:32,447] Trial 6 finished with value: -0.3428224960888501 and parameters: {'hidden_dim': 67, 'num_layers': 2, 'dropout': 0.13825318002446219, 'learning_rate': 0.00010854554636903587, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 11:58:03,318] Trial 7 finished with value: -0.37875736987682374 and parameters: {'hidden_dim': 42, 'num_layers': 1, 'dropout': 0.4245816099157754, 'learning_rate': 0.0017174807962681959, 'batch_size': 128}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 11:58:18,650] Trial 8 finished with value: -0.3747038539140163 and parameters: {'hidden_dim': 65, 'num_layers': 1, 'dropout': 0.36764298450034527, 'learning_rate': 0.0006073613382120015, 'batch_size': 128}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 11:59:18,146] Trial 9 finished with value: -0.5280174581943466 and parameters: {'hidden_dim': 89, 'num_layers': 2, 'dropout': 0.1826686584041527, 'learning_rate': 0.0005193343983442457, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 11:59:54,542] Trial 10 finished with value: -0.44412845375674975 and parameters: {'hidden_dim': 127, 'num_layers': 1, 'dropout': 0.2544727529007419, 'learning_rate': 0.008269422823644084, 'batch_size': 64}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:00:26,825] Trial 11 finished with value: -0.38850650999669056 and parameters: {'hidden_dim': 92, 'num_layers': 1, 'dropout': 0.2326539733966481, 'learning_rate': 0.00016772114610428437, 'batch_size': 32}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:00:59,996] Trial 12 finished with value: -0.4202293448879884 and parameters: {'hidden_dim': 91, 'num_layers': 2, 'dropout': 0.10948615205260623, 'learning_rate': 0.0003259914965299727, 'batch_size': 64}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:01:44,790] Trial 13 finished with value: -0.49470509065715146 and parameters: {'hidden_dim': 87, 'num_layers': 1, 'dropout': 0.20466390516347696, 'learning_rate': 0.0006954244015925634, 'batch_size': 32}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:02:39,200] Trial 14 finished with value: -0.4889427518498497 and parameters: {'hidden_dim': 105, 'num_layers': 1, 'dropout': 0.3027896693446828, 'learning_rate': 0.00024462097421865017, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:04:07,405] Trial 15 finished with value: -0.5183525825023996 and parameters: {'hidden_dim': 105, 'num_layers': 2, 'dropout': 0.18176590558664146, 'learning_rate': 0.0007311124853090881, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:04:36,093] Trial 16 finished with value: -0.41804524734781906 and parameters: {'hidden_dim': 79, 'num_layers': 1, 'dropout': 0.2514849902476427, 'learning_rate': 0.00041311843970192507, 'batch_size': 128}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:05:23,475] Trial 17 finished with value: -0.3965040733669276 and parameters: {'hidden_dim': 120, 'num_layers': 2, 'dropout': 0.35782900260867734, 'learning_rate': 0.0001842041789923965, 'batch_size': 32}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:05:55,105] Trial 18 finished with value: -0.49420358862011005 and parameters: {'hidden_dim': 79, 'num_layers': 2, 'dropout': 0.27271825757874524, 'learning_rate': 0.007303783838236285, 'batch_size': 64}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:06:56,694] Trial 19 finished with value: -0.5387685795333084 and parameters: {'hidden_dim': 101, 'num_layers': 1, 'dropout': 0.1592214462315923, 'learning_rate': 0.0008590902860078946, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:07:55,438] Trial 20 finished with value: -0.4357266470460114 and parameters: {'hidden_dim': 99, 'num_layers': 1, 'dropout': 0.10939436207052472, 'learning_rate': 0.0009646355124459833, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:08:57,629] Trial 21 finished with value: -0.47024826928182073 and parameters: {'hidden_dim': 115, 'num_layers': 1, 'dropout': 0.16170244357958863, 'learning_rate': 0.000550070768423101, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:09:58,006] Trial 22 finished with value: -0.5068330467937397 and parameters: {'hidden_dim': 98, 'num_layers': 1, 'dropout': 0.20773666347653494, 'learning_rate': 0.00092509968586336, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:10:58,259] Trial 23 finished with value: -0.4029592267918176 and parameters: {'hidden_dim': 85, 'num_layers': 1, 'dropout': 0.166470569493044, 'learning_rate': 0.0002970281418046604, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:11:50,723] Trial 24 finished with value: -0.5015550872630761 and parameters: {'hidden_dim': 96, 'num_layers': 1, 'dropout': 0.22577751381693978, 'learning_rate': 0.002063806421288825, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:12:40,360] Trial 25 finished with value: -0.43863620217507443 and parameters: {'hidden_dim': 76, 'num_layers': 1, 'dropout': 0.13352645078304223, 'learning_rate': 0.00443794093270938, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:13:31,360] Trial 26 finished with value: -0.5056152034207302 and parameters: {'hidden_dim': 103, 'num_layers': 2, 'dropout': 0.2761293557074084, 'learning_rate': 0.00046626275466761145, 'batch_size': 32}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:14:03,130] Trial 27 finished with value: -0.4616822092206109 and parameters: {'hidden_dim': 86, 'num_layers': 1, 'dropout': 0.21333343310517902, 'learning_rate': 0.0010632982757183382, 'batch_size': 64}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:14:31,169] Trial 28 finished with value: -0.3522267544122575 and parameters: {'hidden_dim': 112, 'num_layers': 2, 'dropout': 0.1705967558860694, 'learning_rate': 0.00021475864001864692, 'batch_size': 128}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:15:23,446] Trial 29 finished with value: -0.5073774591538954 and parameters: {'hidden_dim': 76, 'num_layers': 1, 'dropout': 0.3270635752379857, 'learning_rate': 0.00042147183229534037, 'batch_size': 16}. Best is trial 4 with value: -0.5482964955974565.\n",
      "[I 2025-05-11 12:15:23,475] A new study created in memory with name: no-name-dd8eb031-3c47-4d3c-b550-8f509e847ab7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 5: Best Params = {'hidden_dim': 92, 'num_layers': 1, 'dropout': 0.21557525139220088, 'learning_rate': 0.0004883533160474792, 'batch_size': 16}, Best F1 = 0.5483\n",
      "\n",
      "=== Forecast Horizon: 21 ===\n",
      "[INFO] Generated 8 folds for forecast horizon 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 12:16:11,188] Trial 0 finished with value: -0.44044651986851063 and parameters: {'hidden_dim': 91, 'num_layers': 1, 'dropout': 0.21806228453940268, 'learning_rate': 0.007851756185983515, 'batch_size': 16}. Best is trial 0 with value: -0.44044651986851063.\n",
      "[I 2025-05-11 12:16:53,270] Trial 1 finished with value: -0.43664169096580063 and parameters: {'hidden_dim': 52, 'num_layers': 1, 'dropout': 0.16366168509839463, 'learning_rate': 0.0004151428371325672, 'batch_size': 16}. Best is trial 0 with value: -0.44044651986851063.\n",
      "[I 2025-05-11 12:17:26,153] Trial 2 finished with value: -0.5485618193240784 and parameters: {'hidden_dim': 79, 'num_layers': 2, 'dropout': 0.41867948098018837, 'learning_rate': 0.00027072268062802376, 'batch_size': 64}. Best is trial 2 with value: -0.5485618193240784.\n",
      "[I 2025-05-11 12:18:27,819] Trial 3 finished with value: -0.5671924723740861 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.45793954832430006, 'learning_rate': 0.00029665560470062323, 'batch_size': 16}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:18:51,458] Trial 4 finished with value: -0.5399082192838752 and parameters: {'hidden_dim': 33, 'num_layers': 1, 'dropout': 0.4131516648967831, 'learning_rate': 0.0012968209989763558, 'batch_size': 128}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:19:10,991] Trial 5 finished with value: -0.46862013241187295 and parameters: {'hidden_dim': 73, 'num_layers': 2, 'dropout': 0.28022047890014035, 'learning_rate': 0.00023818542840675, 'batch_size': 32}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:19:18,281] Trial 6 finished with value: -0.4655641366090608 and parameters: {'hidden_dim': 124, 'num_layers': 1, 'dropout': 0.45386483747768425, 'learning_rate': 0.00012713034484845373, 'batch_size': 128}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:19:26,113] Trial 7 finished with value: -0.4278695521611816 and parameters: {'hidden_dim': 35, 'num_layers': 2, 'dropout': 0.491886438646717, 'learning_rate': 0.00021681706018808223, 'batch_size': 128}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:20:22,679] Trial 8 finished with value: -0.4869331369841907 and parameters: {'hidden_dim': 123, 'num_layers': 2, 'dropout': 0.1027860550736929, 'learning_rate': 0.001135201888496935, 'batch_size': 16}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:20:28,182] Trial 9 finished with value: -0.562493567518673 and parameters: {'hidden_dim': 58, 'num_layers': 1, 'dropout': 0.38765302580581273, 'learning_rate': 0.004944898185176338, 'batch_size': 128}. Best is trial 3 with value: -0.5671924723740861.\n",
      "[I 2025-05-11 12:20:55,709] Trial 10 finished with value: -0.5822836016817544 and parameters: {'hidden_dim': 102, 'num_layers': 2, 'dropout': 0.32620679757452586, 'learning_rate': 0.0006218530326018577, 'batch_size': 32}. Best is trial 10 with value: -0.5822836016817544.\n",
      "[I 2025-05-11 12:21:17,738] Trial 11 finished with value: -0.5045211350125545 and parameters: {'hidden_dim': 100, 'num_layers': 2, 'dropout': 0.33314890584232953, 'learning_rate': 0.0006326848867330172, 'batch_size': 32}. Best is trial 10 with value: -0.5822836016817544.\n",
      "[I 2025-05-11 12:21:51,317] Trial 12 finished with value: -0.4946195407747259 and parameters: {'hidden_dim': 100, 'num_layers': 2, 'dropout': 0.3281615402011395, 'learning_rate': 0.0023124563182874403, 'batch_size': 32}. Best is trial 10 with value: -0.5822836016817544.\n",
      "[I 2025-05-11 12:22:06,971] Trial 13 finished with value: -0.5746389694380091 and parameters: {'hidden_dim': 109, 'num_layers': 2, 'dropout': 0.26399586342365833, 'learning_rate': 0.0005998655769136059, 'batch_size': 64}. Best is trial 10 with value: -0.5822836016817544.\n",
      "[I 2025-05-11 12:22:20,468] Trial 14 finished with value: -0.5507820219714471 and parameters: {'hidden_dim': 112, 'num_layers': 2, 'dropout': 0.26117101897848843, 'learning_rate': 0.0006636004134889246, 'batch_size': 64}. Best is trial 10 with value: -0.5822836016817544.\n",
      "[I 2025-05-11 12:22:41,240] Trial 15 finished with value: -0.5693499777999939 and parameters: {'hidden_dim': 107, 'num_layers': 2, 'dropout': 0.22781279258440099, 'learning_rate': 0.001991941167351176, 'batch_size': 64}. Best is trial 10 with value: -0.5822836016817544.\n",
      "[I 2025-05-11 12:22:57,486] Trial 16 finished with value: -0.5953609544051803 and parameters: {'hidden_dim': 87, 'num_layers': 2, 'dropout': 0.3618853403120836, 'learning_rate': 0.0005634761029617077, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:23:20,596] Trial 17 finished with value: -0.43366008768709374 and parameters: {'hidden_dim': 85, 'num_layers': 2, 'dropout': 0.3492159530263469, 'learning_rate': 0.00010912890798545674, 'batch_size': 32}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:23:44,330] Trial 18 finished with value: -0.5109389662072206 and parameters: {'hidden_dim': 69, 'num_layers': 2, 'dropout': 0.37108527721303725, 'learning_rate': 0.00264024915678185, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:24:14,864] Trial 19 finished with value: -0.479242857094389 and parameters: {'hidden_dim': 85, 'num_layers': 2, 'dropout': 0.3072463703861248, 'learning_rate': 0.000901976711633171, 'batch_size': 32}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:24:36,800] Trial 20 finished with value: -0.5879707934308637 and parameters: {'hidden_dim': 64, 'num_layers': 1, 'dropout': 0.20823050637944018, 'learning_rate': 0.0004241920617934889, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:25:06,730] Trial 21 finished with value: -0.4825168586773209 and parameters: {'hidden_dim': 58, 'num_layers': 1, 'dropout': 0.17547937707836825, 'learning_rate': 0.0004209831893578105, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:25:54,375] Trial 22 finished with value: -0.5547046743879361 and parameters: {'hidden_dim': 68, 'num_layers': 1, 'dropout': 0.2126847041851182, 'learning_rate': 0.000443055209643558, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:26:13,084] Trial 23 finished with value: -0.4896583782976256 and parameters: {'hidden_dim': 46, 'num_layers': 1, 'dropout': 0.3014748197143919, 'learning_rate': 0.0001657350470226196, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:26:47,036] Trial 24 finished with value: -0.5007946334889369 and parameters: {'hidden_dim': 79, 'num_layers': 1, 'dropout': 0.10937519028903073, 'learning_rate': 0.0015858172011950016, 'batch_size': 32}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:27:09,928] Trial 25 finished with value: -0.44163866446637545 and parameters: {'hidden_dim': 62, 'num_layers': 2, 'dropout': 0.3732350252243469, 'learning_rate': 0.000820460423916659, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:27:32,568] Trial 26 finished with value: -0.42695074983521086 and parameters: {'hidden_dim': 89, 'num_layers': 1, 'dropout': 0.24544761131126, 'learning_rate': 0.0003554308983046278, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:28:00,044] Trial 27 finished with value: -0.49739421732088107 and parameters: {'hidden_dim': 75, 'num_layers': 2, 'dropout': 0.18505983428471842, 'learning_rate': 0.0005299391599381381, 'batch_size': 32}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:28:22,958] Trial 28 finished with value: -0.4222654139256107 and parameters: {'hidden_dim': 95, 'num_layers': 1, 'dropout': 0.13990129052693637, 'learning_rate': 0.003469040638621916, 'batch_size': 64}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:29:26,675] Trial 29 finished with value: -0.4865769086317618 and parameters: {'hidden_dim': 116, 'num_layers': 2, 'dropout': 0.21577844013217418, 'learning_rate': 0.0001742440727716437, 'batch_size': 16}. Best is trial 16 with value: -0.5953609544051803.\n",
      "[I 2025-05-11 12:29:26,698] A new study created in memory with name: no-name-8771cc3d-2026-4c31-aef6-75f94abc3690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 21: Best Params = {'hidden_dim': 87, 'num_layers': 2, 'dropout': 0.3618853403120836, 'learning_rate': 0.0005634761029617077, 'batch_size': 64}, Best F1 = 0.5954\n",
      "\n",
      "=== Forecast Horizon: 63 ===\n",
      "[INFO] Generated 7 folds for forecast horizon 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-11 12:29:56,397] Trial 0 finished with value: -0.4308276583330954 and parameters: {'hidden_dim': 93, 'num_layers': 2, 'dropout': 0.4828864432826748, 'learning_rate': 0.0003728019759414556, 'batch_size': 16}. Best is trial 0 with value: -0.4308276583330954.\n",
      "[I 2025-05-11 12:30:25,684] Trial 1 finished with value: -0.48518948833402314 and parameters: {'hidden_dim': 58, 'num_layers': 1, 'dropout': 0.2869298427868413, 'learning_rate': 0.00203125102369817, 'batch_size': 16}. Best is trial 1 with value: -0.48518948833402314.\n",
      "[I 2025-05-11 12:30:40,204] Trial 2 finished with value: -0.4362359558762244 and parameters: {'hidden_dim': 118, 'num_layers': 2, 'dropout': 0.3337429431787884, 'learning_rate': 0.005431819316835627, 'batch_size': 64}. Best is trial 1 with value: -0.48518948833402314.\n",
      "[I 2025-05-11 12:30:49,395] Trial 3 finished with value: -0.5068014503068874 and parameters: {'hidden_dim': 78, 'num_layers': 2, 'dropout': 0.22938497689400014, 'learning_rate': 0.0009918095789440181, 'batch_size': 64}. Best is trial 3 with value: -0.5068014503068874.\n",
      "[I 2025-05-11 12:31:06,653] Trial 4 finished with value: -0.4357231198323305 and parameters: {'hidden_dim': 50, 'num_layers': 1, 'dropout': 0.3681785838067436, 'learning_rate': 0.005420928611595724, 'batch_size': 128}. Best is trial 3 with value: -0.5068014503068874.\n",
      "[I 2025-05-11 12:31:24,689] Trial 5 finished with value: -0.2884819067158206 and parameters: {'hidden_dim': 53, 'num_layers': 2, 'dropout': 0.13887243947880137, 'learning_rate': 0.002004391763770127, 'batch_size': 128}. Best is trial 3 with value: -0.5068014503068874.\n",
      "[I 2025-05-11 12:31:42,086] Trial 6 finished with value: -0.4308276583330954 and parameters: {'hidden_dim': 72, 'num_layers': 2, 'dropout': 0.18983645654047995, 'learning_rate': 0.0002758963194329824, 'batch_size': 32}. Best is trial 3 with value: -0.5068014503068874.\n",
      "[I 2025-05-11 12:32:04,026] Trial 7 finished with value: -0.4520472135332331 and parameters: {'hidden_dim': 61, 'num_layers': 1, 'dropout': 0.44252940928672735, 'learning_rate': 0.003350839349353397, 'batch_size': 32}. Best is trial 3 with value: -0.5068014503068874.\n",
      "[I 2025-05-11 12:32:25,529] Trial 8 finished with value: -0.4139047329006062 and parameters: {'hidden_dim': 50, 'num_layers': 1, 'dropout': 0.17615706483872523, 'learning_rate': 0.00019836700574734075, 'batch_size': 32}. Best is trial 3 with value: -0.5068014503068874.\n",
      "[I 2025-05-11 12:32:58,213] Trial 9 finished with value: -0.5374993688699761 and parameters: {'hidden_dim': 105, 'num_layers': 1, 'dropout': 0.1181692339768953, 'learning_rate': 0.0002958967067012953, 'batch_size': 16}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:33:28,924] Trial 10 finished with value: -0.4984668994739138 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.2695824538021353, 'learning_rate': 0.00010348918057848374, 'batch_size': 16}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:33:49,386] Trial 11 finished with value: -0.4365175587598379 and parameters: {'hidden_dim': 96, 'num_layers': 2, 'dropout': 0.10321667479217994, 'learning_rate': 0.0007310765515383672, 'batch_size': 64}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:34:11,917] Trial 12 finished with value: -0.45217883175800155 and parameters: {'hidden_dim': 99, 'num_layers': 2, 'dropout': 0.22902362536825777, 'learning_rate': 0.0007090105997977354, 'batch_size': 64}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:34:32,331] Trial 13 finished with value: -0.4824587971622658 and parameters: {'hidden_dim': 34, 'num_layers': 1, 'dropout': 0.10003091237021393, 'learning_rate': 0.0010651392609208755, 'batch_size': 64}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:35:09,728] Trial 14 finished with value: -0.5008720874199771 and parameters: {'hidden_dim': 83, 'num_layers': 1, 'dropout': 0.2100872778033978, 'learning_rate': 0.0004315341940596828, 'batch_size': 16}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:35:32,950] Trial 15 finished with value: -0.29273753107329303 and parameters: {'hidden_dim': 109, 'num_layers': 2, 'dropout': 0.2526347156002843, 'learning_rate': 0.0001262067967050605, 'batch_size': 64}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:36:05,471] Trial 16 finished with value: -0.2932776407830779 and parameters: {'hidden_dim': 77, 'num_layers': 2, 'dropout': 0.15932828705083185, 'learning_rate': 0.001128085041810005, 'batch_size': 16}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:36:21,977] Trial 17 finished with value: -0.5285717122705028 and parameters: {'hidden_dim': 86, 'num_layers': 1, 'dropout': 0.33488292205194414, 'learning_rate': 0.0005364762700664355, 'batch_size': 128}. Best is trial 9 with value: -0.5374993688699761.\n",
      "[I 2025-05-11 12:36:41,023] Trial 18 finished with value: -0.5419828679402623 and parameters: {'hidden_dim': 109, 'num_layers': 1, 'dropout': 0.39267957978771995, 'learning_rate': 0.00018813096222396772, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:36:59,226] Trial 19 finished with value: -0.46042247691130017 and parameters: {'hidden_dim': 109, 'num_layers': 1, 'dropout': 0.4095730238753061, 'learning_rate': 0.00019083491898971155, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:37:16,841] Trial 20 finished with value: -0.386893498609462 and parameters: {'hidden_dim': 111, 'num_layers': 1, 'dropout': 0.41823351597770486, 'learning_rate': 0.00018738120435487997, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:37:33,579] Trial 21 finished with value: -0.29757295228020303 and parameters: {'hidden_dim': 90, 'num_layers': 1, 'dropout': 0.33229898184901413, 'learning_rate': 0.0004634268028078161, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:37:52,544] Trial 22 finished with value: -0.4316253303884957 and parameters: {'hidden_dim': 101, 'num_layers': 1, 'dropout': 0.35081180672739437, 'learning_rate': 0.0002870513882603799, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:38:11,653] Trial 23 finished with value: -0.4976956045409304 and parameters: {'hidden_dim': 123, 'num_layers': 1, 'dropout': 0.38042668878792285, 'learning_rate': 0.0005322122050676065, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:38:28,143] Trial 24 finished with value: -0.33756504806689547 and parameters: {'hidden_dim': 86, 'num_layers': 1, 'dropout': 0.3067325370070464, 'learning_rate': 0.00031836180466085604, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:38:57,375] Trial 25 finished with value: -0.39231251614619583 and parameters: {'hidden_dim': 106, 'num_layers': 1, 'dropout': 0.4790133288150716, 'learning_rate': 0.00014327758239119013, 'batch_size': 16}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:39:12,636] Trial 26 finished with value: -0.43398545530532534 and parameters: {'hidden_dim': 117, 'num_layers': 1, 'dropout': 0.3908899857081769, 'learning_rate': 0.00022888988228659304, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:39:23,985] Trial 27 finished with value: -0.5229193169772053 and parameters: {'hidden_dim': 71, 'num_layers': 1, 'dropout': 0.44115447819484893, 'learning_rate': 0.0006046538591212562, 'batch_size': 128}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:39:56,521] Trial 28 finished with value: -0.5125535806042233 and parameters: {'hidden_dim': 102, 'num_layers': 1, 'dropout': 0.3030557425157172, 'learning_rate': 0.009935683784109937, 'batch_size': 16}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:40:29,067] Trial 29 finished with value: -0.44367519083128293 and parameters: {'hidden_dim': 91, 'num_layers': 1, 'dropout': 0.32974691018467484, 'learning_rate': 0.0003912551121165099, 'batch_size': 16}. Best is trial 18 with value: -0.5419828679402623.\n",
      "[I 2025-05-11 12:40:29,082] A new study created in memory with name: no-name-de55c2b7-4295-4244-9a2a-4dbb62f4c784\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 63: Best Params = {'hidden_dim': 109, 'num_layers': 1, 'dropout': 0.39267957978771995, 'learning_rate': 0.00018813096222396772, 'batch_size': 128}, Best F1 = 0.5420\n",
      "\n",
      "=== Forecast Horizon: 252 ===\n",
      "[INFO] Generated 5 folds for forecast horizon 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:40:41,091] Trial 0 finished with value: -0.4166321445615794 and parameters: {'hidden_dim': 125, 'num_layers': 2, 'dropout': 0.3018016204054782, 'learning_rate': 0.00063778304976431, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:40:51,384] Trial 1 finished with value: -0.4024440957043466 and parameters: {'hidden_dim': 111, 'num_layers': 2, 'dropout': 0.2996203544832724, 'learning_rate': 0.00883393748896689, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:41:02,531] Trial 2 finished with value: -0.4049759458403662 and parameters: {'hidden_dim': 50, 'num_layers': 1, 'dropout': 0.21816290625902465, 'learning_rate': 0.007001705627540978, 'batch_size': 64}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:41:18,788] Trial 3 finished with value: -0.39533832553160064 and parameters: {'hidden_dim': 35, 'num_layers': 2, 'dropout': 0.16071658544665404, 'learning_rate': 0.005069280711385831, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:41:30,529] Trial 4 finished with value: -0.39066506165784853 and parameters: {'hidden_dim': 68, 'num_layers': 2, 'dropout': 0.444903125347045, 'learning_rate': 0.0036300634652135333, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:41:40,523] Trial 5 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 109, 'num_layers': 1, 'dropout': 0.2100748219031644, 'learning_rate': 0.00017534259541163467, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:41:57,735] Trial 6 finished with value: -0.3891302942246233 and parameters: {'hidden_dim': 67, 'num_layers': 2, 'dropout': 0.4354372904282061, 'learning_rate': 0.0032866241686266505, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:42:09,751] Trial 7 finished with value: -0.40218457662563933 and parameters: {'hidden_dim': 71, 'num_layers': 1, 'dropout': 0.28463134370594145, 'learning_rate': 0.003316535425608853, 'batch_size': 64}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:42:21,591] Trial 8 finished with value: -0.4019315564875665 and parameters: {'hidden_dim': 62, 'num_layers': 2, 'dropout': 0.2829261481008428, 'learning_rate': 0.00013534561118301377, 'batch_size': 64}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:42:35,908] Trial 9 finished with value: -0.40759945160573174 and parameters: {'hidden_dim': 63, 'num_layers': 2, 'dropout': 0.48974736881131975, 'learning_rate': 0.0010823848792825138, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:42:56,716] Trial 10 finished with value: -0.40086589530695804 and parameters: {'hidden_dim': 128, 'num_layers': 1, 'dropout': 0.10087627080649464, 'learning_rate': 0.00033618586702215456, 'batch_size': 16}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:43:12,868] Trial 11 finished with value: -0.4024440957043466 and parameters: {'hidden_dim': 90, 'num_layers': 2, 'dropout': 0.38552337805642334, 'learning_rate': 0.0007260473706729399, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:43:37,848] Trial 12 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 89, 'num_layers': 2, 'dropout': 0.4966988353908473, 'learning_rate': 0.0011558502366089617, 'batch_size': 16}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:43:52,702] Trial 13 finished with value: -0.4038618467239621 and parameters: {'hidden_dim': 48, 'num_layers': 2, 'dropout': 0.3519527974483177, 'learning_rate': 0.0011541646391849244, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:44:05,773] Trial 14 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'dropout': 0.3624284604299796, 'learning_rate': 0.0005841228217950014, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:44:20,366] Trial 15 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 86, 'num_layers': 2, 'dropout': 0.499262434709011, 'learning_rate': 0.0017807973563245569, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:44:33,442] Trial 16 finished with value: -0.41196356168552334 and parameters: {'hidden_dim': 104, 'num_layers': 2, 'dropout': 0.42827090608047713, 'learning_rate': 0.0003828547113237829, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:44:43,728] Trial 17 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 110, 'num_layers': 1, 'dropout': 0.40095311904335623, 'learning_rate': 0.0003193625301813413, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:44:55,385] Trial 18 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 101, 'num_layers': 2, 'dropout': 0.3296687129915193, 'learning_rate': 0.00036201899051641425, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:45:08,028] Trial 19 finished with value: -0.401220484955228 and parameters: {'hidden_dim': 118, 'num_layers': 2, 'dropout': 0.2419760377867559, 'learning_rate': 0.00022406776934549732, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:45:18,198] Trial 20 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 100, 'num_layers': 1, 'dropout': 0.4222096774674535, 'learning_rate': 0.0005560293389577192, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:45:47,974] Trial 21 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 121, 'num_layers': 2, 'dropout': 0.4663189027204419, 'learning_rate': 0.0018856162772755971, 'batch_size': 16}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:46:02,254] Trial 22 finished with value: -0.4019288323698952 and parameters: {'hidden_dim': 79, 'num_layers': 2, 'dropout': 0.45894840775061535, 'learning_rate': 0.0009177542289564365, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:46:14,960] Trial 23 finished with value: -0.4019288323698952 and parameters: {'hidden_dim': 100, 'num_layers': 2, 'dropout': 0.39191882813151063, 'learning_rate': 0.0016879461873652545, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:46:25,268] Trial 24 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 50, 'num_layers': 2, 'dropout': 0.326433063430026, 'learning_rate': 0.00010141026928355125, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:46:41,078] Trial 25 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 77, 'num_layers': 2, 'dropout': 0.48689517869269683, 'learning_rate': 0.0004963699789137771, 'batch_size': 32}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:47:01,198] Trial 26 finished with value: -0.4025205371454848 and parameters: {'hidden_dim': 57, 'num_layers': 2, 'dropout': 0.41578743009909647, 'learning_rate': 0.0008356827526531059, 'batch_size': 16}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:47:15,513] Trial 27 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 117, 'num_layers': 2, 'dropout': 0.24733147986776818, 'learning_rate': 0.0002447717637452808, 'batch_size': 64}. Best is trial 0 with value: -0.4166321445615794.\n",
      "[I 2025-05-11 12:47:26,244] Trial 28 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 39, 'num_layers': 2, 'dropout': 0.4671439618402267, 'learning_rate': 0.0005185924543914203, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2025-05-11 12:47:38,461] Trial 29 finished with value: -0.4018023501564564 and parameters: {'hidden_dim': 107, 'num_layers': 2, 'dropout': 0.3652672602635987, 'learning_rate': 0.0012610108504472332, 'batch_size': 128}. Best is trial 0 with value: -0.4166321445615794.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 252: Best Params = {'hidden_dim': 125, 'num_layers': 2, 'dropout': 0.3018016204054782, 'learning_rate': 0.00063778304976431, 'batch_size': 128}, Best F1 = 0.4166\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_df = pd.read_csv(r\"X_df.csv\", index_col=0, parse_dates=True)\n",
    "Y_df_dict = {\n",
    "    1: pd.read_csv(r\"Y_df_change_dir_1.csv\", index_col=0, parse_dates=True),\n",
    "    5: pd.read_csv(r\"Y_df_change_dir_5.csv\", index_col=0, parse_dates=True),\n",
    "    21: pd.read_csv(r\"Y_df_change_dir_21.csv\", index_col=0, parse_dates=True),\n",
    "    63: pd.read_csv(r\"Y_df_change_dir_63.csv\", index_col=0, parse_dates=True),\n",
    "    252: pd.read_csv(r\"Y_df_change_dir_252.csv\", index_col=0, parse_dates=True),\n",
    "}\n",
    "\n",
    "# Run optimization\n",
    "results = run_for_all_horizons(X_df, Y_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046d73f4-73c3-43ff-890a-ad2ddc7c042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'best_params': {'hidden_dim': 84,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.45710576033956674,\n",
       "   'learning_rate': 0.004688535399076738,\n",
       "   'batch_size': 16},\n",
       "  'best_f1': 0.5548958508540118},\n",
       " 5: {'best_params': {'hidden_dim': 92,\n",
       "   'num_layers': 1,\n",
       "   'dropout': 0.21557525139220088,\n",
       "   'learning_rate': 0.0004883533160474792,\n",
       "   'batch_size': 16},\n",
       "  'best_f1': 0.5482964955974565},\n",
       " 21: {'best_params': {'hidden_dim': 87,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.3618853403120836,\n",
       "   'learning_rate': 0.0005634761029617077,\n",
       "   'batch_size': 64},\n",
       "  'best_f1': 0.5953609544051803},\n",
       " 63: {'best_params': {'hidden_dim': 109,\n",
       "   'num_layers': 1,\n",
       "   'dropout': 0.39267957978771995,\n",
       "   'learning_rate': 0.00018813096222396772,\n",
       "   'batch_size': 128},\n",
       "  'best_f1': 0.5419828679402623},\n",
       " 252: {'best_params': {'hidden_dim': 125,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.3018016204054782,\n",
       "   'learning_rate': 0.00063778304976431,\n",
       "   'batch_size': 128},\n",
       "  'best_f1': 0.4166321445615794}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c132f59-dbd6-41cc-813c-2ff20c72567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_on_holdout(X_df, Y_df_dict, best_params_dict):\n",
    "    holdout_results = {}\n",
    "    for h in forecast_horizons:\n",
    "        print(f\"\\n[TEST] Forecast Horizon: {h}\")\n",
    "        params = best_params_dict[h]['best_params']\n",
    "        hidden_dim = int(params['hidden_dim'])\n",
    "        num_layers = int(params['num_layers'])\n",
    "        dropout = float(params['dropout'])\n",
    "        learning_rate = float(params['learning_rate'])\n",
    "        batch_size = int(params['batch_size'])\n",
    "\n",
    "        Y_df = Y_df_dict[h]\n",
    "        X_shifted = shift_X_by_horizon(X_df, h)\n",
    "        Y_aligned = Y_df.loc[X_shifted.index]\n",
    "        X_final, Y_final = X_shifted, Y_aligned\n",
    "\n",
    "        folds, last_val_end, _ = get_expanding_folds(X_final, Y_final, h, sequence_length, val_window_num_sequences, holdout_base)\n",
    "        X_train, Y_train = X_final.iloc[:last_val_end], Y_final.iloc[:last_val_end]\n",
    "        X_test, Y_test = X_final.iloc[last_val_end:], Y_final.iloc[last_val_end:]\n",
    "\n",
    "        print(f\"[INFO] Holdout Label Distribution (0s/1s): {np.bincount(Y_test.values.astype(int).flatten())}\")\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "        X_train_seq, Y_train_seq = create_sequences(X_train_scaled, Y_train, sequence_length, h)\n",
    "        X_test_seq, Y_test_seq = create_sequences(X_test_scaled, Y_test, sequence_length, h)\n",
    "\n",
    "        X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
    "        Y_train_tensor = torch.tensor(Y_train_seq, dtype=torch.float32).to(device)\n",
    "        X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\n",
    "        Y_test_tensor = torch.tensor(Y_test_seq, dtype=torch.float32).to(device)\n",
    "\n",
    "        model = LSTMClassifier(X_train_seq.shape[2], hidden_dim, num_layers, Y_train_seq.shape[1], dropout).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(xb), yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for xb in DataLoader(X_test_tensor, batch_size=batch_size):\n",
    "                preds.append(torch.sigmoid(model(xb)))\n",
    "\n",
    "        pred_tensor = torch.cat(preds, dim=0).squeeze()\n",
    "        pred_bin = (pred_tensor > 0.5).int().cpu().numpy()\n",
    "        y_true = Y_test_tensor.int().cpu().numpy()\n",
    "\n",
    "        acc = accuracy_score(y_true, pred_bin)\n",
    "        f1 = f1_score(y_true, pred_bin, average='macro')\n",
    "        precision = precision_score(y_true, pred_bin, average='macro')\n",
    "        recall = recall_score(y_true, pred_bin, average='macro')\n",
    "\n",
    "        holdout_results[h] = {\n",
    "            \"accuracy\": acc,\n",
    "            \"f1\": f1,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }\n",
    "        print(f\"[RESULT] Horizon {h}: Accuracy = {acc:.4f}, F1 = {f1:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}\")\n",
    "\n",
    "    return holdout_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8234fd1-5055-4006-9b11-b36094efb792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Forecast Horizon: 1\n",
      "[INFO] Generated 8 folds for forecast horizon 1\n",
      "[INFO] Holdout Label Distribution (0s/1s): [3620 2728]\n",
      "[RESULT] Horizon 1: Accuracy = 0.6365, F1 = 0.4328, Precision = 0.4679, Recall = 0.4908\n",
      "\n",
      "[TEST] Forecast Horizon: 5\n",
      "[INFO] Generated 8 folds for forecast horizon 5\n",
      "[INFO] Holdout Label Distribution (0s/1s): [2856 3252]\n",
      "[RESULT] Horizon 5: Accuracy = 0.6063, F1 = 0.6063, Precision = 0.6099, Recall = 0.6098\n",
      "\n",
      "[TEST] Forecast Horizon: 21\n",
      "[INFO] Generated 8 folds for forecast horizon 21\n",
      "[INFO] Holdout Label Distribution (0s/1s): [2072 3076]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESULT] Horizon 21: Accuracy = 0.9010, F1 = 0.4740, Precision = 0.4505, Recall = 0.5000\n",
      "\n",
      "[TEST] Forecast Horizon: 63\n",
      "[INFO] Generated 7 folds for forecast horizon 63\n",
      "[INFO] Holdout Label Distribution (0s/1s): [1979 4045]\n",
      "[RESULT] Horizon 63: Accuracy = 0.3101, F1 = 0.2759, Precision = 0.5606, Recall = 0.5159\n",
      "\n",
      "[TEST] Forecast Horizon: 252\n",
      "[INFO] Generated 5 folds for forecast horizon 252\n",
      "[INFO] Holdout Label Distribution (0s/1s): [ 993 3885]\n",
      "[RESULT] Horizon 252: Accuracy = 0.0839, F1 = 0.0774, Precision = 0.5000, Recall = 0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "holdout_results = evaluate_on_holdout(X_df, Y_df_dict, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5ed15-c58b-4d29-b480-b96ef4ab85fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
